{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a href=\"https://colab.research.google.com/github/VighneshS/sentiment_prediction/blob/master/sentiment_prediction.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "<a href=\"https://vighnesh-studies.blogspot.com/2021/04/sentiment-prediction-using-naive-bayes.html\" target=\"_blank\">BLOG</a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sentiment Prediction using Naive Bayes Classifier (NBC)\n",
    "This is a notebook to understand how Naive Bayes Classifier (NBC) works and also how it is useful to classify text based on sentiment.\n",
    "\n",
    "We will also see how it will be effective against missing data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Settings\n",
    "Training Percentage"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "outputs": [],
   "source": [
    "training_ratio = 80 / 100\n",
    "k = 5\n",
    "most_useful_limit = 20"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Importing the Data\n",
    "We used the [kaggle dataset](https://storage.googleapis.com/kagglesdsdata/datasets/22169/30047/sentiment%20labelled%20sentences/imdb_labelled.txt?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20210425%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20210425T202010Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=6133706ef10bc2dcd0b58f8398b4d73ab9e9d788de1718b07334df91f6007e1e4ca0b78e3176f95b8250e0c4535ce1633528f4fabffeb7e4124af3ee3f895ac34c03044fca9b23b23c4ddb8fa90d84dfc14869ff4806f03783cafad53b19445b3c3052983fdf1ca4384257eac1bc0a4270d238a1ea89d1289866c7a0ea7ad7c97a76f2e142c148019e39cc5a1295f92650747ac5ea5946b026f7ad6d5d262d4c4a370aee6bc1f5d5b445bb6d93692debe678a79e5e1c1fe3d3e68ea4f2fad3115795d3361e0626e98156fbc7f5967beb7cf0f00e07351d23a00d8677ebb75e3e13b1bfa07762266efabf6f6f9d53206be31b7623cf3614f60f8cf5011cf23def) to get the ground truth of sample IMDB reviews."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from IPython.display import display\n",
    "import math\n",
    "from sklearn.model_selection import KFold"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "outputs": [],
   "source": [
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "data = pd.read_csv(\n",
    "    r\"http://storage.googleapis.com/kagglesdsdata/datasets/22169/30047/sentiment%20labelled%20sentences/imdb_labelled.txt?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20210425%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20210425T202010Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=6133706ef10bc2dcd0b58f8398b4d73ab9e9d788de1718b07334df91f6007e1e4ca0b78e3176f95b8250e0c4535ce1633528f4fabffeb7e4124af3ee3f895ac34c03044fca9b23b23c4ddb8fa90d84dfc14869ff4806f03783cafad53b19445b3c3052983fdf1ca4384257eac1bc0a4270d238a1ea89d1289866c7a0ea7ad7c97a76f2e142c148019e39cc5a1295f92650747ac5ea5946b026f7ad6d5d262d4c4a370aee6bc1f5d5b445bb6d93692debe678a79e5e1c1fe3d3e68ea4f2fad3115795d3361e0626e98156fbc7f5967beb7cf0f00e07351d23a00d8677ebb75e3e13b1bfa07762266efabf6f6f9d53206be31b7623cf3614f60f8cf5011cf23def\",\n",
    "    delimiter=\"\\t\", header=None, names=[\"IMDB Review\", \"Sentiment\"])\n",
    "data = data.sample(frac=1).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split Data\n",
    "We split the data into train, development and test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "outputs": [],
   "source": [
    "train = data[:math.floor(data.shape[0] * training_ratio)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "outputs": [],
   "source": [
    "validation = data[math.floor(data.shape[0] * training_ratio):].sample(frac=1).reset_index(drop=True)\n",
    "dev, test = np.array_split(validation, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "outputs": [
    {
     "data": {
      "text/plain": "                                           IMDB Review  Sentiment\n0    It has northern humour and positive about the ...          1\n1               But it is entertaining, nonetheless.            1\n2    The result is a film that just don't look righ...          0\n3                              Highly unrecommended.            0\n4    Technically, the film is well made with impres...          1\n..                                                 ...        ...\n593  I am a fan of his ... This movie sucked really...          0\n594                     Nothing at all to recommend.            0\n595                            It is a true classic.            1\n596  It's the one movie that never ceases to intere...          1\n597  Don't be afraid of subtitles........ its worth...          1\n\n[598 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IMDB Review</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>It has northern humour and positive about the ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>But it is entertaining, nonetheless.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The result is a film that just don't look righ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Highly unrecommended.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Technically, the film is well made with impres...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>593</th>\n      <td>I am a fan of his ... This movie sucked really...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>594</th>\n      <td>Nothing at all to recommend.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>595</th>\n      <td>It is a true classic.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>596</th>\n      <td>It's the one movie that never ceases to intere...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>597</th>\n      <td>Don't be afraid of subtitles........ its worth...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>598 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                                          IMDB Review  Sentiment\n0   This is a bad film, with bad writing, and good...          0\n1   Lot of holes in the plot: there's nothing abou...          0\n2   Very disappointed and wondered how it could be...          0\n3           If you want a real scare rent this one!            1\n4   A Lassie movie which should have been \"put to ...          0\n..                                                ...        ...\n70  To be honest with you, this is unbelievable no...          0\n71                  The film looks cheap and bland.            0\n72  It's a shame to see good actors like Thomerson...          0\n73  I could not stand to even watch it for very lo...          0\n74                                   I gave it a 10            1\n\n[75 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IMDB Review</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>This is a bad film, with bad writing, and good...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Lot of holes in the plot: there's nothing abou...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Very disappointed and wondered how it could be...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>If you want a real scare rent this one!</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A Lassie movie which should have been \"put to ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>To be honest with you, this is unbelievable no...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>The film looks cheap and bland.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>It's a shame to see good actors like Thomerson...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>I could not stand to even watch it for very lo...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>I gave it a 10</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>75 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                                           IMDB Review  Sentiment\n75   A very good film indeed, about great and uncon...          1\n76   This is truly an art movie--it actually has a ...          1\n77   The interplay between Martin and Emilio contai...          1\n78   His losing his marbles so early in the proceed...          0\n79   In fact, this stinker smells like a direct-to-...          0\n..                                                 ...        ...\n145                           there is no real plot.            0\n146                                It was so BORING!            0\n147           It is zillion times away from reality.            0\n148        The music in the film is really nice too.            1\n149  Almost all of the songs in Cover Girl are old-...          0\n\n[75 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IMDB Review</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>75</th>\n      <td>A very good film indeed, about great and uncon...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>This is truly an art movie--it actually has a ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>The interplay between Martin and Emilio contai...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>His losing his marbles so early in the proceed...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>In fact, this stinker smells like a direct-to-...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>there is no real plot.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>It was so BORING!</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>It is zillion times away from reality.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>The music in the film is really nice too.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>Almost all of the songs in Cover Girl are old-...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>75 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train, dev, test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generation of Vocabulary list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "outputs": [],
   "source": [
    "def split_words(review):\n",
    "    return review.lower().replace(',', '').replace('\"', '').replace('(', '').replace(')', '').replace('\\'s',\n",
    "                                                                                                      '').replace(\n",
    "        '.',\n",
    "        '').replace(\n",
    "        '!', '').replace('-', ' ').replace('/', ' ').split()\n",
    "\n",
    "\n",
    "def get_word_count(review_data_frame: pd.DataFrame, column_name: str):\n",
    "    vocab = review_data_frame[\"IMDB Review\"].apply(lambda review: pd.value_counts(\n",
    "        split_words(review))).count(axis=0).to_frame()\n",
    "    vocab.columns = [column_name]\n",
    "    vocab.reset_index(inplace=True)\n",
    "    vocab = vocab.rename(columns={'index': 'Word'})\n",
    "    return vocab"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get Naive Bayes Parameters\n",
    "Here we have a function to genereate the Naive Bayes Parameters like:\n",
    "\n",
    "1. Word Frequency\n",
    "2. P(Word)\n",
    "3. Positive Sentiment Word Frequency\n",
    "4. P(Sentiment = Positive)\n",
    "5. P(Word | Sentiment = Positive)\n",
    "6. Negative Sentiment Word Frequency\n",
    "7. P(Sentiment = Negative)\n",
    "8. P(Word | Sentiment = Negative)\n",
    "\n",
    "Which are useful in finding:\n",
    "\n",
    "**P(Sentiment | Sentence (Collection of words)) = P(Sentence | Sentiment) * P(Sentiment) / P(Sentense)**\n",
    "\n",
    "The P(Sentense) can be approximated to 1 as we are comparing sentiments the value will be cancelled on either sides"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "outputs": [],
   "source": [
    "def generate_naive_bayes_parameters(data_frame: pd.DataFrame, smoothening: bool):\n",
    "    naive_bayes_parameters = get_word_count(data_frame, \"Word Frequency\")\n",
    "    if smoothening:\n",
    "        naive_bayes_parameters[\"Word Frequency\"] += 1\n",
    "\n",
    "    total_words = naive_bayes_parameters[\"Word Frequency\"].sum(axis=0)\n",
    "    if smoothening:\n",
    "        total_words += 2\n",
    "\n",
    "    total_sentiments = data_frame.count(axis=0)['Sentiment']\n",
    "    if smoothening:\n",
    "        total_sentiments += 2\n",
    "\n",
    "    naive_bayes_parameters['P(Word)'] = naive_bayes_parameters[\"Word Frequency\"].div(total_words)\n",
    "\n",
    "    positive_sentiments = data_frame[data_frame['Sentiment'] == 1]\n",
    "    positive_vocabulary = get_word_count(positive_sentiments, \"Positive Sentiment Word Frequency\")\n",
    "    naive_bayes_parameters = naive_bayes_parameters.merge(positive_vocabulary, how='left', on='Word')\n",
    "    if smoothening:\n",
    "        naive_bayes_parameters[\"Positive Sentiment Word Frequency\"] += 1\n",
    "        naive_bayes_parameters[\"Positive Sentiment Word Frequency\"] = naive_bayes_parameters[\n",
    "            \"Positive Sentiment Word Frequency\"].fillna(\n",
    "            value=1)\n",
    "\n",
    "    total_positive_words = positive_sentiments.count(axis=0)['Sentiment']\n",
    "    if smoothening:\n",
    "        total_positive_words += 2\n",
    "\n",
    "    probability_of_positive_sentiments = total_positive_words / total_sentiments\n",
    "    naive_bayes_parameters['P(Sentiment = Positive)'] = probability_of_positive_sentiments\n",
    "\n",
    "    naive_bayes_parameters['P(Word | Sentiment = Positive)'] = naive_bayes_parameters[\n",
    "        'Positive Sentiment Word Frequency'].div(\n",
    "        total_positive_words)\n",
    "\n",
    "    negative_sentiments = data_frame[data_frame['Sentiment'] == 0]\n",
    "    negative_vocabulary = get_word_count(negative_sentiments, \"Negative Sentiment Word Frequency\")\n",
    "    naive_bayes_parameters = naive_bayes_parameters.merge(negative_vocabulary, how='left', on='Word')\n",
    "    if smoothening:\n",
    "        naive_bayes_parameters[\"Negative Sentiment Word Frequency\"] += 1\n",
    "        naive_bayes_parameters[\"Negative Sentiment Word Frequency\"] = naive_bayes_parameters[\n",
    "            \"Negative Sentiment Word Frequency\"].fillna(\n",
    "            value=1)\n",
    "\n",
    "    total_negative_words = negative_sentiments.count(axis=0)['Sentiment']\n",
    "    if smoothening:\n",
    "        total_negative_words += 2\n",
    "\n",
    "    probability_of_negative_sentiments = total_negative_words / total_sentiments\n",
    "    naive_bayes_parameters['P(Sentiment = Negative)'] = probability_of_negative_sentiments\n",
    "\n",
    "    naive_bayes_parameters['P(Word | Sentiment = Negative)'] = naive_bayes_parameters[\n",
    "        'Negative Sentiment Word Frequency'].div(\n",
    "        total_negative_words)\n",
    "\n",
    "    return naive_bayes_parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## To Get the Probabilities\n",
    "\n",
    "We use this formula to get the probabilities:\n",
    "\n",
    "**P(Sentiment | Sentence (Collection of words)) = P(Sentence | Sentiment) * P(Sentiment) / P(Sentense)**\n",
    "\n",
    "The below function will calculate the numerator part and assumes the denominator to be 1 as it will cancel out during\n",
    "comparison.\n",
    "\n",
    "For calculating the P(Sentence | Sentiment) we have words in sentences. So, we can write the formula as:\n",
    "\n",
    "**P(Sentence | Sentiment) = P(Word_1,Word_2,...,Word_n | Sentiment)**\n",
    "\n",
    "By Naive Bayes Theorem we can write it as:\n",
    "\n",
    "**P(Word_1,Word_2,...,Word_n | Sentiment) = P(Word_1 | Sentiment).P(Word_2 | Sentiment). ... .P(Word_n | Sentiment)**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "outputs": [],
   "source": [
    "def get_probabilities(review: str, naive_bayes_parameters: pd.DataFrame, sentiment: bool, smoothening: bool):\n",
    "    prob = 1\n",
    "    column_name = 'P(Word | Sentiment = Positive)' if sentiment else 'P(Word | Sentiment = Negative)'\n",
    "    individual_prob = 0 if not smoothening else 1 / (\n",
    "        naive_bayes_parameters['P(Sentiment = Positive)'][0] if sentiment else naive_bayes_parameters[\n",
    "            'P(Sentiment = Negative)'][0])\n",
    "    for word in split_words(review):\n",
    "        if word in naive_bayes_parameters.values:\n",
    "            individual_prob = naive_bayes_parameters[naive_bayes_parameters['Word'] == word].iloc[0][column_name]\n",
    "        prob *= 0 if math.isnan(individual_prob) else individual_prob\n",
    "    return prob * (naive_bayes_parameters['P(Sentiment = Positive)'][0] if sentiment else naive_bayes_parameters[\n",
    "        'P(Sentiment = Negative)'][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "outputs": [],
   "source": [
    "def predict_calculate_accuracy(data_frame: pd.DataFrame, naive_bayes_parameters: pd.DataFrame):\n",
    "    data_frame[\"P(Sentiment = Positive | Sentence)\"] = data_frame[\"IMDB Review\"].apply(\n",
    "        lambda review: get_probabilities(review, naive_bayes_parameters, True, False))\n",
    "    data_frame[\"P(Sentiment = Negative | Sentence)\"] = data_frame[\"IMDB Review\"].apply(\n",
    "        lambda review: get_probabilities(review, naive_bayes_parameters, False, False))\n",
    "    data_frame[\"Predicted sentiment\"] = data_frame[\"P(Sentiment = Positive | Sentence)\"] > data_frame[\n",
    "        \"P(Sentiment = Negative | Sentence)\"]\n",
    "    accuracy = data_frame.loc[data_frame[\"Predicted sentiment\"] == data_frame[\"Sentiment\"]].count(axis=0)[\n",
    "                   'Sentiment'] * 100 / data_frame.count(axis=0)['Sentiment']\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    # print(\"Wrong Predictions:\")\n",
    "    # display(data_frame.loc[data_frame[\"Predicted sentiment\"] != data_frame[\"Sentiment\"]].reset_index(drop=True))\n",
    "    return accuracy\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculating Accuracy\n",
    "\n",
    "To calculate accuracy we first divide the training dataset into k parts of train and test the first part of the\n",
    "set is used to train the dataset with the remaining k-1 test dataset.\n",
    "\n",
    "We then predict using the Naive bayes parameters that we get from training against the test data.\n",
    "\n",
    "We then calculate the accuracy by finding (how many data is of correct prediction)/(total number of datasets)\n",
    "\n",
    "With the parameters having the best accuracy is chosen from this and used for further validation of dev anf test\n",
    "datasets which we separated in the beginning."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------Fold 1---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                           IMDB Review  Sentiment\n0    It has northern humour and positive about the ...          1\n1               But it is entertaining, nonetheless.            1\n2    The result is a film that just don't look righ...          0\n3                              Highly unrecommended.            0\n4    Technically, the film is well made with impres...          1\n..                                                 ...        ...\n593  I am a fan of his ... This movie sucked really...          0\n594                     Nothing at all to recommend.            0\n595                            It is a true classic.            1\n596  It's the one movie that never ceases to intere...          1\n597  Don't be afraid of subtitles........ its worth...          1\n\n[478 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IMDB Review</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>It has northern humour and positive about the ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>But it is entertaining, nonetheless.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The result is a film that just don't look righ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Highly unrecommended.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Technically, the film is well made with impres...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>593</th>\n      <td>I am a fan of his ... This movie sucked really...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>594</th>\n      <td>Nothing at all to recommend.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>595</th>\n      <td>It is a true classic.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>596</th>\n      <td>It's the one movie that never ceases to intere...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>597</th>\n      <td>Don't be afraid of subtitles........ its worth...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>478 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  56.666666666666664\n"
     ]
    },
    {
     "data": {
      "text/plain": "            Word  Word Frequency   P(Word)  Positive Sentiment Word Frequency  \\\n0             it             146  0.019120                               78.0   \n1     represents               1  0.000131                                1.0   \n2            the             250  0.032740                              143.0   \n3         humour               2  0.000262                                2.0   \n4       northern               1  0.000131                                1.0   \n...          ...             ...       ...                                ...   \n2400      ceases               1  0.000131                                1.0   \n2401       alert               1  0.000131                                1.0   \n2402     therapy               1  0.000131                                1.0   \n2403   subtitles               1  0.000131                                1.0   \n2404    aversion               1  0.000131                                1.0   \n\n      P(Sentiment = Positive)  P(Word | Sentiment = Positive)  \\\n0                    0.531381                        0.307087   \n1                    0.531381                        0.003937   \n2                    0.531381                        0.562992   \n3                    0.531381                        0.007874   \n4                    0.531381                        0.003937   \n...                       ...                             ...   \n2400                 0.531381                        0.003937   \n2401                 0.531381                        0.003937   \n2402                 0.531381                        0.003937   \n2403                 0.531381                        0.003937   \n2404                 0.531381                        0.003937   \n\n      Negative Sentiment Word Frequency  P(Sentiment = Negative)  \\\n0                                  68.0                 0.468619   \n1                                   NaN                 0.468619   \n2                                 107.0                 0.468619   \n3                                   NaN                 0.468619   \n4                                   NaN                 0.468619   \n...                                 ...                      ...   \n2400                                NaN                 0.468619   \n2401                                NaN                 0.468619   \n2402                                NaN                 0.468619   \n2403                                NaN                 0.468619   \n2404                                NaN                 0.468619   \n\n      P(Word | Sentiment = Negative)  \n0                           0.303571  \n1                                NaN  \n2                           0.477679  \n3                                NaN  \n4                                NaN  \n...                              ...  \n2400                             NaN  \n2401                             NaN  \n2402                             NaN  \n2403                             NaN  \n2404                             NaN  \n\n[2405 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Word Frequency</th>\n      <th>P(Word)</th>\n      <th>Positive Sentiment Word Frequency</th>\n      <th>P(Sentiment = Positive)</th>\n      <th>P(Word | Sentiment = Positive)</th>\n      <th>Negative Sentiment Word Frequency</th>\n      <th>P(Sentiment = Negative)</th>\n      <th>P(Word | Sentiment = Negative)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>it</td>\n      <td>146</td>\n      <td>0.019120</td>\n      <td>78.0</td>\n      <td>0.531381</td>\n      <td>0.307087</td>\n      <td>68.0</td>\n      <td>0.468619</td>\n      <td>0.303571</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>represents</td>\n      <td>1</td>\n      <td>0.000131</td>\n      <td>1.0</td>\n      <td>0.531381</td>\n      <td>0.003937</td>\n      <td>NaN</td>\n      <td>0.468619</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>the</td>\n      <td>250</td>\n      <td>0.032740</td>\n      <td>143.0</td>\n      <td>0.531381</td>\n      <td>0.562992</td>\n      <td>107.0</td>\n      <td>0.468619</td>\n      <td>0.477679</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>humour</td>\n      <td>2</td>\n      <td>0.000262</td>\n      <td>2.0</td>\n      <td>0.531381</td>\n      <td>0.007874</td>\n      <td>NaN</td>\n      <td>0.468619</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>northern</td>\n      <td>1</td>\n      <td>0.000131</td>\n      <td>1.0</td>\n      <td>0.531381</td>\n      <td>0.003937</td>\n      <td>NaN</td>\n      <td>0.468619</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2400</th>\n      <td>ceases</td>\n      <td>1</td>\n      <td>0.000131</td>\n      <td>1.0</td>\n      <td>0.531381</td>\n      <td>0.003937</td>\n      <td>NaN</td>\n      <td>0.468619</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2401</th>\n      <td>alert</td>\n      <td>1</td>\n      <td>0.000131</td>\n      <td>1.0</td>\n      <td>0.531381</td>\n      <td>0.003937</td>\n      <td>NaN</td>\n      <td>0.468619</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2402</th>\n      <td>therapy</td>\n      <td>1</td>\n      <td>0.000131</td>\n      <td>1.0</td>\n      <td>0.531381</td>\n      <td>0.003937</td>\n      <td>NaN</td>\n      <td>0.468619</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2403</th>\n      <td>subtitles</td>\n      <td>1</td>\n      <td>0.000131</td>\n      <td>1.0</td>\n      <td>0.531381</td>\n      <td>0.003937</td>\n      <td>NaN</td>\n      <td>0.468619</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2404</th>\n      <td>aversion</td>\n      <td>1</td>\n      <td>0.000131</td>\n      <td>1.0</td>\n      <td>0.531381</td>\n      <td>0.003937</td>\n      <td>NaN</td>\n      <td>0.468619</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>2405 rows Ã— 9 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------Fold 2---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                           IMDB Review  Sentiment\n0    It has northern humour and positive about the ...          1\n1               But it is entertaining, nonetheless.            1\n3                              Highly unrecommended.            0\n4    Technically, the film is well made with impres...          1\n5    There is no plot here to keep you going in the...          0\n..                                                 ...        ...\n593  I am a fan of his ... This movie sucked really...          0\n594                     Nothing at all to recommend.            0\n595                            It is a true classic.            1\n596  It's the one movie that never ceases to intere...          1\n597  Don't be afraid of subtitles........ its worth...          1\n\n[478 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IMDB Review</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>It has northern humour and positive about the ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>But it is entertaining, nonetheless.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Highly unrecommended.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Technically, the film is well made with impres...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>There is no plot here to keep you going in the...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>593</th>\n      <td>I am a fan of his ... This movie sucked really...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>594</th>\n      <td>Nothing at all to recommend.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>595</th>\n      <td>It is a true classic.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>596</th>\n      <td>It's the one movie that never ceases to intere...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>597</th>\n      <td>Don't be afraid of subtitles........ its worth...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>478 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  70.83333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": "            Word  Word Frequency   P(Word)  Positive Sentiment Word Frequency  \\\n0             it             134  0.017503                               70.0   \n1     represents               1  0.000131                                1.0   \n2            the             241  0.031479                              136.0   \n3         humour               2  0.000261                                2.0   \n4       northern               1  0.000131                                1.0   \n...          ...             ...       ...                                ...   \n2388    interest               1  0.000131                                1.0   \n2389       alert               1  0.000131                                1.0   \n2390     therapy               1  0.000131                                1.0   \n2391   subtitles               1  0.000131                                1.0   \n2392    aversion               1  0.000131                                1.0   \n\n      P(Sentiment = Positive)  P(Word | Sentiment = Positive)  \\\n0                    0.539749                        0.271318   \n1                    0.539749                        0.003876   \n2                    0.539749                        0.527132   \n3                    0.539749                        0.007752   \n4                    0.539749                        0.003876   \n...                       ...                             ...   \n2388                 0.539749                        0.003876   \n2389                 0.539749                        0.003876   \n2390                 0.539749                        0.003876   \n2391                 0.539749                        0.003876   \n2392                 0.539749                        0.003876   \n\n      Negative Sentiment Word Frequency  P(Sentiment = Negative)  \\\n0                                  64.0                 0.460251   \n1                                   NaN                 0.460251   \n2                                 105.0                 0.460251   \n3                                   NaN                 0.460251   \n4                                   NaN                 0.460251   \n...                                 ...                      ...   \n2388                                NaN                 0.460251   \n2389                                NaN                 0.460251   \n2390                                NaN                 0.460251   \n2391                                NaN                 0.460251   \n2392                                NaN                 0.460251   \n\n      P(Word | Sentiment = Negative)  \n0                           0.290909  \n1                                NaN  \n2                           0.477273  \n3                                NaN  \n4                                NaN  \n...                              ...  \n2388                             NaN  \n2389                             NaN  \n2390                             NaN  \n2391                             NaN  \n2392                             NaN  \n\n[2393 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Word Frequency</th>\n      <th>P(Word)</th>\n      <th>Positive Sentiment Word Frequency</th>\n      <th>P(Sentiment = Positive)</th>\n      <th>P(Word | Sentiment = Positive)</th>\n      <th>Negative Sentiment Word Frequency</th>\n      <th>P(Sentiment = Negative)</th>\n      <th>P(Word | Sentiment = Negative)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>it</td>\n      <td>134</td>\n      <td>0.017503</td>\n      <td>70.0</td>\n      <td>0.539749</td>\n      <td>0.271318</td>\n      <td>64.0</td>\n      <td>0.460251</td>\n      <td>0.290909</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>represents</td>\n      <td>1</td>\n      <td>0.000131</td>\n      <td>1.0</td>\n      <td>0.539749</td>\n      <td>0.003876</td>\n      <td>NaN</td>\n      <td>0.460251</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>the</td>\n      <td>241</td>\n      <td>0.031479</td>\n      <td>136.0</td>\n      <td>0.539749</td>\n      <td>0.527132</td>\n      <td>105.0</td>\n      <td>0.460251</td>\n      <td>0.477273</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>humour</td>\n      <td>2</td>\n      <td>0.000261</td>\n      <td>2.0</td>\n      <td>0.539749</td>\n      <td>0.007752</td>\n      <td>NaN</td>\n      <td>0.460251</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>northern</td>\n      <td>1</td>\n      <td>0.000131</td>\n      <td>1.0</td>\n      <td>0.539749</td>\n      <td>0.003876</td>\n      <td>NaN</td>\n      <td>0.460251</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2388</th>\n      <td>interest</td>\n      <td>1</td>\n      <td>0.000131</td>\n      <td>1.0</td>\n      <td>0.539749</td>\n      <td>0.003876</td>\n      <td>NaN</td>\n      <td>0.460251</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2389</th>\n      <td>alert</td>\n      <td>1</td>\n      <td>0.000131</td>\n      <td>1.0</td>\n      <td>0.539749</td>\n      <td>0.003876</td>\n      <td>NaN</td>\n      <td>0.460251</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2390</th>\n      <td>therapy</td>\n      <td>1</td>\n      <td>0.000131</td>\n      <td>1.0</td>\n      <td>0.539749</td>\n      <td>0.003876</td>\n      <td>NaN</td>\n      <td>0.460251</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2391</th>\n      <td>subtitles</td>\n      <td>1</td>\n      <td>0.000131</td>\n      <td>1.0</td>\n      <td>0.539749</td>\n      <td>0.003876</td>\n      <td>NaN</td>\n      <td>0.460251</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2392</th>\n      <td>aversion</td>\n      <td>1</td>\n      <td>0.000131</td>\n      <td>1.0</td>\n      <td>0.539749</td>\n      <td>0.003876</td>\n      <td>NaN</td>\n      <td>0.460251</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>2393 rows Ã— 9 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------Fold 3---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                           IMDB Review  Sentiment\n2    The result is a film that just don't look righ...          0\n3                              Highly unrecommended.            0\n4    Technically, the film is well made with impres...          1\n5    There is no plot here to keep you going in the...          0\n6       Oh yeah, and the storyline was pathetic too.            0\n..                                                 ...        ...\n586             This movie has a cutting edge to it.            1\n589  1/10 - and only because there is no setting fo...          0\n590        I'll even say it again Â– this is torture.            0\n596  It's the one movie that never ceases to intere...          1\n597  Don't be afraid of subtitles........ its worth...          1\n\n[478 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IMDB Review</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>The result is a film that just don't look righ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Highly unrecommended.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Technically, the film is well made with impres...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>There is no plot here to keep you going in the...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Oh yeah, and the storyline was pathetic too.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>586</th>\n      <td>This movie has a cutting edge to it.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>589</th>\n      <td>1/10 - and only because there is no setting fo...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>590</th>\n      <td>I'll even say it again Â– this is torture.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>596</th>\n      <td>It's the one movie that never ceases to intere...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>597</th>\n      <td>Don't be afraid of subtitles........ its worth...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>478 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  60.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "           Word  Word Frequency   P(Word)  Positive Sentiment Word Frequency  \\\n0         don't              14  0.001910                                3.0   \n1          look              13  0.001773                                7.0   \n2          just              33  0.004501                               12.0   \n3           the             239  0.032601                              135.0   \n4          film              68  0.009276                               46.0   \n...         ...             ...       ...                                ...   \n2272      alert               1  0.000136                                1.0   \n2273     afraid               1  0.000136                                1.0   \n2274    therapy               1  0.000136                                1.0   \n2275  subtitles               1  0.000136                                1.0   \n2276   aversion               1  0.000136                                1.0   \n\n      P(Sentiment = Positive)  P(Word | Sentiment = Positive)  \\\n0                    0.539749                        0.011628   \n1                    0.539749                        0.027132   \n2                    0.539749                        0.046512   \n3                    0.539749                        0.523256   \n4                    0.539749                        0.178295   \n...                       ...                             ...   \n2272                 0.539749                        0.003876   \n2273                 0.539749                        0.003876   \n2274                 0.539749                        0.003876   \n2275                 0.539749                        0.003876   \n2276                 0.539749                        0.003876   \n\n      Negative Sentiment Word Frequency  P(Sentiment = Negative)  \\\n0                                  11.0                 0.460251   \n1                                   6.0                 0.460251   \n2                                  21.0                 0.460251   \n3                                 104.0                 0.460251   \n4                                  22.0                 0.460251   \n...                                 ...                      ...   \n2272                                NaN                 0.460251   \n2273                                NaN                 0.460251   \n2274                                NaN                 0.460251   \n2275                                NaN                 0.460251   \n2276                                NaN                 0.460251   \n\n      P(Word | Sentiment = Negative)  \n0                           0.050000  \n1                           0.027273  \n2                           0.095455  \n3                           0.472727  \n4                           0.100000  \n...                              ...  \n2272                             NaN  \n2273                             NaN  \n2274                             NaN  \n2275                             NaN  \n2276                             NaN  \n\n[2277 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Word Frequency</th>\n      <th>P(Word)</th>\n      <th>Positive Sentiment Word Frequency</th>\n      <th>P(Sentiment = Positive)</th>\n      <th>P(Word | Sentiment = Positive)</th>\n      <th>Negative Sentiment Word Frequency</th>\n      <th>P(Sentiment = Negative)</th>\n      <th>P(Word | Sentiment = Negative)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>don't</td>\n      <td>14</td>\n      <td>0.001910</td>\n      <td>3.0</td>\n      <td>0.539749</td>\n      <td>0.011628</td>\n      <td>11.0</td>\n      <td>0.460251</td>\n      <td>0.050000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>look</td>\n      <td>13</td>\n      <td>0.001773</td>\n      <td>7.0</td>\n      <td>0.539749</td>\n      <td>0.027132</td>\n      <td>6.0</td>\n      <td>0.460251</td>\n      <td>0.027273</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>just</td>\n      <td>33</td>\n      <td>0.004501</td>\n      <td>12.0</td>\n      <td>0.539749</td>\n      <td>0.046512</td>\n      <td>21.0</td>\n      <td>0.460251</td>\n      <td>0.095455</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>the</td>\n      <td>239</td>\n      <td>0.032601</td>\n      <td>135.0</td>\n      <td>0.539749</td>\n      <td>0.523256</td>\n      <td>104.0</td>\n      <td>0.460251</td>\n      <td>0.472727</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>film</td>\n      <td>68</td>\n      <td>0.009276</td>\n      <td>46.0</td>\n      <td>0.539749</td>\n      <td>0.178295</td>\n      <td>22.0</td>\n      <td>0.460251</td>\n      <td>0.100000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2272</th>\n      <td>alert</td>\n      <td>1</td>\n      <td>0.000136</td>\n      <td>1.0</td>\n      <td>0.539749</td>\n      <td>0.003876</td>\n      <td>NaN</td>\n      <td>0.460251</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2273</th>\n      <td>afraid</td>\n      <td>1</td>\n      <td>0.000136</td>\n      <td>1.0</td>\n      <td>0.539749</td>\n      <td>0.003876</td>\n      <td>NaN</td>\n      <td>0.460251</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2274</th>\n      <td>therapy</td>\n      <td>1</td>\n      <td>0.000136</td>\n      <td>1.0</td>\n      <td>0.539749</td>\n      <td>0.003876</td>\n      <td>NaN</td>\n      <td>0.460251</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2275</th>\n      <td>subtitles</td>\n      <td>1</td>\n      <td>0.000136</td>\n      <td>1.0</td>\n      <td>0.539749</td>\n      <td>0.003876</td>\n      <td>NaN</td>\n      <td>0.460251</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2276</th>\n      <td>aversion</td>\n      <td>1</td>\n      <td>0.000136</td>\n      <td>1.0</td>\n      <td>0.539749</td>\n      <td>0.003876</td>\n      <td>NaN</td>\n      <td>0.460251</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>2277 rows Ã— 9 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------Fold 4---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                           IMDB Review  Sentiment\n0    It has northern humour and positive about the ...          1\n1               But it is entertaining, nonetheless.            1\n2    The result is a film that just don't look righ...          0\n3                              Highly unrecommended.            0\n5    There is no plot here to keep you going in the...          0\n..                                                 ...        ...\n591  Judith Light is one of my favorite actresses a...          1\n592  But it picked up speed and got right to the po...          1\n593  I am a fan of his ... This movie sucked really...          0\n594                     Nothing at all to recommend.            0\n595                            It is a true classic.            1\n\n[479 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IMDB Review</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>It has northern humour and positive about the ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>But it is entertaining, nonetheless.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The result is a film that just don't look righ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Highly unrecommended.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>There is no plot here to keep you going in the...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>591</th>\n      <td>Judith Light is one of my favorite actresses a...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>592</th>\n      <td>But it picked up speed and got right to the po...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>593</th>\n      <td>I am a fan of his ... This movie sucked really...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>594</th>\n      <td>Nothing at all to recommend.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>595</th>\n      <td>It is a true classic.</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>479 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  55.46218487394958\n"
     ]
    },
    {
     "data": {
      "text/plain": "            Word  Word Frequency   P(Word)  Positive Sentiment Word Frequency  \\\n0             it             141  0.018340                               74.0   \n1     represents               1  0.000130                                1.0   \n2            the             247  0.032128                              134.0   \n3         humour               2  0.000260                                2.0   \n4       northern               1  0.000130                                1.0   \n...          ...             ...       ...                                ...   \n2368     setting               1  0.000130                                NaN   \n2369    favorite               1  0.000130                                1.0   \n2370      judith               1  0.000130                                1.0   \n2371      picked               1  0.000130                                1.0   \n2372         fan               1  0.000130                                NaN   \n\n      P(Sentiment = Positive)  P(Word | Sentiment = Positive)  \\\n0                    0.509395                        0.303279   \n1                    0.509395                        0.004098   \n2                    0.509395                        0.549180   \n3                    0.509395                        0.008197   \n4                    0.509395                        0.004098   \n...                       ...                             ...   \n2368                 0.509395                             NaN   \n2369                 0.509395                        0.004098   \n2370                 0.509395                        0.004098   \n2371                 0.509395                        0.004098   \n2372                 0.509395                             NaN   \n\n      Negative Sentiment Word Frequency  P(Sentiment = Negative)  \\\n0                                  67.0                 0.490605   \n1                                   NaN                 0.490605   \n2                                 113.0                 0.490605   \n3                                   NaN                 0.490605   \n4                                   NaN                 0.490605   \n...                                 ...                      ...   \n2368                                1.0                 0.490605   \n2369                                NaN                 0.490605   \n2370                                NaN                 0.490605   \n2371                                NaN                 0.490605   \n2372                                1.0                 0.490605   \n\n      P(Word | Sentiment = Negative)  \n0                           0.285106  \n1                                NaN  \n2                           0.480851  \n3                                NaN  \n4                                NaN  \n...                              ...  \n2368                        0.004255  \n2369                             NaN  \n2370                             NaN  \n2371                             NaN  \n2372                        0.004255  \n\n[2373 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Word Frequency</th>\n      <th>P(Word)</th>\n      <th>Positive Sentiment Word Frequency</th>\n      <th>P(Sentiment = Positive)</th>\n      <th>P(Word | Sentiment = Positive)</th>\n      <th>Negative Sentiment Word Frequency</th>\n      <th>P(Sentiment = Negative)</th>\n      <th>P(Word | Sentiment = Negative)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>it</td>\n      <td>141</td>\n      <td>0.018340</td>\n      <td>74.0</td>\n      <td>0.509395</td>\n      <td>0.303279</td>\n      <td>67.0</td>\n      <td>0.490605</td>\n      <td>0.285106</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>represents</td>\n      <td>1</td>\n      <td>0.000130</td>\n      <td>1.0</td>\n      <td>0.509395</td>\n      <td>0.004098</td>\n      <td>NaN</td>\n      <td>0.490605</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>the</td>\n      <td>247</td>\n      <td>0.032128</td>\n      <td>134.0</td>\n      <td>0.509395</td>\n      <td>0.549180</td>\n      <td>113.0</td>\n      <td>0.490605</td>\n      <td>0.480851</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>humour</td>\n      <td>2</td>\n      <td>0.000260</td>\n      <td>2.0</td>\n      <td>0.509395</td>\n      <td>0.008197</td>\n      <td>NaN</td>\n      <td>0.490605</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>northern</td>\n      <td>1</td>\n      <td>0.000130</td>\n      <td>1.0</td>\n      <td>0.509395</td>\n      <td>0.004098</td>\n      <td>NaN</td>\n      <td>0.490605</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2368</th>\n      <td>setting</td>\n      <td>1</td>\n      <td>0.000130</td>\n      <td>NaN</td>\n      <td>0.509395</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.490605</td>\n      <td>0.004255</td>\n    </tr>\n    <tr>\n      <th>2369</th>\n      <td>favorite</td>\n      <td>1</td>\n      <td>0.000130</td>\n      <td>1.0</td>\n      <td>0.509395</td>\n      <td>0.004098</td>\n      <td>NaN</td>\n      <td>0.490605</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2370</th>\n      <td>judith</td>\n      <td>1</td>\n      <td>0.000130</td>\n      <td>1.0</td>\n      <td>0.509395</td>\n      <td>0.004098</td>\n      <td>NaN</td>\n      <td>0.490605</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2371</th>\n      <td>picked</td>\n      <td>1</td>\n      <td>0.000130</td>\n      <td>1.0</td>\n      <td>0.509395</td>\n      <td>0.004098</td>\n      <td>NaN</td>\n      <td>0.490605</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2372</th>\n      <td>fan</td>\n      <td>1</td>\n      <td>0.000130</td>\n      <td>NaN</td>\n      <td>0.509395</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.490605</td>\n      <td>0.004255</td>\n    </tr>\n  </tbody>\n</table>\n<p>2373 rows Ã— 9 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------Fold 5---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                           IMDB Review  Sentiment\n0    It has northern humour and positive about the ...          1\n1               But it is entertaining, nonetheless.            1\n2    The result is a film that just don't look righ...          0\n4    Technically, the film is well made with impres...          1\n5    There is no plot here to keep you going in the...          0\n..                                                 ...        ...\n593  I am a fan of his ... This movie sucked really...          0\n594                     Nothing at all to recommend.            0\n595                            It is a true classic.            1\n596  It's the one movie that never ceases to intere...          1\n597  Don't be afraid of subtitles........ its worth...          1\n\n[479 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IMDB Review</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>It has northern humour and positive about the ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>But it is entertaining, nonetheless.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The result is a film that just don't look righ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Technically, the film is well made with impres...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>There is no plot here to keep you going in the...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>593</th>\n      <td>I am a fan of his ... This movie sucked really...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>594</th>\n      <td>Nothing at all to recommend.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>595</th>\n      <td>It is a true classic.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>596</th>\n      <td>It's the one movie that never ceases to intere...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>597</th>\n      <td>Don't be afraid of subtitles........ its worth...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>479 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  65.54621848739495\n"
     ]
    },
    {
     "data": {
      "text/plain": "            Word  Word Frequency   P(Word)  Positive Sentiment Word Frequency  \\\n0             it             131  0.017894                               75.0   \n1     represents               1  0.000137                                1.0   \n2            the             247  0.033739                              140.0   \n3         humour               2  0.000273                                2.0   \n4       northern               1  0.000137                                1.0   \n...          ...             ...       ...                                ...   \n2273      ceases               1  0.000137                                1.0   \n2274       alert               1  0.000137                                1.0   \n2275     therapy               1  0.000137                                1.0   \n2276   subtitles               1  0.000137                                1.0   \n2277    aversion               1  0.000137                                1.0   \n\n      P(Sentiment = Positive)  P(Word | Sentiment = Positive)  \\\n0                    0.555324                        0.281955   \n1                    0.555324                        0.003759   \n2                    0.555324                        0.526316   \n3                    0.555324                        0.007519   \n4                    0.555324                        0.003759   \n...                       ...                             ...   \n2273                 0.555324                        0.003759   \n2274                 0.555324                        0.003759   \n2275                 0.555324                        0.003759   \n2276                 0.555324                        0.003759   \n2277                 0.555324                        0.003759   \n\n      Negative Sentiment Word Frequency  P(Sentiment = Negative)  \\\n0                                  56.0                 0.444676   \n1                                   NaN                 0.444676   \n2                                 107.0                 0.444676   \n3                                   NaN                 0.444676   \n4                                   NaN                 0.444676   \n...                                 ...                      ...   \n2273                                NaN                 0.444676   \n2274                                NaN                 0.444676   \n2275                                NaN                 0.444676   \n2276                                NaN                 0.444676   \n2277                                NaN                 0.444676   \n\n      P(Word | Sentiment = Negative)  \n0                           0.262911  \n1                                NaN  \n2                           0.502347  \n3                                NaN  \n4                                NaN  \n...                              ...  \n2273                             NaN  \n2274                             NaN  \n2275                             NaN  \n2276                             NaN  \n2277                             NaN  \n\n[2278 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Word Frequency</th>\n      <th>P(Word)</th>\n      <th>Positive Sentiment Word Frequency</th>\n      <th>P(Sentiment = Positive)</th>\n      <th>P(Word | Sentiment = Positive)</th>\n      <th>Negative Sentiment Word Frequency</th>\n      <th>P(Sentiment = Negative)</th>\n      <th>P(Word | Sentiment = Negative)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>it</td>\n      <td>131</td>\n      <td>0.017894</td>\n      <td>75.0</td>\n      <td>0.555324</td>\n      <td>0.281955</td>\n      <td>56.0</td>\n      <td>0.444676</td>\n      <td>0.262911</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>represents</td>\n      <td>1</td>\n      <td>0.000137</td>\n      <td>1.0</td>\n      <td>0.555324</td>\n      <td>0.003759</td>\n      <td>NaN</td>\n      <td>0.444676</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>the</td>\n      <td>247</td>\n      <td>0.033739</td>\n      <td>140.0</td>\n      <td>0.555324</td>\n      <td>0.526316</td>\n      <td>107.0</td>\n      <td>0.444676</td>\n      <td>0.502347</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>humour</td>\n      <td>2</td>\n      <td>0.000273</td>\n      <td>2.0</td>\n      <td>0.555324</td>\n      <td>0.007519</td>\n      <td>NaN</td>\n      <td>0.444676</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>northern</td>\n      <td>1</td>\n      <td>0.000137</td>\n      <td>1.0</td>\n      <td>0.555324</td>\n      <td>0.003759</td>\n      <td>NaN</td>\n      <td>0.444676</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2273</th>\n      <td>ceases</td>\n      <td>1</td>\n      <td>0.000137</td>\n      <td>1.0</td>\n      <td>0.555324</td>\n      <td>0.003759</td>\n      <td>NaN</td>\n      <td>0.444676</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2274</th>\n      <td>alert</td>\n      <td>1</td>\n      <td>0.000137</td>\n      <td>1.0</td>\n      <td>0.555324</td>\n      <td>0.003759</td>\n      <td>NaN</td>\n      <td>0.444676</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2275</th>\n      <td>therapy</td>\n      <td>1</td>\n      <td>0.000137</td>\n      <td>1.0</td>\n      <td>0.555324</td>\n      <td>0.003759</td>\n      <td>NaN</td>\n      <td>0.444676</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2276</th>\n      <td>subtitles</td>\n      <td>1</td>\n      <td>0.000137</td>\n      <td>1.0</td>\n      <td>0.555324</td>\n      <td>0.003759</td>\n      <td>NaN</td>\n      <td>0.444676</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2277</th>\n      <td>aversion</td>\n      <td>1</td>\n      <td>0.000137</td>\n      <td>1.0</td>\n      <td>0.555324</td>\n      <td>0.003759</td>\n      <td>NaN</td>\n      <td>0.444676</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>2278 rows Ã— 9 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "            Word  Word Frequency   P(Word)  Positive Sentiment Word Frequency  \\\n0             it             134  0.017503                               70.0   \n1     represents               1  0.000131                                1.0   \n2            the             241  0.031479                              136.0   \n3         humour               2  0.000261                                2.0   \n4       northern               1  0.000131                                1.0   \n...          ...             ...       ...                                ...   \n2388    interest               1  0.000131                                1.0   \n2389       alert               1  0.000131                                1.0   \n2390     therapy               1  0.000131                                1.0   \n2391   subtitles               1  0.000131                                1.0   \n2392    aversion               1  0.000131                                1.0   \n\n      P(Sentiment = Positive)  P(Word | Sentiment = Positive)  \\\n0                    0.539749                        0.271318   \n1                    0.539749                        0.003876   \n2                    0.539749                        0.527132   \n3                    0.539749                        0.007752   \n4                    0.539749                        0.003876   \n...                       ...                             ...   \n2388                 0.539749                        0.003876   \n2389                 0.539749                        0.003876   \n2390                 0.539749                        0.003876   \n2391                 0.539749                        0.003876   \n2392                 0.539749                        0.003876   \n\n      Negative Sentiment Word Frequency  P(Sentiment = Negative)  \\\n0                                  64.0                 0.460251   \n1                                   NaN                 0.460251   \n2                                 105.0                 0.460251   \n3                                   NaN                 0.460251   \n4                                   NaN                 0.460251   \n...                                 ...                      ...   \n2388                                NaN                 0.460251   \n2389                                NaN                 0.460251   \n2390                                NaN                 0.460251   \n2391                                NaN                 0.460251   \n2392                                NaN                 0.460251   \n\n      P(Word | Sentiment = Negative)  \n0                           0.290909  \n1                                NaN  \n2                           0.477273  \n3                                NaN  \n4                                NaN  \n...                              ...  \n2388                             NaN  \n2389                             NaN  \n2390                             NaN  \n2391                             NaN  \n2392                             NaN  \n\n[2393 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Word Frequency</th>\n      <th>P(Word)</th>\n      <th>Positive Sentiment Word Frequency</th>\n      <th>P(Sentiment = Positive)</th>\n      <th>P(Word | Sentiment = Positive)</th>\n      <th>Negative Sentiment Word Frequency</th>\n      <th>P(Sentiment = Negative)</th>\n      <th>P(Word | Sentiment = Negative)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>it</td>\n      <td>134</td>\n      <td>0.017503</td>\n      <td>70.0</td>\n      <td>0.539749</td>\n      <td>0.271318</td>\n      <td>64.0</td>\n      <td>0.460251</td>\n      <td>0.290909</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>represents</td>\n      <td>1</td>\n      <td>0.000131</td>\n      <td>1.0</td>\n      <td>0.539749</td>\n      <td>0.003876</td>\n      <td>NaN</td>\n      <td>0.460251</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>the</td>\n      <td>241</td>\n      <td>0.031479</td>\n      <td>136.0</td>\n      <td>0.539749</td>\n      <td>0.527132</td>\n      <td>105.0</td>\n      <td>0.460251</td>\n      <td>0.477273</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>humour</td>\n      <td>2</td>\n      <td>0.000261</td>\n      <td>2.0</td>\n      <td>0.539749</td>\n      <td>0.007752</td>\n      <td>NaN</td>\n      <td>0.460251</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>northern</td>\n      <td>1</td>\n      <td>0.000131</td>\n      <td>1.0</td>\n      <td>0.539749</td>\n      <td>0.003876</td>\n      <td>NaN</td>\n      <td>0.460251</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2388</th>\n      <td>interest</td>\n      <td>1</td>\n      <td>0.000131</td>\n      <td>1.0</td>\n      <td>0.539749</td>\n      <td>0.003876</td>\n      <td>NaN</td>\n      <td>0.460251</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2389</th>\n      <td>alert</td>\n      <td>1</td>\n      <td>0.000131</td>\n      <td>1.0</td>\n      <td>0.539749</td>\n      <td>0.003876</td>\n      <td>NaN</td>\n      <td>0.460251</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2390</th>\n      <td>therapy</td>\n      <td>1</td>\n      <td>0.000131</td>\n      <td>1.0</td>\n      <td>0.539749</td>\n      <td>0.003876</td>\n      <td>NaN</td>\n      <td>0.460251</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2391</th>\n      <td>subtitles</td>\n      <td>1</td>\n      <td>0.000131</td>\n      <td>1.0</td>\n      <td>0.539749</td>\n      <td>0.003876</td>\n      <td>NaN</td>\n      <td>0.460251</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2392</th>\n      <td>aversion</td>\n      <td>1</td>\n      <td>0.000131</td>\n      <td>1.0</td>\n      <td>0.539749</td>\n      <td>0.003876</td>\n      <td>NaN</td>\n      <td>0.460251</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>2393 rows Ã— 9 columns</p>\n</div>"
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def five_fold_cross_validation(data_frame: pd.DataFrame, smoothening: bool):\n",
    "    kf = KFold(n_splits=k, shuffle=True)\n",
    "    train_folds = kf.split(data_frame)\n",
    "    accuracies = []\n",
    "    max_accuracy_naive_bayes_parameters = pd.DataFrame()\n",
    "    for (train_training, train_testing), index in zip(train_folds, range(5)):\n",
    "        print(f\"---------------------------Fold {index + 1}---------------------------------\")\n",
    "        display(train.loc[train_training])\n",
    "        trained_parameters = generate_naive_bayes_parameters(train.loc[train_training], smoothening)\n",
    "        accuracy = predict_calculate_accuracy(train.loc[train_testing], trained_parameters)\n",
    "        accuracies.append(accuracy)\n",
    "        max_accuracy_naive_bayes_parameters = trained_parameters if max(\n",
    "            accuracies) == accuracy else max_accuracy_naive_bayes_parameters\n",
    "        display(trained_parameters)\n",
    "    return max_accuracy_naive_bayes_parameters\n",
    "\n",
    "\n",
    "vocabulary = five_fold_cross_validation(train, False)\n",
    "vocabulary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-249-198896de2224>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame[\"P(Sentiment = Positive | Sentence)\"] = data_frame[\"IMDB Review\"].apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  93.1438127090301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-249-198896de2224>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame[\"P(Sentiment = Negative | Sentence)\"] = data_frame[\"IMDB Review\"].apply(\n",
      "<ipython-input-249-198896de2224>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame[\"Predicted sentiment\"] = data_frame[\"P(Sentiment = Positive | Sentence)\"] > data_frame[\n"
     ]
    },
    {
     "data": {
      "text/plain": "93.1438127090301"
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_calculate_accuracy(train, vocabulary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  72.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "72.0"
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_calculate_accuracy(dev, vocabulary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  68.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "68.0"
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_calculate_accuracy(test, vocabulary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Most Useful words before Smoothing\n",
    "\n",
    "This is found by ordering the vocabulary in descending order of **P(Word | Sentiment)** for each negative and positive\n",
    "sentiments"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Useful Positive sentiment words:\n"
     ]
    },
    {
     "data": {
      "text/plain": "      Word  Word Frequency   P(Word)  Positive Sentiment Word Frequency  \\\n2      the             241  0.031479                              136.0   \n6      and             171  0.022335                              117.0   \n17       a             172  0.022466                              106.0   \n75      of             157  0.020507                               93.0   \n10      is             153  0.019984                               82.0   \n69    this             142  0.018548                               79.0   \n0       it             134  0.017503                               70.0   \n48      to             120  0.015674                               68.0   \n148      i             114  0.014890                               63.0   \n37    film              79  0.010319                               52.0   \n47      in              94  0.012278                               52.0   \n99   movie              81  0.010580                               47.0   \n60     was              83  0.010841                               43.0   \n44    that              75  0.009796                               38.0   \n33    with              49  0.006400                               32.0   \n84     for              55  0.007184                               28.0   \n12     but              43  0.005617                               28.0   \n106    are              43  0.005617                               28.0   \n62      as              38  0.004963                               24.0   \n34    good              31  0.004049                               23.0   \n\n     P(Sentiment = Positive)  P(Word | Sentiment = Positive)  \\\n2                   0.539749                        0.527132   \n6                   0.539749                        0.453488   \n17                  0.539749                        0.410853   \n75                  0.539749                        0.360465   \n10                  0.539749                        0.317829   \n69                  0.539749                        0.306202   \n0                   0.539749                        0.271318   \n48                  0.539749                        0.263566   \n148                 0.539749                        0.244186   \n37                  0.539749                        0.201550   \n47                  0.539749                        0.201550   \n99                  0.539749                        0.182171   \n60                  0.539749                        0.166667   \n44                  0.539749                        0.147287   \n33                  0.539749                        0.124031   \n84                  0.539749                        0.108527   \n12                  0.539749                        0.108527   \n106                 0.539749                        0.108527   \n62                  0.539749                        0.093023   \n34                  0.539749                        0.089147   \n\n     Negative Sentiment Word Frequency  P(Sentiment = Negative)  \\\n2                                105.0                 0.460251   \n6                                 54.0                 0.460251   \n17                                66.0                 0.460251   \n75                                64.0                 0.460251   \n10                                71.0                 0.460251   \n69                                63.0                 0.460251   \n0                                 64.0                 0.460251   \n48                                52.0                 0.460251   \n148                               51.0                 0.460251   \n37                                27.0                 0.460251   \n47                                42.0                 0.460251   \n99                                34.0                 0.460251   \n60                                40.0                 0.460251   \n44                                37.0                 0.460251   \n33                                17.0                 0.460251   \n84                                27.0                 0.460251   \n12                                15.0                 0.460251   \n106                               15.0                 0.460251   \n62                                14.0                 0.460251   \n34                                 8.0                 0.460251   \n\n     P(Word | Sentiment = Negative)  \n2                          0.477273  \n6                          0.245455  \n17                         0.300000  \n75                         0.290909  \n10                         0.322727  \n69                         0.286364  \n0                          0.290909  \n48                         0.236364  \n148                        0.231818  \n37                         0.122727  \n47                         0.190909  \n99                         0.154545  \n60                         0.181818  \n44                         0.168182  \n33                         0.077273  \n84                         0.122727  \n12                         0.068182  \n106                        0.068182  \n62                         0.063636  \n34                         0.036364  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Word Frequency</th>\n      <th>P(Word)</th>\n      <th>Positive Sentiment Word Frequency</th>\n      <th>P(Sentiment = Positive)</th>\n      <th>P(Word | Sentiment = Positive)</th>\n      <th>Negative Sentiment Word Frequency</th>\n      <th>P(Sentiment = Negative)</th>\n      <th>P(Word | Sentiment = Negative)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>the</td>\n      <td>241</td>\n      <td>0.031479</td>\n      <td>136.0</td>\n      <td>0.539749</td>\n      <td>0.527132</td>\n      <td>105.0</td>\n      <td>0.460251</td>\n      <td>0.477273</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>and</td>\n      <td>171</td>\n      <td>0.022335</td>\n      <td>117.0</td>\n      <td>0.539749</td>\n      <td>0.453488</td>\n      <td>54.0</td>\n      <td>0.460251</td>\n      <td>0.245455</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>a</td>\n      <td>172</td>\n      <td>0.022466</td>\n      <td>106.0</td>\n      <td>0.539749</td>\n      <td>0.410853</td>\n      <td>66.0</td>\n      <td>0.460251</td>\n      <td>0.300000</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>of</td>\n      <td>157</td>\n      <td>0.020507</td>\n      <td>93.0</td>\n      <td>0.539749</td>\n      <td>0.360465</td>\n      <td>64.0</td>\n      <td>0.460251</td>\n      <td>0.290909</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>is</td>\n      <td>153</td>\n      <td>0.019984</td>\n      <td>82.0</td>\n      <td>0.539749</td>\n      <td>0.317829</td>\n      <td>71.0</td>\n      <td>0.460251</td>\n      <td>0.322727</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>this</td>\n      <td>142</td>\n      <td>0.018548</td>\n      <td>79.0</td>\n      <td>0.539749</td>\n      <td>0.306202</td>\n      <td>63.0</td>\n      <td>0.460251</td>\n      <td>0.286364</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>it</td>\n      <td>134</td>\n      <td>0.017503</td>\n      <td>70.0</td>\n      <td>0.539749</td>\n      <td>0.271318</td>\n      <td>64.0</td>\n      <td>0.460251</td>\n      <td>0.290909</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>to</td>\n      <td>120</td>\n      <td>0.015674</td>\n      <td>68.0</td>\n      <td>0.539749</td>\n      <td>0.263566</td>\n      <td>52.0</td>\n      <td>0.460251</td>\n      <td>0.236364</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>i</td>\n      <td>114</td>\n      <td>0.014890</td>\n      <td>63.0</td>\n      <td>0.539749</td>\n      <td>0.244186</td>\n      <td>51.0</td>\n      <td>0.460251</td>\n      <td>0.231818</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>film</td>\n      <td>79</td>\n      <td>0.010319</td>\n      <td>52.0</td>\n      <td>0.539749</td>\n      <td>0.201550</td>\n      <td>27.0</td>\n      <td>0.460251</td>\n      <td>0.122727</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>in</td>\n      <td>94</td>\n      <td>0.012278</td>\n      <td>52.0</td>\n      <td>0.539749</td>\n      <td>0.201550</td>\n      <td>42.0</td>\n      <td>0.460251</td>\n      <td>0.190909</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>movie</td>\n      <td>81</td>\n      <td>0.010580</td>\n      <td>47.0</td>\n      <td>0.539749</td>\n      <td>0.182171</td>\n      <td>34.0</td>\n      <td>0.460251</td>\n      <td>0.154545</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>was</td>\n      <td>83</td>\n      <td>0.010841</td>\n      <td>43.0</td>\n      <td>0.539749</td>\n      <td>0.166667</td>\n      <td>40.0</td>\n      <td>0.460251</td>\n      <td>0.181818</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>that</td>\n      <td>75</td>\n      <td>0.009796</td>\n      <td>38.0</td>\n      <td>0.539749</td>\n      <td>0.147287</td>\n      <td>37.0</td>\n      <td>0.460251</td>\n      <td>0.168182</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>with</td>\n      <td>49</td>\n      <td>0.006400</td>\n      <td>32.0</td>\n      <td>0.539749</td>\n      <td>0.124031</td>\n      <td>17.0</td>\n      <td>0.460251</td>\n      <td>0.077273</td>\n    </tr>\n    <tr>\n      <th>84</th>\n      <td>for</td>\n      <td>55</td>\n      <td>0.007184</td>\n      <td>28.0</td>\n      <td>0.539749</td>\n      <td>0.108527</td>\n      <td>27.0</td>\n      <td>0.460251</td>\n      <td>0.122727</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>but</td>\n      <td>43</td>\n      <td>0.005617</td>\n      <td>28.0</td>\n      <td>0.539749</td>\n      <td>0.108527</td>\n      <td>15.0</td>\n      <td>0.460251</td>\n      <td>0.068182</td>\n    </tr>\n    <tr>\n      <th>106</th>\n      <td>are</td>\n      <td>43</td>\n      <td>0.005617</td>\n      <td>28.0</td>\n      <td>0.539749</td>\n      <td>0.108527</td>\n      <td>15.0</td>\n      <td>0.460251</td>\n      <td>0.068182</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>as</td>\n      <td>38</td>\n      <td>0.004963</td>\n      <td>24.0</td>\n      <td>0.539749</td>\n      <td>0.093023</td>\n      <td>14.0</td>\n      <td>0.460251</td>\n      <td>0.063636</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>good</td>\n      <td>31</td>\n      <td>0.004049</td>\n      <td>23.0</td>\n      <td>0.539749</td>\n      <td>0.089147</td>\n      <td>8.0</td>\n      <td>0.460251</td>\n      <td>0.036364</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Most Useful Positive sentiment words:\")\n",
    "vocabulary.sort_values(\"P(Word | Sentiment = Positive)\", ascending=False)[:most_useful_limit]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Useful Negative sentiment words:\n"
     ]
    },
    {
     "data": {
      "text/plain": "      Word  Word Frequency   P(Word)  Positive Sentiment Word Frequency  \\\n2      the             241  0.031479                              136.0   \n10      is             153  0.019984                               82.0   \n17       a             172  0.022466                              106.0   \n0       it             134  0.017503                               70.0   \n75      of             157  0.020507                               93.0   \n69    this             142  0.018548                               79.0   \n6      and             171  0.022335                              117.0   \n48      to             120  0.015674                               68.0   \n148      i             114  0.014890                               63.0   \n47      in              94  0.012278                               52.0   \n60     was              83  0.010841                               43.0   \n44    that              75  0.009796                               38.0   \n99   movie              81  0.010580                               47.0   \n152    bad              30  0.003918                                2.0   \n84     for              55  0.007184                               28.0   \n37    film              79  0.010319                               52.0   \n166     on              40  0.005225                               17.0   \n363   just              34  0.004441                               11.0   \n209     so              36  0.004702                               14.0   \n122    all              37  0.004833                               15.0   \n\n     P(Sentiment = Positive)  P(Word | Sentiment = Positive)  \\\n2                   0.539749                        0.527132   \n10                  0.539749                        0.317829   \n17                  0.539749                        0.410853   \n0                   0.539749                        0.271318   \n75                  0.539749                        0.360465   \n69                  0.539749                        0.306202   \n6                   0.539749                        0.453488   \n48                  0.539749                        0.263566   \n148                 0.539749                        0.244186   \n47                  0.539749                        0.201550   \n60                  0.539749                        0.166667   \n44                  0.539749                        0.147287   \n99                  0.539749                        0.182171   \n152                 0.539749                        0.007752   \n84                  0.539749                        0.108527   \n37                  0.539749                        0.201550   \n166                 0.539749                        0.065891   \n363                 0.539749                        0.042636   \n209                 0.539749                        0.054264   \n122                 0.539749                        0.058140   \n\n     Negative Sentiment Word Frequency  P(Sentiment = Negative)  \\\n2                                105.0                 0.460251   \n10                                71.0                 0.460251   \n17                                66.0                 0.460251   \n0                                 64.0                 0.460251   \n75                                64.0                 0.460251   \n69                                63.0                 0.460251   \n6                                 54.0                 0.460251   \n48                                52.0                 0.460251   \n148                               51.0                 0.460251   \n47                                42.0                 0.460251   \n60                                40.0                 0.460251   \n44                                37.0                 0.460251   \n99                                34.0                 0.460251   \n152                               28.0                 0.460251   \n84                                27.0                 0.460251   \n37                                27.0                 0.460251   \n166                               23.0                 0.460251   \n363                               23.0                 0.460251   \n209                               22.0                 0.460251   \n122                               22.0                 0.460251   \n\n     P(Word | Sentiment = Negative)  \n2                          0.477273  \n10                         0.322727  \n17                         0.300000  \n0                          0.290909  \n75                         0.290909  \n69                         0.286364  \n6                          0.245455  \n48                         0.236364  \n148                        0.231818  \n47                         0.190909  \n60                         0.181818  \n44                         0.168182  \n99                         0.154545  \n152                        0.127273  \n84                         0.122727  \n37                         0.122727  \n166                        0.104545  \n363                        0.104545  \n209                        0.100000  \n122                        0.100000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Word Frequency</th>\n      <th>P(Word)</th>\n      <th>Positive Sentiment Word Frequency</th>\n      <th>P(Sentiment = Positive)</th>\n      <th>P(Word | Sentiment = Positive)</th>\n      <th>Negative Sentiment Word Frequency</th>\n      <th>P(Sentiment = Negative)</th>\n      <th>P(Word | Sentiment = Negative)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>the</td>\n      <td>241</td>\n      <td>0.031479</td>\n      <td>136.0</td>\n      <td>0.539749</td>\n      <td>0.527132</td>\n      <td>105.0</td>\n      <td>0.460251</td>\n      <td>0.477273</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>is</td>\n      <td>153</td>\n      <td>0.019984</td>\n      <td>82.0</td>\n      <td>0.539749</td>\n      <td>0.317829</td>\n      <td>71.0</td>\n      <td>0.460251</td>\n      <td>0.322727</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>a</td>\n      <td>172</td>\n      <td>0.022466</td>\n      <td>106.0</td>\n      <td>0.539749</td>\n      <td>0.410853</td>\n      <td>66.0</td>\n      <td>0.460251</td>\n      <td>0.300000</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>it</td>\n      <td>134</td>\n      <td>0.017503</td>\n      <td>70.0</td>\n      <td>0.539749</td>\n      <td>0.271318</td>\n      <td>64.0</td>\n      <td>0.460251</td>\n      <td>0.290909</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>of</td>\n      <td>157</td>\n      <td>0.020507</td>\n      <td>93.0</td>\n      <td>0.539749</td>\n      <td>0.360465</td>\n      <td>64.0</td>\n      <td>0.460251</td>\n      <td>0.290909</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>this</td>\n      <td>142</td>\n      <td>0.018548</td>\n      <td>79.0</td>\n      <td>0.539749</td>\n      <td>0.306202</td>\n      <td>63.0</td>\n      <td>0.460251</td>\n      <td>0.286364</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>and</td>\n      <td>171</td>\n      <td>0.022335</td>\n      <td>117.0</td>\n      <td>0.539749</td>\n      <td>0.453488</td>\n      <td>54.0</td>\n      <td>0.460251</td>\n      <td>0.245455</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>to</td>\n      <td>120</td>\n      <td>0.015674</td>\n      <td>68.0</td>\n      <td>0.539749</td>\n      <td>0.263566</td>\n      <td>52.0</td>\n      <td>0.460251</td>\n      <td>0.236364</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>i</td>\n      <td>114</td>\n      <td>0.014890</td>\n      <td>63.0</td>\n      <td>0.539749</td>\n      <td>0.244186</td>\n      <td>51.0</td>\n      <td>0.460251</td>\n      <td>0.231818</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>in</td>\n      <td>94</td>\n      <td>0.012278</td>\n      <td>52.0</td>\n      <td>0.539749</td>\n      <td>0.201550</td>\n      <td>42.0</td>\n      <td>0.460251</td>\n      <td>0.190909</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>was</td>\n      <td>83</td>\n      <td>0.010841</td>\n      <td>43.0</td>\n      <td>0.539749</td>\n      <td>0.166667</td>\n      <td>40.0</td>\n      <td>0.460251</td>\n      <td>0.181818</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>that</td>\n      <td>75</td>\n      <td>0.009796</td>\n      <td>38.0</td>\n      <td>0.539749</td>\n      <td>0.147287</td>\n      <td>37.0</td>\n      <td>0.460251</td>\n      <td>0.168182</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>movie</td>\n      <td>81</td>\n      <td>0.010580</td>\n      <td>47.0</td>\n      <td>0.539749</td>\n      <td>0.182171</td>\n      <td>34.0</td>\n      <td>0.460251</td>\n      <td>0.154545</td>\n    </tr>\n    <tr>\n      <th>152</th>\n      <td>bad</td>\n      <td>30</td>\n      <td>0.003918</td>\n      <td>2.0</td>\n      <td>0.539749</td>\n      <td>0.007752</td>\n      <td>28.0</td>\n      <td>0.460251</td>\n      <td>0.127273</td>\n    </tr>\n    <tr>\n      <th>84</th>\n      <td>for</td>\n      <td>55</td>\n      <td>0.007184</td>\n      <td>28.0</td>\n      <td>0.539749</td>\n      <td>0.108527</td>\n      <td>27.0</td>\n      <td>0.460251</td>\n      <td>0.122727</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>film</td>\n      <td>79</td>\n      <td>0.010319</td>\n      <td>52.0</td>\n      <td>0.539749</td>\n      <td>0.201550</td>\n      <td>27.0</td>\n      <td>0.460251</td>\n      <td>0.122727</td>\n    </tr>\n    <tr>\n      <th>166</th>\n      <td>on</td>\n      <td>40</td>\n      <td>0.005225</td>\n      <td>17.0</td>\n      <td>0.539749</td>\n      <td>0.065891</td>\n      <td>23.0</td>\n      <td>0.460251</td>\n      <td>0.104545</td>\n    </tr>\n    <tr>\n      <th>363</th>\n      <td>just</td>\n      <td>34</td>\n      <td>0.004441</td>\n      <td>11.0</td>\n      <td>0.539749</td>\n      <td>0.042636</td>\n      <td>23.0</td>\n      <td>0.460251</td>\n      <td>0.104545</td>\n    </tr>\n    <tr>\n      <th>209</th>\n      <td>so</td>\n      <td>36</td>\n      <td>0.004702</td>\n      <td>14.0</td>\n      <td>0.539749</td>\n      <td>0.054264</td>\n      <td>22.0</td>\n      <td>0.460251</td>\n      <td>0.100000</td>\n    </tr>\n    <tr>\n      <th>122</th>\n      <td>all</td>\n      <td>37</td>\n      <td>0.004833</td>\n      <td>15.0</td>\n      <td>0.539749</td>\n      <td>0.058140</td>\n      <td>22.0</td>\n      <td>0.460251</td>\n      <td>0.100000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Most Useful Negative sentiment words:\")\n",
    "vocabulary.sort_values(\"P(Word | Sentiment = Negative)\", ascending=False)[:most_useful_limit]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Smoothening\n",
    "\n",
    "Smoothening is done to compensate for unknown words. As all words can't be added to a dictionary and Naive Bayes is\n",
    "specialized to handle missing words.\n",
    "\n",
    "Smoothening is done by using the +1 method it is done in the get_naive_bayes_parameters function.\n",
    "\n",
    "All it does is adding +1 to the following:\n",
    "1. Word Frequency\n",
    "2. Positive Sentiment Word Frequency\n",
    "3. Negative Sentiment Word Frequency\n",
    "\n",
    "Also, +2 for Number of sentiments as these terms are in the denominator and needs to adhere and compensate for the +1 in\n",
    "the numerator so that the probability of most occurrence words will be less than 1\n",
    "1. Total words\n",
    "2. Total Positive sentiments\n",
    "3. Total Negative sentiments\n",
    "4. Total sentiments\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------Fold 1---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                           IMDB Review  Sentiment  \\\n0    It has northern humour and positive about the ...          1   \n1               But it is entertaining, nonetheless.            1   \n2    The result is a film that just don't look righ...          0   \n3                              Highly unrecommended.            0   \n4    Technically, the film is well made with impres...          1   \n..                                                 ...        ...   \n593  I am a fan of his ... This movie sucked really...          0   \n594                     Nothing at all to recommend.            0   \n595                            It is a true classic.            1   \n596  It's the one movie that never ceases to intere...          1   \n597  Don't be afraid of subtitles........ its worth...          1   \n\n     P(Sentiment = Positive | Sentence)  P(Sentiment = Negative | Sentence)  \\\n0                          2.471503e-17                        0.000000e+00   \n1                          2.276588e-07                        0.000000e+00   \n2                          1.782963e-12                        0.000000e+00   \n3                          0.000000e+00                        1.901864e-05   \n4                          4.910824e-57                        0.000000e+00   \n..                                  ...                                 ...   \n593                        0.000000e+00                        2.194147e-13   \n594                        4.093666e-08                        4.658780e-07   \n595                        2.298270e-06                        0.000000e+00   \n596                        2.023924e-36                        0.000000e+00   \n597                        4.206275e-22                        0.000000e+00   \n\n     Predicted sentiment  \n0                   True  \n1                   True  \n2                   True  \n3                  False  \n4                   True  \n..                   ...  \n593                False  \n594                False  \n595                 True  \n596                 True  \n597                 True  \n\n[478 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IMDB Review</th>\n      <th>Sentiment</th>\n      <th>P(Sentiment = Positive | Sentence)</th>\n      <th>P(Sentiment = Negative | Sentence)</th>\n      <th>Predicted sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>It has northern humour and positive about the ...</td>\n      <td>1</td>\n      <td>2.471503e-17</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>But it is entertaining, nonetheless.</td>\n      <td>1</td>\n      <td>2.276588e-07</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The result is a film that just don't look righ...</td>\n      <td>0</td>\n      <td>1.782963e-12</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Highly unrecommended.</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>1.901864e-05</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Technically, the film is well made with impres...</td>\n      <td>1</td>\n      <td>4.910824e-57</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>593</th>\n      <td>I am a fan of his ... This movie sucked really...</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>2.194147e-13</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>594</th>\n      <td>Nothing at all to recommend.</td>\n      <td>0</td>\n      <td>4.093666e-08</td>\n      <td>4.658780e-07</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>595</th>\n      <td>It is a true classic.</td>\n      <td>1</td>\n      <td>2.298270e-06</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>596</th>\n      <td>It's the one movie that never ceases to intere...</td>\n      <td>1</td>\n      <td>2.023924e-36</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>597</th>\n      <td>Don't be afraid of subtitles........ its worth...</td>\n      <td>1</td>\n      <td>4.206275e-22</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>478 rows Ã— 5 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  74.16666666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": "            Word  Word Frequency   P(Word)  Positive Sentiment Word Frequency  \\\n0             it             132  0.013408                               72.0   \n1     represents               2  0.000203                                2.0   \n2            the             241  0.024479                              136.0   \n3         humour               3  0.000305                                3.0   \n4       northern               2  0.000203                                2.0   \n...          ...             ...       ...                                ...   \n2347      ceases               2  0.000203                                2.0   \n2348       alert               2  0.000203                                2.0   \n2349     therapy               2  0.000203                                2.0   \n2350   subtitles               2  0.000203                                2.0   \n2351    aversion               2  0.000203                                2.0   \n\n      P(Sentiment = Positive)  P(Word | Sentiment = Positive)  \\\n0                    0.522917                        0.286853   \n1                    0.522917                        0.007968   \n2                    0.522917                        0.541833   \n3                    0.522917                        0.011952   \n4                    0.522917                        0.007968   \n...                       ...                             ...   \n2347                 0.522917                        0.007968   \n2348                 0.522917                        0.007968   \n2349                 0.522917                        0.007968   \n2350                 0.522917                        0.007968   \n2351                 0.522917                        0.007968   \n\n      Negative Sentiment Word Frequency  P(Sentiment = Negative)  \\\n0                                  61.0                  0.48125   \n1                                   1.0                  0.48125   \n2                                 106.0                  0.48125   \n3                                   1.0                  0.48125   \n4                                   1.0                  0.48125   \n...                                 ...                      ...   \n2347                                1.0                  0.48125   \n2348                                1.0                  0.48125   \n2349                                1.0                  0.48125   \n2350                                1.0                  0.48125   \n2351                                1.0                  0.48125   \n\n      P(Word | Sentiment = Negative)  \n0                           0.264069  \n1                           0.004329  \n2                           0.458874  \n3                           0.004329  \n4                           0.004329  \n...                              ...  \n2347                        0.004329  \n2348                        0.004329  \n2349                        0.004329  \n2350                        0.004329  \n2351                        0.004329  \n\n[2352 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Word Frequency</th>\n      <th>P(Word)</th>\n      <th>Positive Sentiment Word Frequency</th>\n      <th>P(Sentiment = Positive)</th>\n      <th>P(Word | Sentiment = Positive)</th>\n      <th>Negative Sentiment Word Frequency</th>\n      <th>P(Sentiment = Negative)</th>\n      <th>P(Word | Sentiment = Negative)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>it</td>\n      <td>132</td>\n      <td>0.013408</td>\n      <td>72.0</td>\n      <td>0.522917</td>\n      <td>0.286853</td>\n      <td>61.0</td>\n      <td>0.48125</td>\n      <td>0.264069</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>represents</td>\n      <td>2</td>\n      <td>0.000203</td>\n      <td>2.0</td>\n      <td>0.522917</td>\n      <td>0.007968</td>\n      <td>1.0</td>\n      <td>0.48125</td>\n      <td>0.004329</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>the</td>\n      <td>241</td>\n      <td>0.024479</td>\n      <td>136.0</td>\n      <td>0.522917</td>\n      <td>0.541833</td>\n      <td>106.0</td>\n      <td>0.48125</td>\n      <td>0.458874</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>humour</td>\n      <td>3</td>\n      <td>0.000305</td>\n      <td>3.0</td>\n      <td>0.522917</td>\n      <td>0.011952</td>\n      <td>1.0</td>\n      <td>0.48125</td>\n      <td>0.004329</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>northern</td>\n      <td>2</td>\n      <td>0.000203</td>\n      <td>2.0</td>\n      <td>0.522917</td>\n      <td>0.007968</td>\n      <td>1.0</td>\n      <td>0.48125</td>\n      <td>0.004329</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2347</th>\n      <td>ceases</td>\n      <td>2</td>\n      <td>0.000203</td>\n      <td>2.0</td>\n      <td>0.522917</td>\n      <td>0.007968</td>\n      <td>1.0</td>\n      <td>0.48125</td>\n      <td>0.004329</td>\n    </tr>\n    <tr>\n      <th>2348</th>\n      <td>alert</td>\n      <td>2</td>\n      <td>0.000203</td>\n      <td>2.0</td>\n      <td>0.522917</td>\n      <td>0.007968</td>\n      <td>1.0</td>\n      <td>0.48125</td>\n      <td>0.004329</td>\n    </tr>\n    <tr>\n      <th>2349</th>\n      <td>therapy</td>\n      <td>2</td>\n      <td>0.000203</td>\n      <td>2.0</td>\n      <td>0.522917</td>\n      <td>0.007968</td>\n      <td>1.0</td>\n      <td>0.48125</td>\n      <td>0.004329</td>\n    </tr>\n    <tr>\n      <th>2350</th>\n      <td>subtitles</td>\n      <td>2</td>\n      <td>0.000203</td>\n      <td>2.0</td>\n      <td>0.522917</td>\n      <td>0.007968</td>\n      <td>1.0</td>\n      <td>0.48125</td>\n      <td>0.004329</td>\n    </tr>\n    <tr>\n      <th>2351</th>\n      <td>aversion</td>\n      <td>2</td>\n      <td>0.000203</td>\n      <td>2.0</td>\n      <td>0.522917</td>\n      <td>0.007968</td>\n      <td>1.0</td>\n      <td>0.48125</td>\n      <td>0.004329</td>\n    </tr>\n  </tbody>\n</table>\n<p>2352 rows Ã— 9 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------Fold 2---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                           IMDB Review  Sentiment  \\\n0    It has northern humour and positive about the ...          1   \n1               But it is entertaining, nonetheless.            1   \n2    The result is a film that just don't look righ...          0   \n3                              Highly unrecommended.            0   \n4    Technically, the film is well made with impres...          1   \n..                                                 ...        ...   \n592  But it picked up speed and got right to the po...          1   \n593  I am a fan of his ... This movie sucked really...          0   \n594                     Nothing at all to recommend.            0   \n595                            It is a true classic.            1   \n596  It's the one movie that never ceases to intere...          1   \n\n     P(Sentiment = Positive | Sentence)  P(Sentiment = Negative | Sentence)  \\\n0                          2.471503e-17                        0.000000e+00   \n1                          2.276588e-07                        0.000000e+00   \n2                          1.782963e-12                        0.000000e+00   \n3                          0.000000e+00                        1.901864e-05   \n4                          4.910824e-57                        0.000000e+00   \n..                                  ...                                 ...   \n592                        8.691701e-16                        0.000000e+00   \n593                        0.000000e+00                        2.194147e-13   \n594                        4.093666e-08                        4.658780e-07   \n595                        2.298270e-06                        0.000000e+00   \n596                        2.023924e-36                        0.000000e+00   \n\n     Predicted sentiment  \n0                   True  \n1                   True  \n2                   True  \n3                  False  \n4                   True  \n..                   ...  \n592                 True  \n593                False  \n594                False  \n595                 True  \n596                 True  \n\n[478 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IMDB Review</th>\n      <th>Sentiment</th>\n      <th>P(Sentiment = Positive | Sentence)</th>\n      <th>P(Sentiment = Negative | Sentence)</th>\n      <th>Predicted sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>It has northern humour and positive about the ...</td>\n      <td>1</td>\n      <td>2.471503e-17</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>But it is entertaining, nonetheless.</td>\n      <td>1</td>\n      <td>2.276588e-07</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The result is a film that just don't look righ...</td>\n      <td>0</td>\n      <td>1.782963e-12</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Highly unrecommended.</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>1.901864e-05</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Technically, the film is well made with impres...</td>\n      <td>1</td>\n      <td>4.910824e-57</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>592</th>\n      <td>But it picked up speed and got right to the po...</td>\n      <td>1</td>\n      <td>8.691701e-16</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>593</th>\n      <td>I am a fan of his ... This movie sucked really...</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>2.194147e-13</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>594</th>\n      <td>Nothing at all to recommend.</td>\n      <td>0</td>\n      <td>4.093666e-08</td>\n      <td>4.658780e-07</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>595</th>\n      <td>It is a true classic.</td>\n      <td>1</td>\n      <td>2.298270e-06</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>596</th>\n      <td>It's the one movie that never ceases to intere...</td>\n      <td>1</td>\n      <td>2.023924e-36</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>478 rows Ã— 5 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  65.83333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": "            Word  Word Frequency   P(Word)  Positive Sentiment Word Frequency  \\\n0             it             137  0.013475                               78.0   \n1     represents               2  0.000197                                2.0   \n2            the             251  0.024688                              143.0   \n3         humour               3  0.000295                                3.0   \n4       northern               2  0.000197                                2.0   \n...          ...             ...       ...                                ...   \n2428       keeps               2  0.000197                                2.0   \n2429    decipher               2  0.000197                                2.0   \n2430      ceases               2  0.000197                                2.0   \n2431    interest               2  0.000197                                2.0   \n2432       alert               2  0.000197                                2.0   \n\n      P(Sentiment = Positive)  P(Word | Sentiment = Positive)  \\\n0                     0.54375                        0.298851   \n1                     0.54375                        0.007663   \n2                     0.54375                        0.547893   \n3                     0.54375                        0.011494   \n4                     0.54375                        0.007663   \n...                       ...                             ...   \n2428                  0.54375                        0.007663   \n2429                  0.54375                        0.007663   \n2430                  0.54375                        0.007663   \n2431                  0.54375                        0.007663   \n2432                  0.54375                        0.007663   \n\n      Negative Sentiment Word Frequency  P(Sentiment = Negative)  \\\n0                                  60.0                 0.460417   \n1                                   1.0                 0.460417   \n2                                 109.0                 0.460417   \n3                                   1.0                 0.460417   \n4                                   1.0                 0.460417   \n...                                 ...                      ...   \n2428                                1.0                 0.460417   \n2429                                1.0                 0.460417   \n2430                                1.0                 0.460417   \n2431                                1.0                 0.460417   \n2432                                1.0                 0.460417   \n\n      P(Word | Sentiment = Negative)  \n0                           0.271493  \n1                           0.004525  \n2                           0.493213  \n3                           0.004525  \n4                           0.004525  \n...                              ...  \n2428                        0.004525  \n2429                        0.004525  \n2430                        0.004525  \n2431                        0.004525  \n2432                        0.004525  \n\n[2433 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Word Frequency</th>\n      <th>P(Word)</th>\n      <th>Positive Sentiment Word Frequency</th>\n      <th>P(Sentiment = Positive)</th>\n      <th>P(Word | Sentiment = Positive)</th>\n      <th>Negative Sentiment Word Frequency</th>\n      <th>P(Sentiment = Negative)</th>\n      <th>P(Word | Sentiment = Negative)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>it</td>\n      <td>137</td>\n      <td>0.013475</td>\n      <td>78.0</td>\n      <td>0.54375</td>\n      <td>0.298851</td>\n      <td>60.0</td>\n      <td>0.460417</td>\n      <td>0.271493</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>represents</td>\n      <td>2</td>\n      <td>0.000197</td>\n      <td>2.0</td>\n      <td>0.54375</td>\n      <td>0.007663</td>\n      <td>1.0</td>\n      <td>0.460417</td>\n      <td>0.004525</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>the</td>\n      <td>251</td>\n      <td>0.024688</td>\n      <td>143.0</td>\n      <td>0.54375</td>\n      <td>0.547893</td>\n      <td>109.0</td>\n      <td>0.460417</td>\n      <td>0.493213</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>humour</td>\n      <td>3</td>\n      <td>0.000295</td>\n      <td>3.0</td>\n      <td>0.54375</td>\n      <td>0.011494</td>\n      <td>1.0</td>\n      <td>0.460417</td>\n      <td>0.004525</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>northern</td>\n      <td>2</td>\n      <td>0.000197</td>\n      <td>2.0</td>\n      <td>0.54375</td>\n      <td>0.007663</td>\n      <td>1.0</td>\n      <td>0.460417</td>\n      <td>0.004525</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2428</th>\n      <td>keeps</td>\n      <td>2</td>\n      <td>0.000197</td>\n      <td>2.0</td>\n      <td>0.54375</td>\n      <td>0.007663</td>\n      <td>1.0</td>\n      <td>0.460417</td>\n      <td>0.004525</td>\n    </tr>\n    <tr>\n      <th>2429</th>\n      <td>decipher</td>\n      <td>2</td>\n      <td>0.000197</td>\n      <td>2.0</td>\n      <td>0.54375</td>\n      <td>0.007663</td>\n      <td>1.0</td>\n      <td>0.460417</td>\n      <td>0.004525</td>\n    </tr>\n    <tr>\n      <th>2430</th>\n      <td>ceases</td>\n      <td>2</td>\n      <td>0.000197</td>\n      <td>2.0</td>\n      <td>0.54375</td>\n      <td>0.007663</td>\n      <td>1.0</td>\n      <td>0.460417</td>\n      <td>0.004525</td>\n    </tr>\n    <tr>\n      <th>2431</th>\n      <td>interest</td>\n      <td>2</td>\n      <td>0.000197</td>\n      <td>2.0</td>\n      <td>0.54375</td>\n      <td>0.007663</td>\n      <td>1.0</td>\n      <td>0.460417</td>\n      <td>0.004525</td>\n    </tr>\n    <tr>\n      <th>2432</th>\n      <td>alert</td>\n      <td>2</td>\n      <td>0.000197</td>\n      <td>2.0</td>\n      <td>0.54375</td>\n      <td>0.007663</td>\n      <td>1.0</td>\n      <td>0.460417</td>\n      <td>0.004525</td>\n    </tr>\n  </tbody>\n</table>\n<p>2433 rows Ã— 9 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------Fold 3---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                           IMDB Review  Sentiment  \\\n0    It has northern humour and positive about the ...          1   \n1               But it is entertaining, nonetheless.            1   \n4    Technically, the film is well made with impres...          1   \n6       Oh yeah, and the storyline was pathetic too.            0   \n7    Watching washing machine twirling around would...          0   \n..                                                 ...        ...   \n591  Judith Light is one of my favorite actresses a...          1   \n592  But it picked up speed and got right to the po...          1   \n593  I am a fan of his ... This movie sucked really...          0   \n595                            It is a true classic.            1   \n597  Don't be afraid of subtitles........ its worth...          1   \n\n     P(Sentiment = Positive | Sentence)  P(Sentiment = Negative | Sentence)  \\\n0                          2.471503e-17                        0.000000e+00   \n1                          2.276588e-07                        0.000000e+00   \n4                          4.910824e-57                        0.000000e+00   \n6                          0.000000e+00                        5.478339e-12   \n7                          0.000000e+00                        3.107479e-25   \n..                                  ...                                 ...   \n591                        1.864440e-25                        0.000000e+00   \n592                        8.691701e-16                        0.000000e+00   \n593                        0.000000e+00                        2.194147e-13   \n595                        2.298270e-06                        0.000000e+00   \n597                        4.206275e-22                        0.000000e+00   \n\n     Predicted sentiment  \n0                   True  \n1                   True  \n4                   True  \n6                  False  \n7                  False  \n..                   ...  \n591                 True  \n592                 True  \n593                False  \n595                 True  \n597                 True  \n\n[478 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IMDB Review</th>\n      <th>Sentiment</th>\n      <th>P(Sentiment = Positive | Sentence)</th>\n      <th>P(Sentiment = Negative | Sentence)</th>\n      <th>Predicted sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>It has northern humour and positive about the ...</td>\n      <td>1</td>\n      <td>2.471503e-17</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>But it is entertaining, nonetheless.</td>\n      <td>1</td>\n      <td>2.276588e-07</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Technically, the film is well made with impres...</td>\n      <td>1</td>\n      <td>4.910824e-57</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Oh yeah, and the storyline was pathetic too.</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>5.478339e-12</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Watching washing machine twirling around would...</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>3.107479e-25</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>591</th>\n      <td>Judith Light is one of my favorite actresses a...</td>\n      <td>1</td>\n      <td>1.864440e-25</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>592</th>\n      <td>But it picked up speed and got right to the po...</td>\n      <td>1</td>\n      <td>8.691701e-16</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>593</th>\n      <td>I am a fan of his ... This movie sucked really...</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>2.194147e-13</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>595</th>\n      <td>It is a true classic.</td>\n      <td>1</td>\n      <td>2.298270e-06</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>597</th>\n      <td>Don't be afraid of subtitles........ its worth...</td>\n      <td>1</td>\n      <td>4.206275e-22</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>478 rows Ã— 5 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  70.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "            Word  Word Frequency   P(Word)  Positive Sentiment Word Frequency  \\\n0             it             135  0.013397                               68.0   \n1     represents               2  0.000198                                2.0   \n2            the             242  0.024015                              136.0   \n3         humour               3  0.000298                                3.0   \n4       northern               2  0.000198                                2.0   \n...          ...             ...       ...                                ...   \n2362      judith               2  0.000198                                2.0   \n2363      picked               2  0.000198                                2.0   \n2364     therapy               2  0.000198                                2.0   \n2365   subtitles               2  0.000198                                2.0   \n2366    aversion               2  0.000198                                2.0   \n\n      P(Sentiment = Positive)  P(Word | Sentiment = Positive)  \\\n0                    0.539583                        0.262548   \n1                    0.539583                        0.007722   \n2                    0.539583                        0.525097   \n3                    0.539583                        0.011583   \n4                    0.539583                        0.007722   \n...                       ...                             ...   \n2362                 0.539583                        0.007722   \n2363                 0.539583                        0.007722   \n2364                 0.539583                        0.007722   \n2365                 0.539583                        0.007722   \n2366                 0.539583                        0.007722   \n\n      Negative Sentiment Word Frequency  P(Sentiment = Negative)  \\\n0                                  68.0                 0.464583   \n1                                   1.0                 0.464583   \n2                                 107.0                 0.464583   \n3                                   1.0                 0.464583   \n4                                   1.0                 0.464583   \n...                                 ...                      ...   \n2362                                1.0                 0.464583   \n2363                                1.0                 0.464583   \n2364                                1.0                 0.464583   \n2365                                1.0                 0.464583   \n2366                                1.0                 0.464583   \n\n      P(Word | Sentiment = Negative)  \n0                           0.304933  \n1                           0.004484  \n2                           0.479821  \n3                           0.004484  \n4                           0.004484  \n...                              ...  \n2362                        0.004484  \n2363                        0.004484  \n2364                        0.004484  \n2365                        0.004484  \n2366                        0.004484  \n\n[2367 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Word Frequency</th>\n      <th>P(Word)</th>\n      <th>Positive Sentiment Word Frequency</th>\n      <th>P(Sentiment = Positive)</th>\n      <th>P(Word | Sentiment = Positive)</th>\n      <th>Negative Sentiment Word Frequency</th>\n      <th>P(Sentiment = Negative)</th>\n      <th>P(Word | Sentiment = Negative)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>it</td>\n      <td>135</td>\n      <td>0.013397</td>\n      <td>68.0</td>\n      <td>0.539583</td>\n      <td>0.262548</td>\n      <td>68.0</td>\n      <td>0.464583</td>\n      <td>0.304933</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>represents</td>\n      <td>2</td>\n      <td>0.000198</td>\n      <td>2.0</td>\n      <td>0.539583</td>\n      <td>0.007722</td>\n      <td>1.0</td>\n      <td>0.464583</td>\n      <td>0.004484</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>the</td>\n      <td>242</td>\n      <td>0.024015</td>\n      <td>136.0</td>\n      <td>0.539583</td>\n      <td>0.525097</td>\n      <td>107.0</td>\n      <td>0.464583</td>\n      <td>0.479821</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>humour</td>\n      <td>3</td>\n      <td>0.000298</td>\n      <td>3.0</td>\n      <td>0.539583</td>\n      <td>0.011583</td>\n      <td>1.0</td>\n      <td>0.464583</td>\n      <td>0.004484</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>northern</td>\n      <td>2</td>\n      <td>0.000198</td>\n      <td>2.0</td>\n      <td>0.539583</td>\n      <td>0.007722</td>\n      <td>1.0</td>\n      <td>0.464583</td>\n      <td>0.004484</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2362</th>\n      <td>judith</td>\n      <td>2</td>\n      <td>0.000198</td>\n      <td>2.0</td>\n      <td>0.539583</td>\n      <td>0.007722</td>\n      <td>1.0</td>\n      <td>0.464583</td>\n      <td>0.004484</td>\n    </tr>\n    <tr>\n      <th>2363</th>\n      <td>picked</td>\n      <td>2</td>\n      <td>0.000198</td>\n      <td>2.0</td>\n      <td>0.539583</td>\n      <td>0.007722</td>\n      <td>1.0</td>\n      <td>0.464583</td>\n      <td>0.004484</td>\n    </tr>\n    <tr>\n      <th>2364</th>\n      <td>therapy</td>\n      <td>2</td>\n      <td>0.000198</td>\n      <td>2.0</td>\n      <td>0.539583</td>\n      <td>0.007722</td>\n      <td>1.0</td>\n      <td>0.464583</td>\n      <td>0.004484</td>\n    </tr>\n    <tr>\n      <th>2365</th>\n      <td>subtitles</td>\n      <td>2</td>\n      <td>0.000198</td>\n      <td>2.0</td>\n      <td>0.539583</td>\n      <td>0.007722</td>\n      <td>1.0</td>\n      <td>0.464583</td>\n      <td>0.004484</td>\n    </tr>\n    <tr>\n      <th>2366</th>\n      <td>aversion</td>\n      <td>2</td>\n      <td>0.000198</td>\n      <td>2.0</td>\n      <td>0.539583</td>\n      <td>0.007722</td>\n      <td>1.0</td>\n      <td>0.464583</td>\n      <td>0.004484</td>\n    </tr>\n  </tbody>\n</table>\n<p>2367 rows Ã— 9 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------Fold 4---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                           IMDB Review  Sentiment  \\\n0    It has northern humour and positive about the ...          1   \n1               But it is entertaining, nonetheless.            1   \n2    The result is a film that just don't look righ...          0   \n3                              Highly unrecommended.            0   \n4    Technically, the film is well made with impres...          1   \n..                                                 ...        ...   \n592  But it picked up speed and got right to the po...          1   \n593  I am a fan of his ... This movie sucked really...          0   \n594                     Nothing at all to recommend.            0   \n596  It's the one movie that never ceases to intere...          1   \n597  Don't be afraid of subtitles........ its worth...          1   \n\n     P(Sentiment = Positive | Sentence)  P(Sentiment = Negative | Sentence)  \\\n0                          2.471503e-17                        0.000000e+00   \n1                          2.276588e-07                        0.000000e+00   \n2                          1.782963e-12                        0.000000e+00   \n3                          0.000000e+00                        1.901864e-05   \n4                          4.910824e-57                        0.000000e+00   \n..                                  ...                                 ...   \n592                        8.691701e-16                        0.000000e+00   \n593                        0.000000e+00                        2.194147e-13   \n594                        4.093666e-08                        4.658780e-07   \n596                        2.023924e-36                        0.000000e+00   \n597                        4.206275e-22                        0.000000e+00   \n\n     Predicted sentiment  \n0                   True  \n1                   True  \n2                   True  \n3                  False  \n4                   True  \n..                   ...  \n592                 True  \n593                False  \n594                False  \n596                 True  \n597                 True  \n\n[479 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IMDB Review</th>\n      <th>Sentiment</th>\n      <th>P(Sentiment = Positive | Sentence)</th>\n      <th>P(Sentiment = Negative | Sentence)</th>\n      <th>Predicted sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>It has northern humour and positive about the ...</td>\n      <td>1</td>\n      <td>2.471503e-17</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>But it is entertaining, nonetheless.</td>\n      <td>1</td>\n      <td>2.276588e-07</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The result is a film that just don't look righ...</td>\n      <td>0</td>\n      <td>1.782963e-12</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Highly unrecommended.</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>1.901864e-05</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Technically, the film is well made with impres...</td>\n      <td>1</td>\n      <td>4.910824e-57</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>592</th>\n      <td>But it picked up speed and got right to the po...</td>\n      <td>1</td>\n      <td>8.691701e-16</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>593</th>\n      <td>I am a fan of his ... This movie sucked really...</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>2.194147e-13</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>594</th>\n      <td>Nothing at all to recommend.</td>\n      <td>0</td>\n      <td>4.093666e-08</td>\n      <td>4.658780e-07</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>596</th>\n      <td>It's the one movie that never ceases to intere...</td>\n      <td>1</td>\n      <td>2.023924e-36</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>597</th>\n      <td>Don't be afraid of subtitles........ its worth...</td>\n      <td>1</td>\n      <td>4.206275e-22</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>479 rows Ã— 5 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  65.54621848739495\n"
     ]
    },
    {
     "data": {
      "text/plain": "            Word  Word Frequency   P(Word)  Positive Sentiment Word Frequency  \\\n0             it             140  0.014675                               76.0   \n1     represents               2  0.000210                                2.0   \n2            the             254  0.026625                              148.0   \n3         humour               2  0.000210                                2.0   \n4       northern               2  0.000210                                2.0   \n...          ...             ...       ...                                ...   \n2258       alert               2  0.000210                                2.0   \n2259      afraid               2  0.000210                                2.0   \n2260     therapy               2  0.000210                                2.0   \n2261   subtitles               2  0.000210                                2.0   \n2262    aversion               2  0.000210                                2.0   \n\n      P(Sentiment = Positive)  P(Word | Sentiment = Positive)  \\\n0                    0.553015                        0.285714   \n1                    0.553015                        0.007519   \n2                    0.553015                        0.556391   \n3                    0.553015                        0.007519   \n4                    0.553015                        0.007519   \n...                       ...                             ...   \n2258                 0.553015                        0.007519   \n2259                 0.553015                        0.007519   \n2260                 0.553015                        0.007519   \n2261                 0.553015                        0.007519   \n2262                 0.553015                        0.007519   \n\n      Negative Sentiment Word Frequency  P(Sentiment = Negative)  \\\n0                                  65.0                 0.451143   \n1                                   1.0                 0.451143   \n2                                 107.0                 0.451143   \n3                                   1.0                 0.451143   \n4                                   1.0                 0.451143   \n...                                 ...                      ...   \n2258                                1.0                 0.451143   \n2259                                1.0                 0.451143   \n2260                                1.0                 0.451143   \n2261                                1.0                 0.451143   \n2262                                1.0                 0.451143   \n\n      P(Word | Sentiment = Negative)  \n0                           0.299539  \n1                           0.004608  \n2                           0.493088  \n3                           0.004608  \n4                           0.004608  \n...                              ...  \n2258                        0.004608  \n2259                        0.004608  \n2260                        0.004608  \n2261                        0.004608  \n2262                        0.004608  \n\n[2263 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Word Frequency</th>\n      <th>P(Word)</th>\n      <th>Positive Sentiment Word Frequency</th>\n      <th>P(Sentiment = Positive)</th>\n      <th>P(Word | Sentiment = Positive)</th>\n      <th>Negative Sentiment Word Frequency</th>\n      <th>P(Sentiment = Negative)</th>\n      <th>P(Word | Sentiment = Negative)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>it</td>\n      <td>140</td>\n      <td>0.014675</td>\n      <td>76.0</td>\n      <td>0.553015</td>\n      <td>0.285714</td>\n      <td>65.0</td>\n      <td>0.451143</td>\n      <td>0.299539</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>represents</td>\n      <td>2</td>\n      <td>0.000210</td>\n      <td>2.0</td>\n      <td>0.553015</td>\n      <td>0.007519</td>\n      <td>1.0</td>\n      <td>0.451143</td>\n      <td>0.004608</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>the</td>\n      <td>254</td>\n      <td>0.026625</td>\n      <td>148.0</td>\n      <td>0.553015</td>\n      <td>0.556391</td>\n      <td>107.0</td>\n      <td>0.451143</td>\n      <td>0.493088</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>humour</td>\n      <td>2</td>\n      <td>0.000210</td>\n      <td>2.0</td>\n      <td>0.553015</td>\n      <td>0.007519</td>\n      <td>1.0</td>\n      <td>0.451143</td>\n      <td>0.004608</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>northern</td>\n      <td>2</td>\n      <td>0.000210</td>\n      <td>2.0</td>\n      <td>0.553015</td>\n      <td>0.007519</td>\n      <td>1.0</td>\n      <td>0.451143</td>\n      <td>0.004608</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2258</th>\n      <td>alert</td>\n      <td>2</td>\n      <td>0.000210</td>\n      <td>2.0</td>\n      <td>0.553015</td>\n      <td>0.007519</td>\n      <td>1.0</td>\n      <td>0.451143</td>\n      <td>0.004608</td>\n    </tr>\n    <tr>\n      <th>2259</th>\n      <td>afraid</td>\n      <td>2</td>\n      <td>0.000210</td>\n      <td>2.0</td>\n      <td>0.553015</td>\n      <td>0.007519</td>\n      <td>1.0</td>\n      <td>0.451143</td>\n      <td>0.004608</td>\n    </tr>\n    <tr>\n      <th>2260</th>\n      <td>therapy</td>\n      <td>2</td>\n      <td>0.000210</td>\n      <td>2.0</td>\n      <td>0.553015</td>\n      <td>0.007519</td>\n      <td>1.0</td>\n      <td>0.451143</td>\n      <td>0.004608</td>\n    </tr>\n    <tr>\n      <th>2261</th>\n      <td>subtitles</td>\n      <td>2</td>\n      <td>0.000210</td>\n      <td>2.0</td>\n      <td>0.553015</td>\n      <td>0.007519</td>\n      <td>1.0</td>\n      <td>0.451143</td>\n      <td>0.004608</td>\n    </tr>\n    <tr>\n      <th>2262</th>\n      <td>aversion</td>\n      <td>2</td>\n      <td>0.000210</td>\n      <td>2.0</td>\n      <td>0.553015</td>\n      <td>0.007519</td>\n      <td>1.0</td>\n      <td>0.451143</td>\n      <td>0.004608</td>\n    </tr>\n  </tbody>\n</table>\n<p>2263 rows Ã— 9 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------Fold 5---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                           IMDB Review  Sentiment  \\\n2    The result is a film that just don't look righ...          0   \n3                              Highly unrecommended.            0   \n5    There is no plot here to keep you going in the...          0   \n6       Oh yeah, and the storyline was pathetic too.            0   \n9                     This is an extraordinary film.            1   \n..                                                 ...        ...   \n591  Judith Light is one of my favorite actresses a...          1   \n594                     Nothing at all to recommend.            0   \n595                            It is a true classic.            1   \n596  It's the one movie that never ceases to intere...          1   \n597  Don't be afraid of subtitles........ its worth...          1   \n\n     P(Sentiment = Positive | Sentence)  P(Sentiment = Negative | Sentence)  \\\n2                          1.782963e-12                        0.000000e+00   \n3                          0.000000e+00                        1.901864e-05   \n5                          0.000000e+00                        1.557680e-17   \n6                          0.000000e+00                        5.478339e-12   \n9                          4.071717e-05                        1.305057e-05   \n..                                  ...                                 ...   \n591                        1.864440e-25                        0.000000e+00   \n594                        4.093666e-08                        4.658780e-07   \n595                        2.298270e-06                        0.000000e+00   \n596                        2.023924e-36                        0.000000e+00   \n597                        4.206275e-22                        0.000000e+00   \n\n     Predicted sentiment  \n2                   True  \n3                  False  \n5                  False  \n6                  False  \n9                   True  \n..                   ...  \n591                 True  \n594                False  \n595                 True  \n596                 True  \n597                 True  \n\n[479 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IMDB Review</th>\n      <th>Sentiment</th>\n      <th>P(Sentiment = Positive | Sentence)</th>\n      <th>P(Sentiment = Negative | Sentence)</th>\n      <th>Predicted sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>The result is a film that just don't look righ...</td>\n      <td>0</td>\n      <td>1.782963e-12</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Highly unrecommended.</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>1.901864e-05</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>There is no plot here to keep you going in the...</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>1.557680e-17</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Oh yeah, and the storyline was pathetic too.</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>5.478339e-12</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>This is an extraordinary film.</td>\n      <td>1</td>\n      <td>4.071717e-05</td>\n      <td>1.305057e-05</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>591</th>\n      <td>Judith Light is one of my favorite actresses a...</td>\n      <td>1</td>\n      <td>1.864440e-25</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>594</th>\n      <td>Nothing at all to recommend.</td>\n      <td>0</td>\n      <td>4.093666e-08</td>\n      <td>4.658780e-07</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>595</th>\n      <td>It is a true classic.</td>\n      <td>1</td>\n      <td>2.298270e-06</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>596</th>\n      <td>It's the one movie that never ceases to intere...</td>\n      <td>1</td>\n      <td>2.023924e-36</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>597</th>\n      <td>Don't be afraid of subtitles........ its worth...</td>\n      <td>1</td>\n      <td>4.206275e-22</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>479 rows Ã— 5 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  67.22689075630252\n"
     ]
    },
    {
     "data": {
      "text/plain": "           Word  Word Frequency   P(Word)  Positive Sentiment Word Frequency  \\\n0         don't              15  0.001540                                4.0   \n1          look              15  0.001540                                8.0   \n2          just              33  0.003388                               12.0   \n3           the             241  0.024741                              130.0   \n4          film              79  0.008110                               52.0   \n...         ...             ...       ...                                ...   \n2308     ceases               2  0.000205                                2.0   \n2309      alert               2  0.000205                                2.0   \n2310    therapy               2  0.000205                                2.0   \n2311  subtitles               2  0.000205                                2.0   \n2312   aversion               2  0.000205                                2.0   \n\n      P(Sentiment = Positive)  P(Word | Sentiment = Positive)  \\\n0                    0.525988                        0.015810   \n1                    0.525988                        0.031621   \n2                    0.525988                        0.047431   \n3                    0.525988                        0.513834   \n4                    0.525988                        0.205534   \n...                       ...                             ...   \n2308                 0.525988                        0.007905   \n2309                 0.525988                        0.007905   \n2310                 0.525988                        0.007905   \n2311                 0.525988                        0.007905   \n2312                 0.525988                        0.007905   \n\n      Negative Sentiment Word Frequency  P(Sentiment = Negative)  \\\n0                                  12.0                  0.47817   \n1                                   8.0                  0.47817   \n2                                  22.0                  0.47817   \n3                                 112.0                  0.47817   \n4                                  28.0                  0.47817   \n...                                 ...                      ...   \n2308                                1.0                  0.47817   \n2309                                1.0                  0.47817   \n2310                                1.0                  0.47817   \n2311                                1.0                  0.47817   \n2312                                1.0                  0.47817   \n\n      P(Word | Sentiment = Negative)  \n0                           0.052174  \n1                           0.034783  \n2                           0.095652  \n3                           0.486957  \n4                           0.121739  \n...                              ...  \n2308                        0.004348  \n2309                        0.004348  \n2310                        0.004348  \n2311                        0.004348  \n2312                        0.004348  \n\n[2313 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Word Frequency</th>\n      <th>P(Word)</th>\n      <th>Positive Sentiment Word Frequency</th>\n      <th>P(Sentiment = Positive)</th>\n      <th>P(Word | Sentiment = Positive)</th>\n      <th>Negative Sentiment Word Frequency</th>\n      <th>P(Sentiment = Negative)</th>\n      <th>P(Word | Sentiment = Negative)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>don't</td>\n      <td>15</td>\n      <td>0.001540</td>\n      <td>4.0</td>\n      <td>0.525988</td>\n      <td>0.015810</td>\n      <td>12.0</td>\n      <td>0.47817</td>\n      <td>0.052174</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>look</td>\n      <td>15</td>\n      <td>0.001540</td>\n      <td>8.0</td>\n      <td>0.525988</td>\n      <td>0.031621</td>\n      <td>8.0</td>\n      <td>0.47817</td>\n      <td>0.034783</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>just</td>\n      <td>33</td>\n      <td>0.003388</td>\n      <td>12.0</td>\n      <td>0.525988</td>\n      <td>0.047431</td>\n      <td>22.0</td>\n      <td>0.47817</td>\n      <td>0.095652</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>the</td>\n      <td>241</td>\n      <td>0.024741</td>\n      <td>130.0</td>\n      <td>0.525988</td>\n      <td>0.513834</td>\n      <td>112.0</td>\n      <td>0.47817</td>\n      <td>0.486957</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>film</td>\n      <td>79</td>\n      <td>0.008110</td>\n      <td>52.0</td>\n      <td>0.525988</td>\n      <td>0.205534</td>\n      <td>28.0</td>\n      <td>0.47817</td>\n      <td>0.121739</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2308</th>\n      <td>ceases</td>\n      <td>2</td>\n      <td>0.000205</td>\n      <td>2.0</td>\n      <td>0.525988</td>\n      <td>0.007905</td>\n      <td>1.0</td>\n      <td>0.47817</td>\n      <td>0.004348</td>\n    </tr>\n    <tr>\n      <th>2309</th>\n      <td>alert</td>\n      <td>2</td>\n      <td>0.000205</td>\n      <td>2.0</td>\n      <td>0.525988</td>\n      <td>0.007905</td>\n      <td>1.0</td>\n      <td>0.47817</td>\n      <td>0.004348</td>\n    </tr>\n    <tr>\n      <th>2310</th>\n      <td>therapy</td>\n      <td>2</td>\n      <td>0.000205</td>\n      <td>2.0</td>\n      <td>0.525988</td>\n      <td>0.007905</td>\n      <td>1.0</td>\n      <td>0.47817</td>\n      <td>0.004348</td>\n    </tr>\n    <tr>\n      <th>2311</th>\n      <td>subtitles</td>\n      <td>2</td>\n      <td>0.000205</td>\n      <td>2.0</td>\n      <td>0.525988</td>\n      <td>0.007905</td>\n      <td>1.0</td>\n      <td>0.47817</td>\n      <td>0.004348</td>\n    </tr>\n    <tr>\n      <th>2312</th>\n      <td>aversion</td>\n      <td>2</td>\n      <td>0.000205</td>\n      <td>2.0</td>\n      <td>0.525988</td>\n      <td>0.007905</td>\n      <td>1.0</td>\n      <td>0.47817</td>\n      <td>0.004348</td>\n    </tr>\n  </tbody>\n</table>\n<p>2313 rows Ã— 9 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "            Word  Word Frequency   P(Word)  Positive Sentiment Word Frequency  \\\n0             it             132  0.013408                               72.0   \n1     represents               2  0.000203                                2.0   \n2            the             241  0.024479                              136.0   \n3         humour               3  0.000305                                3.0   \n4       northern               2  0.000203                                2.0   \n...          ...             ...       ...                                ...   \n2347      ceases               2  0.000203                                2.0   \n2348       alert               2  0.000203                                2.0   \n2349     therapy               2  0.000203                                2.0   \n2350   subtitles               2  0.000203                                2.0   \n2351    aversion               2  0.000203                                2.0   \n\n      P(Sentiment = Positive)  P(Word | Sentiment = Positive)  \\\n0                    0.522917                        0.286853   \n1                    0.522917                        0.007968   \n2                    0.522917                        0.541833   \n3                    0.522917                        0.011952   \n4                    0.522917                        0.007968   \n...                       ...                             ...   \n2347                 0.522917                        0.007968   \n2348                 0.522917                        0.007968   \n2349                 0.522917                        0.007968   \n2350                 0.522917                        0.007968   \n2351                 0.522917                        0.007968   \n\n      Negative Sentiment Word Frequency  P(Sentiment = Negative)  \\\n0                                  61.0                  0.48125   \n1                                   1.0                  0.48125   \n2                                 106.0                  0.48125   \n3                                   1.0                  0.48125   \n4                                   1.0                  0.48125   \n...                                 ...                      ...   \n2347                                1.0                  0.48125   \n2348                                1.0                  0.48125   \n2349                                1.0                  0.48125   \n2350                                1.0                  0.48125   \n2351                                1.0                  0.48125   \n\n      P(Word | Sentiment = Negative)  \n0                           0.264069  \n1                           0.004329  \n2                           0.458874  \n3                           0.004329  \n4                           0.004329  \n...                              ...  \n2347                        0.004329  \n2348                        0.004329  \n2349                        0.004329  \n2350                        0.004329  \n2351                        0.004329  \n\n[2352 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Word Frequency</th>\n      <th>P(Word)</th>\n      <th>Positive Sentiment Word Frequency</th>\n      <th>P(Sentiment = Positive)</th>\n      <th>P(Word | Sentiment = Positive)</th>\n      <th>Negative Sentiment Word Frequency</th>\n      <th>P(Sentiment = Negative)</th>\n      <th>P(Word | Sentiment = Negative)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>it</td>\n      <td>132</td>\n      <td>0.013408</td>\n      <td>72.0</td>\n      <td>0.522917</td>\n      <td>0.286853</td>\n      <td>61.0</td>\n      <td>0.48125</td>\n      <td>0.264069</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>represents</td>\n      <td>2</td>\n      <td>0.000203</td>\n      <td>2.0</td>\n      <td>0.522917</td>\n      <td>0.007968</td>\n      <td>1.0</td>\n      <td>0.48125</td>\n      <td>0.004329</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>the</td>\n      <td>241</td>\n      <td>0.024479</td>\n      <td>136.0</td>\n      <td>0.522917</td>\n      <td>0.541833</td>\n      <td>106.0</td>\n      <td>0.48125</td>\n      <td>0.458874</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>humour</td>\n      <td>3</td>\n      <td>0.000305</td>\n      <td>3.0</td>\n      <td>0.522917</td>\n      <td>0.011952</td>\n      <td>1.0</td>\n      <td>0.48125</td>\n      <td>0.004329</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>northern</td>\n      <td>2</td>\n      <td>0.000203</td>\n      <td>2.0</td>\n      <td>0.522917</td>\n      <td>0.007968</td>\n      <td>1.0</td>\n      <td>0.48125</td>\n      <td>0.004329</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2347</th>\n      <td>ceases</td>\n      <td>2</td>\n      <td>0.000203</td>\n      <td>2.0</td>\n      <td>0.522917</td>\n      <td>0.007968</td>\n      <td>1.0</td>\n      <td>0.48125</td>\n      <td>0.004329</td>\n    </tr>\n    <tr>\n      <th>2348</th>\n      <td>alert</td>\n      <td>2</td>\n      <td>0.000203</td>\n      <td>2.0</td>\n      <td>0.522917</td>\n      <td>0.007968</td>\n      <td>1.0</td>\n      <td>0.48125</td>\n      <td>0.004329</td>\n    </tr>\n    <tr>\n      <th>2349</th>\n      <td>therapy</td>\n      <td>2</td>\n      <td>0.000203</td>\n      <td>2.0</td>\n      <td>0.522917</td>\n      <td>0.007968</td>\n      <td>1.0</td>\n      <td>0.48125</td>\n      <td>0.004329</td>\n    </tr>\n    <tr>\n      <th>2350</th>\n      <td>subtitles</td>\n      <td>2</td>\n      <td>0.000203</td>\n      <td>2.0</td>\n      <td>0.522917</td>\n      <td>0.007968</td>\n      <td>1.0</td>\n      <td>0.48125</td>\n      <td>0.004329</td>\n    </tr>\n    <tr>\n      <th>2351</th>\n      <td>aversion</td>\n      <td>2</td>\n      <td>0.000203</td>\n      <td>2.0</td>\n      <td>0.522917</td>\n      <td>0.007968</td>\n      <td>1.0</td>\n      <td>0.48125</td>\n      <td>0.004329</td>\n    </tr>\n  </tbody>\n</table>\n<p>2352 rows Ã— 9 columns</p>\n</div>"
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = five_fold_cross_validation(train, True)\n",
    "vocabulary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-249-198896de2224>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame[\"P(Sentiment = Positive | Sentence)\"] = data_frame[\"IMDB Review\"].apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  93.1438127090301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-249-198896de2224>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame[\"P(Sentiment = Negative | Sentence)\"] = data_frame[\"IMDB Review\"].apply(\n",
      "<ipython-input-249-198896de2224>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame[\"Predicted sentiment\"] = data_frame[\"P(Sentiment = Positive | Sentence)\"] > data_frame[\n"
     ]
    },
    {
     "data": {
      "text/plain": "93.1438127090301"
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_calculate_accuracy(train, vocabulary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  73.33333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": "73.33333333333333"
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_calculate_accuracy(dev, vocabulary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  69.33333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": "69.33333333333333"
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_calculate_accuracy(test, vocabulary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Most Useful words after Smoothing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Useful Positive sentiment words:\n"
     ]
    },
    {
     "data": {
      "text/plain": "      Word  Word Frequency   P(Word)  Positive Sentiment Word Frequency  \\\n2      the             241  0.024479                              136.0   \n6      and             171  0.017369                              114.0   \n19       a             178  0.018080                              105.0   \n74      of             152  0.015439                               90.0   \n10      is             156  0.015846                               77.0   \n68    this             141  0.014322                               75.0   \n0       it             132  0.013408                               72.0   \n53      to             126  0.012798                               68.0   \n108      i             111  0.011275                               61.0   \n52      in              90  0.009142                               53.0   \n17    film              78  0.007923                               53.0   \n97     was              82  0.008329                               45.0   \n99   movie              82  0.008329                               43.0   \n20    that              81  0.008228                               41.0   \n40    with              46  0.004672                               29.0   \n12     but              44  0.004469                               29.0   \n61      as              47  0.004774                               28.0   \n41    good              34  0.003454                               26.0   \n83     for              54  0.005485                               26.0   \n112    are              41  0.004165                               25.0   \n\n     P(Sentiment = Positive)  P(Word | Sentiment = Positive)  \\\n2                   0.522917                        0.541833   \n6                   0.522917                        0.454183   \n19                  0.522917                        0.418327   \n74                  0.522917                        0.358566   \n10                  0.522917                        0.306773   \n68                  0.522917                        0.298805   \n0                   0.522917                        0.286853   \n53                  0.522917                        0.270916   \n108                 0.522917                        0.243028   \n52                  0.522917                        0.211155   \n17                  0.522917                        0.211155   \n97                  0.522917                        0.179283   \n99                  0.522917                        0.171315   \n20                  0.522917                        0.163347   \n40                  0.522917                        0.115538   \n12                  0.522917                        0.115538   \n61                  0.522917                        0.111554   \n41                  0.522917                        0.103586   \n83                  0.522917                        0.103586   \n112                 0.522917                        0.099602   \n\n     Negative Sentiment Word Frequency  P(Sentiment = Negative)  \\\n2                                106.0                  0.48125   \n6                                 58.0                  0.48125   \n19                                74.0                  0.48125   \n74                                63.0                  0.48125   \n10                                80.0                  0.48125   \n68                                67.0                  0.48125   \n0                                 61.0                  0.48125   \n53                                59.0                  0.48125   \n108                               51.0                  0.48125   \n52                                38.0                  0.48125   \n17                                26.0                  0.48125   \n97                                38.0                  0.48125   \n99                                40.0                  0.48125   \n20                                41.0                  0.48125   \n40                                18.0                  0.48125   \n12                                16.0                  0.48125   \n61                                20.0                  0.48125   \n41                                 9.0                  0.48125   \n83                                29.0                  0.48125   \n112                               17.0                  0.48125   \n\n     P(Word | Sentiment = Negative)  \n2                          0.458874  \n6                          0.251082  \n19                         0.320346  \n74                         0.272727  \n10                         0.346320  \n68                         0.290043  \n0                          0.264069  \n53                         0.255411  \n108                        0.220779  \n52                         0.164502  \n17                         0.112554  \n97                         0.164502  \n99                         0.173160  \n20                         0.177489  \n40                         0.077922  \n12                         0.069264  \n61                         0.086580  \n41                         0.038961  \n83                         0.125541  \n112                        0.073593  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Word Frequency</th>\n      <th>P(Word)</th>\n      <th>Positive Sentiment Word Frequency</th>\n      <th>P(Sentiment = Positive)</th>\n      <th>P(Word | Sentiment = Positive)</th>\n      <th>Negative Sentiment Word Frequency</th>\n      <th>P(Sentiment = Negative)</th>\n      <th>P(Word | Sentiment = Negative)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>the</td>\n      <td>241</td>\n      <td>0.024479</td>\n      <td>136.0</td>\n      <td>0.522917</td>\n      <td>0.541833</td>\n      <td>106.0</td>\n      <td>0.48125</td>\n      <td>0.458874</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>and</td>\n      <td>171</td>\n      <td>0.017369</td>\n      <td>114.0</td>\n      <td>0.522917</td>\n      <td>0.454183</td>\n      <td>58.0</td>\n      <td>0.48125</td>\n      <td>0.251082</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>a</td>\n      <td>178</td>\n      <td>0.018080</td>\n      <td>105.0</td>\n      <td>0.522917</td>\n      <td>0.418327</td>\n      <td>74.0</td>\n      <td>0.48125</td>\n      <td>0.320346</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>of</td>\n      <td>152</td>\n      <td>0.015439</td>\n      <td>90.0</td>\n      <td>0.522917</td>\n      <td>0.358566</td>\n      <td>63.0</td>\n      <td>0.48125</td>\n      <td>0.272727</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>is</td>\n      <td>156</td>\n      <td>0.015846</td>\n      <td>77.0</td>\n      <td>0.522917</td>\n      <td>0.306773</td>\n      <td>80.0</td>\n      <td>0.48125</td>\n      <td>0.346320</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>this</td>\n      <td>141</td>\n      <td>0.014322</td>\n      <td>75.0</td>\n      <td>0.522917</td>\n      <td>0.298805</td>\n      <td>67.0</td>\n      <td>0.48125</td>\n      <td>0.290043</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>it</td>\n      <td>132</td>\n      <td>0.013408</td>\n      <td>72.0</td>\n      <td>0.522917</td>\n      <td>0.286853</td>\n      <td>61.0</td>\n      <td>0.48125</td>\n      <td>0.264069</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>to</td>\n      <td>126</td>\n      <td>0.012798</td>\n      <td>68.0</td>\n      <td>0.522917</td>\n      <td>0.270916</td>\n      <td>59.0</td>\n      <td>0.48125</td>\n      <td>0.255411</td>\n    </tr>\n    <tr>\n      <th>108</th>\n      <td>i</td>\n      <td>111</td>\n      <td>0.011275</td>\n      <td>61.0</td>\n      <td>0.522917</td>\n      <td>0.243028</td>\n      <td>51.0</td>\n      <td>0.48125</td>\n      <td>0.220779</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>in</td>\n      <td>90</td>\n      <td>0.009142</td>\n      <td>53.0</td>\n      <td>0.522917</td>\n      <td>0.211155</td>\n      <td>38.0</td>\n      <td>0.48125</td>\n      <td>0.164502</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>film</td>\n      <td>78</td>\n      <td>0.007923</td>\n      <td>53.0</td>\n      <td>0.522917</td>\n      <td>0.211155</td>\n      <td>26.0</td>\n      <td>0.48125</td>\n      <td>0.112554</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>was</td>\n      <td>82</td>\n      <td>0.008329</td>\n      <td>45.0</td>\n      <td>0.522917</td>\n      <td>0.179283</td>\n      <td>38.0</td>\n      <td>0.48125</td>\n      <td>0.164502</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>movie</td>\n      <td>82</td>\n      <td>0.008329</td>\n      <td>43.0</td>\n      <td>0.522917</td>\n      <td>0.171315</td>\n      <td>40.0</td>\n      <td>0.48125</td>\n      <td>0.173160</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>that</td>\n      <td>81</td>\n      <td>0.008228</td>\n      <td>41.0</td>\n      <td>0.522917</td>\n      <td>0.163347</td>\n      <td>41.0</td>\n      <td>0.48125</td>\n      <td>0.177489</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>with</td>\n      <td>46</td>\n      <td>0.004672</td>\n      <td>29.0</td>\n      <td>0.522917</td>\n      <td>0.115538</td>\n      <td>18.0</td>\n      <td>0.48125</td>\n      <td>0.077922</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>but</td>\n      <td>44</td>\n      <td>0.004469</td>\n      <td>29.0</td>\n      <td>0.522917</td>\n      <td>0.115538</td>\n      <td>16.0</td>\n      <td>0.48125</td>\n      <td>0.069264</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>as</td>\n      <td>47</td>\n      <td>0.004774</td>\n      <td>28.0</td>\n      <td>0.522917</td>\n      <td>0.111554</td>\n      <td>20.0</td>\n      <td>0.48125</td>\n      <td>0.086580</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>good</td>\n      <td>34</td>\n      <td>0.003454</td>\n      <td>26.0</td>\n      <td>0.522917</td>\n      <td>0.103586</td>\n      <td>9.0</td>\n      <td>0.48125</td>\n      <td>0.038961</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>for</td>\n      <td>54</td>\n      <td>0.005485</td>\n      <td>26.0</td>\n      <td>0.522917</td>\n      <td>0.103586</td>\n      <td>29.0</td>\n      <td>0.48125</td>\n      <td>0.125541</td>\n    </tr>\n    <tr>\n      <th>112</th>\n      <td>are</td>\n      <td>41</td>\n      <td>0.004165</td>\n      <td>25.0</td>\n      <td>0.522917</td>\n      <td>0.099602</td>\n      <td>17.0</td>\n      <td>0.48125</td>\n      <td>0.073593</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Most Useful Positive sentiment words:\")\n",
    "vocabulary.sort_values(\"P(Word | Sentiment = Positive)\", ascending=False)[:most_useful_limit]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Useful Negative sentiment words:\n"
     ]
    },
    {
     "data": {
      "text/plain": "      Word  Word Frequency   P(Word)  Positive Sentiment Word Frequency  \\\n2      the             241  0.024479                              136.0   \n10      is             156  0.015846                               77.0   \n19       a             178  0.018080                              105.0   \n68    this             141  0.014322                               75.0   \n74      of             152  0.015439                               90.0   \n0       it             132  0.013408                               72.0   \n53      to             126  0.012798                               68.0   \n6      and             171  0.017369                              114.0   \n108      i             111  0.011275                               61.0   \n20    that              81  0.008228                               41.0   \n99   movie              82  0.008329                               43.0   \n52      in              90  0.009142                               53.0   \n97     was              82  0.008329                               45.0   \n83     for              54  0.005485                               26.0   \n169    bad              30  0.003047                                4.0   \n17    film              78  0.007923                               53.0   \n187     on              41  0.004165                               17.0   \n133    all              36  0.003657                               15.0   \n16    just              32  0.003250                               12.0   \n61      as              47  0.004774                               28.0   \n\n     P(Sentiment = Positive)  P(Word | Sentiment = Positive)  \\\n2                   0.522917                        0.541833   \n10                  0.522917                        0.306773   \n19                  0.522917                        0.418327   \n68                  0.522917                        0.298805   \n74                  0.522917                        0.358566   \n0                   0.522917                        0.286853   \n53                  0.522917                        0.270916   \n6                   0.522917                        0.454183   \n108                 0.522917                        0.243028   \n20                  0.522917                        0.163347   \n99                  0.522917                        0.171315   \n52                  0.522917                        0.211155   \n97                  0.522917                        0.179283   \n83                  0.522917                        0.103586   \n169                 0.522917                        0.015936   \n17                  0.522917                        0.211155   \n187                 0.522917                        0.067729   \n133                 0.522917                        0.059761   \n16                  0.522917                        0.047809   \n61                  0.522917                        0.111554   \n\n     Negative Sentiment Word Frequency  P(Sentiment = Negative)  \\\n2                                106.0                  0.48125   \n10                                80.0                  0.48125   \n19                                74.0                  0.48125   \n68                                67.0                  0.48125   \n74                                63.0                  0.48125   \n0                                 61.0                  0.48125   \n53                                59.0                  0.48125   \n6                                 58.0                  0.48125   \n108                               51.0                  0.48125   \n20                                41.0                  0.48125   \n99                                40.0                  0.48125   \n52                                38.0                  0.48125   \n97                                38.0                  0.48125   \n83                                29.0                  0.48125   \n169                               27.0                  0.48125   \n17                                26.0                  0.48125   \n187                               25.0                  0.48125   \n133                               22.0                  0.48125   \n16                                21.0                  0.48125   \n61                                20.0                  0.48125   \n\n     P(Word | Sentiment = Negative)  \n2                          0.458874  \n10                         0.346320  \n19                         0.320346  \n68                         0.290043  \n74                         0.272727  \n0                          0.264069  \n53                         0.255411  \n6                          0.251082  \n108                        0.220779  \n20                         0.177489  \n99                         0.173160  \n52                         0.164502  \n97                         0.164502  \n83                         0.125541  \n169                        0.116883  \n17                         0.112554  \n187                        0.108225  \n133                        0.095238  \n16                         0.090909  \n61                         0.086580  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Word Frequency</th>\n      <th>P(Word)</th>\n      <th>Positive Sentiment Word Frequency</th>\n      <th>P(Sentiment = Positive)</th>\n      <th>P(Word | Sentiment = Positive)</th>\n      <th>Negative Sentiment Word Frequency</th>\n      <th>P(Sentiment = Negative)</th>\n      <th>P(Word | Sentiment = Negative)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>the</td>\n      <td>241</td>\n      <td>0.024479</td>\n      <td>136.0</td>\n      <td>0.522917</td>\n      <td>0.541833</td>\n      <td>106.0</td>\n      <td>0.48125</td>\n      <td>0.458874</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>is</td>\n      <td>156</td>\n      <td>0.015846</td>\n      <td>77.0</td>\n      <td>0.522917</td>\n      <td>0.306773</td>\n      <td>80.0</td>\n      <td>0.48125</td>\n      <td>0.346320</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>a</td>\n      <td>178</td>\n      <td>0.018080</td>\n      <td>105.0</td>\n      <td>0.522917</td>\n      <td>0.418327</td>\n      <td>74.0</td>\n      <td>0.48125</td>\n      <td>0.320346</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>this</td>\n      <td>141</td>\n      <td>0.014322</td>\n      <td>75.0</td>\n      <td>0.522917</td>\n      <td>0.298805</td>\n      <td>67.0</td>\n      <td>0.48125</td>\n      <td>0.290043</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>of</td>\n      <td>152</td>\n      <td>0.015439</td>\n      <td>90.0</td>\n      <td>0.522917</td>\n      <td>0.358566</td>\n      <td>63.0</td>\n      <td>0.48125</td>\n      <td>0.272727</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>it</td>\n      <td>132</td>\n      <td>0.013408</td>\n      <td>72.0</td>\n      <td>0.522917</td>\n      <td>0.286853</td>\n      <td>61.0</td>\n      <td>0.48125</td>\n      <td>0.264069</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>to</td>\n      <td>126</td>\n      <td>0.012798</td>\n      <td>68.0</td>\n      <td>0.522917</td>\n      <td>0.270916</td>\n      <td>59.0</td>\n      <td>0.48125</td>\n      <td>0.255411</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>and</td>\n      <td>171</td>\n      <td>0.017369</td>\n      <td>114.0</td>\n      <td>0.522917</td>\n      <td>0.454183</td>\n      <td>58.0</td>\n      <td>0.48125</td>\n      <td>0.251082</td>\n    </tr>\n    <tr>\n      <th>108</th>\n      <td>i</td>\n      <td>111</td>\n      <td>0.011275</td>\n      <td>61.0</td>\n      <td>0.522917</td>\n      <td>0.243028</td>\n      <td>51.0</td>\n      <td>0.48125</td>\n      <td>0.220779</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>that</td>\n      <td>81</td>\n      <td>0.008228</td>\n      <td>41.0</td>\n      <td>0.522917</td>\n      <td>0.163347</td>\n      <td>41.0</td>\n      <td>0.48125</td>\n      <td>0.177489</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>movie</td>\n      <td>82</td>\n      <td>0.008329</td>\n      <td>43.0</td>\n      <td>0.522917</td>\n      <td>0.171315</td>\n      <td>40.0</td>\n      <td>0.48125</td>\n      <td>0.173160</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>in</td>\n      <td>90</td>\n      <td>0.009142</td>\n      <td>53.0</td>\n      <td>0.522917</td>\n      <td>0.211155</td>\n      <td>38.0</td>\n      <td>0.48125</td>\n      <td>0.164502</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>was</td>\n      <td>82</td>\n      <td>0.008329</td>\n      <td>45.0</td>\n      <td>0.522917</td>\n      <td>0.179283</td>\n      <td>38.0</td>\n      <td>0.48125</td>\n      <td>0.164502</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>for</td>\n      <td>54</td>\n      <td>0.005485</td>\n      <td>26.0</td>\n      <td>0.522917</td>\n      <td>0.103586</td>\n      <td>29.0</td>\n      <td>0.48125</td>\n      <td>0.125541</td>\n    </tr>\n    <tr>\n      <th>169</th>\n      <td>bad</td>\n      <td>30</td>\n      <td>0.003047</td>\n      <td>4.0</td>\n      <td>0.522917</td>\n      <td>0.015936</td>\n      <td>27.0</td>\n      <td>0.48125</td>\n      <td>0.116883</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>film</td>\n      <td>78</td>\n      <td>0.007923</td>\n      <td>53.0</td>\n      <td>0.522917</td>\n      <td>0.211155</td>\n      <td>26.0</td>\n      <td>0.48125</td>\n      <td>0.112554</td>\n    </tr>\n    <tr>\n      <th>187</th>\n      <td>on</td>\n      <td>41</td>\n      <td>0.004165</td>\n      <td>17.0</td>\n      <td>0.522917</td>\n      <td>0.067729</td>\n      <td>25.0</td>\n      <td>0.48125</td>\n      <td>0.108225</td>\n    </tr>\n    <tr>\n      <th>133</th>\n      <td>all</td>\n      <td>36</td>\n      <td>0.003657</td>\n      <td>15.0</td>\n      <td>0.522917</td>\n      <td>0.059761</td>\n      <td>22.0</td>\n      <td>0.48125</td>\n      <td>0.095238</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>just</td>\n      <td>32</td>\n      <td>0.003250</td>\n      <td>12.0</td>\n      <td>0.522917</td>\n      <td>0.047809</td>\n      <td>21.0</td>\n      <td>0.48125</td>\n      <td>0.090909</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>as</td>\n      <td>47</td>\n      <td>0.004774</td>\n      <td>28.0</td>\n      <td>0.522917</td>\n      <td>0.111554</td>\n      <td>20.0</td>\n      <td>0.48125</td>\n      <td>0.086580</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Most Useful Negative sentiment words:\")\n",
    "vocabulary.sort_values(\"P(Word | Sentiment = Negative)\", ascending=False)[:most_useful_limit]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference\n",
    "\n",
    "From the above we can see the effect of smoothening at the time of runtime with accuracy increase of 15%.\n",
    "\n",
    "Also, from the most useful words we can see 2 things.\n",
    "1. The most common words are the useful words.\n",
    "2. The most common words, and some words have higher probability in both positive and negative sentiments.\n",
    "\n",
    "This shows us that these data need to be removed.\n",
    "\n",
    "For doing these as future work we can remove stop words from Pythons old NLTK library for stop words.\n",
    "Also, we can remove the more frequent words like the movie, film as it is both positive and negative which is\n",
    "logical as it is a movie database..."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMlp6bFS4Cf9rSnQgklke3R",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "sentiment_prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}