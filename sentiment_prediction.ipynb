{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a href=\"https://colab.research.google.com/github/VighneshS/sentiment_prediction/blob/master/sentiment_prediction.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "<a href=\"https://vighnesh-studies.blogspot.com/2021/04/sentiment-prediction-using-naive-bayes.html\" target=\"_blank\">BLOG</a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sentiment Prediction using Naive Bayes Classifier (NBC)\n",
    "This is a notebook to understand how Naive Bayes Classifier (NBC) works and also how it is useful to classify text based on sentiment.\n",
    "\n",
    "We will also see how it will be effective against missing data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Settings\n",
    "Training Percentage"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [],
   "source": [
    "training_ratio = 80 / 100\n",
    "k = 5\n",
    "most_useful_limit = 20"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Importing the Data\n",
    "We used the [kaggle dataset](https://storage.googleapis.com/kagglesdsdata/datasets/22169/30047/sentiment%20labelled%20sentences/imdb_labelled.txt?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20210425%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20210425T202010Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=6133706ef10bc2dcd0b58f8398b4d73ab9e9d788de1718b07334df91f6007e1e4ca0b78e3176f95b8250e0c4535ce1633528f4fabffeb7e4124af3ee3f895ac34c03044fca9b23b23c4ddb8fa90d84dfc14869ff4806f03783cafad53b19445b3c3052983fdf1ca4384257eac1bc0a4270d238a1ea89d1289866c7a0ea7ad7c97a76f2e142c148019e39cc5a1295f92650747ac5ea5946b026f7ad6d5d262d4c4a370aee6bc1f5d5b445bb6d93692debe678a79e5e1c1fe3d3e68ea4f2fad3115795d3361e0626e98156fbc7f5967beb7cf0f00e07351d23a00d8677ebb75e3e13b1bfa07762266efabf6f6f9d53206be31b7623cf3614f60f8cf5011cf23def) to get the ground truth of sample IMDB reviews."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from IPython.display import display\n",
    "import math\n",
    "from sklearn.model_selection import KFold"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [],
   "source": [
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "data = pd.read_csv(\n",
    "    r\"http://storage.googleapis.com/kagglesdsdata/datasets/22169/30047/sentiment%20labelled%20sentences/imdb_labelled.txt?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20210425%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20210425T202010Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=6133706ef10bc2dcd0b58f8398b4d73ab9e9d788de1718b07334df91f6007e1e4ca0b78e3176f95b8250e0c4535ce1633528f4fabffeb7e4124af3ee3f895ac34c03044fca9b23b23c4ddb8fa90d84dfc14869ff4806f03783cafad53b19445b3c3052983fdf1ca4384257eac1bc0a4270d238a1ea89d1289866c7a0ea7ad7c97a76f2e142c148019e39cc5a1295f92650747ac5ea5946b026f7ad6d5d262d4c4a370aee6bc1f5d5b445bb6d93692debe678a79e5e1c1fe3d3e68ea4f2fad3115795d3361e0626e98156fbc7f5967beb7cf0f00e07351d23a00d8677ebb75e3e13b1bfa07762266efabf6f6f9d53206be31b7623cf3614f60f8cf5011cf23def\",\n",
    "    delimiter=\"\\t\", header=None, names=[\"IMDB Review\", \"Sentiment\"])\n",
    "data = data.sample(frac=1).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split Data\n",
    "We split the data into train, development and test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [],
   "source": [
    "train = data[:math.floor(data.shape[0] * training_ratio)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [],
   "source": [
    "validation = data[math.floor(data.shape[0] * training_ratio):].sample(frac=1).reset_index(drop=True)\n",
    "dev, test = np.array_split(validation, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [
    {
     "data": {
      "text/plain": "                                           IMDB Review  Sentiment\n0          This scene is very strong and unpleasant.            0\n1    The plot was the same as pretty much every oth...          0\n2    I liked the way Dustin Hoffman's character was...          1\n3    From here on the Widmark character turns unint...          0\n4    Also the music by Mark Snow is possibly the be...          1\n..                                                 ...        ...\n593            I never walked out of a movie faster.            0\n594                        He's a national treasure.            1\n595  One of the most boring,pointless movies I have...          0\n596  As for the killer, don't expect anything origi...          0\n597  Vivian Schilling did an excellent job with the...          1\n\n[598 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IMDB Review</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>This scene is very strong and unpleasant.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The plot was the same as pretty much every oth...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I liked the way Dustin Hoffman's character was...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>From here on the Widmark character turns unint...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Also the music by Mark Snow is possibly the be...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>593</th>\n      <td>I never walked out of a movie faster.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>594</th>\n      <td>He's a national treasure.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>595</th>\n      <td>One of the most boring,pointless movies I have...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>596</th>\n      <td>As for the killer, don't expect anything origi...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>597</th>\n      <td>Vivian Schilling did an excellent job with the...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>598 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                                          IMDB Review  Sentiment\n0   This movie suffered because of the writing, it...          0\n1   The movie is not completely perfect but 'Titta...          1\n2   But this understated film leaves a lasting imp...          1\n3   At no point in the proceedings does it look re...          0\n4   The plot doesn't hang together at all, and the...          0\n..                                                ...        ...\n70  The only possible way this movie could be rede...          0\n71  Having to humour him just to get by and get th...          1\n72  PS the only scene in the movie that was cool i...          1\n73        I believe that Pitch Black was done well.            1\n74  But above all the exquisite visual composition...          1\n\n[75 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IMDB Review</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>This movie suffered because of the writing, it...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The movie is not completely perfect but 'Titta...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>But this understated film leaves a lasting imp...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>At no point in the proceedings does it look re...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The plot doesn't hang together at all, and the...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>The only possible way this movie could be rede...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>Having to humour him just to get by and get th...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>PS the only scene in the movie that was cool i...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>I believe that Pitch Black was done well.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>But above all the exquisite visual composition...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>75 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                                           IMDB Review  Sentiment\n75   I had to walk out of the theatre for a few min...          0\n76                                 How awful she is!            0\n77   Overall, the film is interesting and thought-p...          1\n78   I don't understand how this garbage got on the...          0\n79   Kathy Bates is wonderful in her characters sub...          1\n..                                                 ...        ...\n145  Easily, none other cartoon made me laugh in a ...          1\n146                  I couldn't take them seriously.            0\n147  The film lacks any real scares or tension & so...          0\n148  Just consider the excellent story, solid actin...          1\n149  This show is made for Americans - it is too st...          0\n\n[75 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IMDB Review</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>75</th>\n      <td>I had to walk out of the theatre for a few min...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>How awful she is!</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>Overall, the film is interesting and thought-p...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>I don't understand how this garbage got on the...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>Kathy Bates is wonderful in her characters sub...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>Easily, none other cartoon made me laugh in a ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>I couldn't take them seriously.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>The film lacks any real scares or tension &amp; so...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>Just consider the excellent story, solid actin...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>This show is made for Americans - it is too st...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>75 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train, dev, test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generation of Vocabulary list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [],
   "source": [
    "def split_words(review):\n",
    "    return review.lower().replace(',', '').replace('\"', '').replace('(', '').replace(')', '').replace('\\'s',\n",
    "                                                                                                      '').replace(\n",
    "        '.',\n",
    "        '').replace(\n",
    "        '!', '').replace('-', ' ').replace('/', ' ').split()\n",
    "\n",
    "\n",
    "def get_word_count(review_data_frame: pd.DataFrame, column_name: str):\n",
    "    vocab = review_data_frame[\"IMDB Review\"].apply(lambda review: pd.value_counts(\n",
    "        split_words(review))).count(axis=0).to_frame()\n",
    "    vocab.columns = [column_name]\n",
    "    vocab.reset_index(inplace=True)\n",
    "    vocab = vocab.rename(columns={'index': 'Word'})\n",
    "    return vocab"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get Naive Bayes Parameters\n",
    "Here we have a function to genereate the Naive Bayes Parameters like:\n",
    "\n",
    "1. Word Frequency\n",
    "2. P(Word)\n",
    "3. Positive Sentiment Word Frequency\n",
    "4. P(Sentiment = Positive)\n",
    "5. P(Word | Sentiment = Positive)\n",
    "6. Negative Sentiment Word Frequency\n",
    "7. P(Sentiment = Negative)\n",
    "8. P(Word | Sentiment = Negative)\n",
    "\n",
    "Which are useful in finding:\n",
    "\n",
    "**P(Sentiment | Sentence (Collection of words)) = P(Sentence | Sentiment) * P(Sentiment) / P(Sentense)**\n",
    "\n",
    "The P(Sentense) can be approximated to 1 as we are comparing sentiments the value will be cancelled on either sides"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [],
   "source": [
    "def generate_naive_bayes_parameters(data_frame: pd.DataFrame, smoothening: bool):\n",
    "    naive_bayes_parameters = get_word_count(data_frame, \"Word Frequency\")\n",
    "    if smoothening:\n",
    "        naive_bayes_parameters[\"Word Frequency\"] += 1\n",
    "\n",
    "    total_words = naive_bayes_parameters[\"Word Frequency\"].sum(axis=0)\n",
    "    if smoothening:\n",
    "        total_words += 2\n",
    "\n",
    "    total_sentiments = data_frame.count(axis=0)['Sentiment']\n",
    "    if smoothening:\n",
    "        total_sentiments += 2\n",
    "\n",
    "    naive_bayes_parameters['P(Word)'] = naive_bayes_parameters[\"Word Frequency\"].div(total_words)\n",
    "\n",
    "    positive_sentiments = data_frame[data_frame['Sentiment'] == 1]\n",
    "    positive_vocabulary = get_word_count(positive_sentiments, \"Positive Sentiment Word Frequency\")\n",
    "    naive_bayes_parameters = naive_bayes_parameters.merge(positive_vocabulary, how='left', on='Word')\n",
    "    if smoothening:\n",
    "        naive_bayes_parameters[\"Positive Sentiment Word Frequency\"] += 1\n",
    "        naive_bayes_parameters[\"Positive Sentiment Word Frequency\"] = naive_bayes_parameters[\n",
    "            \"Positive Sentiment Word Frequency\"].fillna(\n",
    "            value=1)\n",
    "\n",
    "    total_positive_words = positive_sentiments.count(axis=0)['Sentiment']\n",
    "    if smoothening:\n",
    "        total_positive_words += 2\n",
    "\n",
    "    probability_of_positive_sentiments = total_positive_words / total_sentiments\n",
    "    naive_bayes_parameters['P(Sentiment = Positive)'] = probability_of_positive_sentiments\n",
    "\n",
    "    naive_bayes_parameters['P(Word | Sentiment = Positive)'] = naive_bayes_parameters[\n",
    "        'Positive Sentiment Word Frequency'].div(\n",
    "        total_positive_words)\n",
    "\n",
    "    negative_sentiments = data_frame[data_frame['Sentiment'] == 0]\n",
    "    negative_vocabulary = get_word_count(negative_sentiments, \"Negative Sentiment Word Frequency\")\n",
    "    naive_bayes_parameters = naive_bayes_parameters.merge(negative_vocabulary, how='left', on='Word')\n",
    "    if smoothening:\n",
    "        naive_bayes_parameters[\"Negative Sentiment Word Frequency\"] += 1\n",
    "        naive_bayes_parameters[\"Negative Sentiment Word Frequency\"] = naive_bayes_parameters[\n",
    "            \"Negative Sentiment Word Frequency\"].fillna(\n",
    "            value=1)\n",
    "\n",
    "    total_negative_words = negative_sentiments.count(axis=0)['Sentiment']\n",
    "    if smoothening:\n",
    "        total_negative_words += 2\n",
    "\n",
    "    probability_of_negative_sentiments = total_negative_words / total_sentiments\n",
    "    naive_bayes_parameters['P(Sentiment = Negative)'] = probability_of_negative_sentiments\n",
    "\n",
    "    naive_bayes_parameters['P(Word | Sentiment = Negative)'] = naive_bayes_parameters[\n",
    "        'Negative Sentiment Word Frequency'].div(\n",
    "        total_negative_words)\n",
    "\n",
    "    return naive_bayes_parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## To Get the Probabilities\n",
    "\n",
    "We use this formula to get the probabilities:\n",
    "\n",
    "**P(Sentiment | Sentence (Collection of words)) = P(Sentence | Sentiment) * P(Sentiment) / P(Sentense)**\n",
    "\n",
    "The below function will calculate the numerator part and assumes the denominator to be 1 as it will cancel out during\n",
    "comparison.\n",
    "\n",
    "For calculating the P(Sentence | Sentiment) we have words in sentences. So, we can write the formula as:\n",
    "\n",
    "**P(Sentence | Sentiment) = P(Word_1,Word_2,...,Word_n | Sentiment)**\n",
    "\n",
    "By Naive Bayes Theorem we can write it as:\n",
    "\n",
    "**P(Word_1,Word_2,...,Word_n | Sentiment) = P(Word_1 | Sentiment).P(Word_2 | Sentiment). ... .P(Word_n | Sentiment)**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [],
   "source": [
    "def get_probabilities(review: str, naive_bayes_parameters: pd.DataFrame, sentiment: bool, smoothening: bool):\n",
    "    prob = 1\n",
    "    column_name = 'P(Word | Sentiment = Positive)' if sentiment else 'P(Word | Sentiment = Negative)'\n",
    "    individual_prob = 0 if not smoothening else 1 / (\n",
    "        naive_bayes_parameters['P(Sentiment = Positive)'][0] if sentiment else naive_bayes_parameters[\n",
    "            'P(Sentiment = Negative)'][0])\n",
    "    for word in split_words(review):\n",
    "        if word in naive_bayes_parameters.values:\n",
    "            individual_prob = naive_bayes_parameters[naive_bayes_parameters['Word'] == word].iloc[0][column_name]\n",
    "        prob *= 0 if math.isnan(individual_prob) else individual_prob\n",
    "    return prob * (naive_bayes_parameters['P(Sentiment = Positive)'][0] if sentiment else naive_bayes_parameters[\n",
    "        'P(Sentiment = Negative)'][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [],
   "source": [
    "def predict_calculate_accuracy(data_frame: pd.DataFrame, naive_bayes_parameters: pd.DataFrame):\n",
    "    data_frame[\"P(Sentiment = Positive | Sentence)\"] = data_frame[\"IMDB Review\"].apply(\n",
    "        lambda review: get_probabilities(review, naive_bayes_parameters, True, False))\n",
    "    data_frame[\"P(Sentiment = Negative | Sentence)\"] = data_frame[\"IMDB Review\"].apply(\n",
    "        lambda review: get_probabilities(review, naive_bayes_parameters, False, False))\n",
    "    data_frame[\"Predicted sentiment\"] = data_frame[\"P(Sentiment = Positive | Sentence)\"] > data_frame[\n",
    "        \"P(Sentiment = Negative | Sentence)\"]\n",
    "    accuracy = data_frame.loc[data_frame[\"Predicted sentiment\"] == data_frame[\"Sentiment\"]].count(axis=0)[\n",
    "                   'Sentiment'] * 100 / data_frame.count(axis=0)['Sentiment']\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    # print(\"Wrong Predictions:\")\n",
    "    # display(data_frame.loc[data_frame[\"Predicted sentiment\"] != data_frame[\"Sentiment\"]].reset_index(drop=True))\n",
    "    return accuracy\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculating Accuracy\n",
    "\n",
    "To calculate accuracy we first divide the training dataset into k parts of train and test the first part of the\n",
    "set is used to train the dataset with the remaining k-1 test dataset.\n",
    "\n",
    "We then predict using the Naive bayes parameters that we get from training against the test data.\n",
    "\n",
    "We then calculate the accuracy by finding (how many data is of correct prediction)/(total number of datasets)\n",
    "\n",
    "With the parameters having the best accuracy is chosen from this and used for further validation of dev anf test\n",
    "datasets which we separated in the beginning."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------Fold 1---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                           IMDB Review  Sentiment\n0          This scene is very strong and unpleasant.            0\n3    From here on the Widmark character turns unint...          0\n4    Also the music by Mark Snow is possibly the be...          1\n5    The memories are murky but I can only say that...          1\n6    This movie does an excellent job of revealing ...          1\n..                                                 ...        ...\n591  Crash is a depressing little nothing, that pro...          0\n592  I just got bored watching Jessice Lange take h...          0\n593            I never walked out of a movie faster.            0\n595  One of the most boring,pointless movies I have...          0\n596  As for the killer, don't expect anything origi...          0\n\n[478 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IMDB Review</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>This scene is very strong and unpleasant.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>From here on the Widmark character turns unint...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Also the music by Mark Snow is possibly the be...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>The memories are murky but I can only say that...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>This movie does an excellent job of revealing ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>591</th>\n      <td>Crash is a depressing little nothing, that pro...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>592</th>\n      <td>I just got bored watching Jessice Lange take h...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>593</th>\n      <td>I never walked out of a movie faster.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>595</th>\n      <td>One of the most boring,pointless movies I have...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>596</th>\n      <td>As for the killer, don't expect anything origi...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>478 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  66.66666666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": "                 Word  Word Frequency   P(Word)  \\\n0                very              32  0.004562   \n1               scene               6  0.000855   \n2              strong               2  0.000285   \n3                  is             135  0.019247   \n4                 and             173  0.024665   \n...               ...             ...       ...   \n2150          jessice               1  0.000143   \n2151             take               1  0.000143   \n2152           faster               1  0.000143   \n2153  boringpointless               1  0.000143   \n2154         remotely               1  0.000143   \n\n      Positive Sentiment Word Frequency  P(Sentiment = Positive)  \\\n0                                  15.0                 0.537657   \n1                                   3.0                 0.537657   \n2                                   1.0                 0.537657   \n3                                  67.0                 0.537657   \n4                                 113.0                 0.537657   \n...                                 ...                      ...   \n2150                                NaN                 0.537657   \n2151                                NaN                 0.537657   \n2152                                NaN                 0.537657   \n2153                                NaN                 0.537657   \n2154                                NaN                 0.537657   \n\n      P(Word | Sentiment = Positive)  Negative Sentiment Word Frequency  \\\n0                           0.058366                               17.0   \n1                           0.011673                                3.0   \n2                           0.003891                                1.0   \n3                           0.260700                               68.0   \n4                           0.439689                               60.0   \n...                              ...                                ...   \n2150                             NaN                                1.0   \n2151                             NaN                                1.0   \n2152                             NaN                                1.0   \n2153                             NaN                                1.0   \n2154                             NaN                                1.0   \n\n      P(Sentiment = Negative)  P(Word | Sentiment = Negative)  \n0                    0.462343                        0.076923  \n1                    0.462343                        0.013575  \n2                    0.462343                        0.004525  \n3                    0.462343                        0.307692  \n4                    0.462343                        0.271493  \n...                       ...                             ...  \n2150                 0.462343                        0.004525  \n2151                 0.462343                        0.004525  \n2152                 0.462343                        0.004525  \n2153                 0.462343                        0.004525  \n2154                 0.462343                        0.004525  \n\n[2155 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Word Frequency</th>\n      <th>P(Word)</th>\n      <th>Positive Sentiment Word Frequency</th>\n      <th>P(Sentiment = Positive)</th>\n      <th>P(Word | Sentiment = Positive)</th>\n      <th>Negative Sentiment Word Frequency</th>\n      <th>P(Sentiment = Negative)</th>\n      <th>P(Word | Sentiment = Negative)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>very</td>\n      <td>32</td>\n      <td>0.004562</td>\n      <td>15.0</td>\n      <td>0.537657</td>\n      <td>0.058366</td>\n      <td>17.0</td>\n      <td>0.462343</td>\n      <td>0.076923</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>scene</td>\n      <td>6</td>\n      <td>0.000855</td>\n      <td>3.0</td>\n      <td>0.537657</td>\n      <td>0.011673</td>\n      <td>3.0</td>\n      <td>0.462343</td>\n      <td>0.013575</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>strong</td>\n      <td>2</td>\n      <td>0.000285</td>\n      <td>1.0</td>\n      <td>0.537657</td>\n      <td>0.003891</td>\n      <td>1.0</td>\n      <td>0.462343</td>\n      <td>0.004525</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>is</td>\n      <td>135</td>\n      <td>0.019247</td>\n      <td>67.0</td>\n      <td>0.537657</td>\n      <td>0.260700</td>\n      <td>68.0</td>\n      <td>0.462343</td>\n      <td>0.307692</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>and</td>\n      <td>173</td>\n      <td>0.024665</td>\n      <td>113.0</td>\n      <td>0.537657</td>\n      <td>0.439689</td>\n      <td>60.0</td>\n      <td>0.462343</td>\n      <td>0.271493</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2150</th>\n      <td>jessice</td>\n      <td>1</td>\n      <td>0.000143</td>\n      <td>NaN</td>\n      <td>0.537657</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.462343</td>\n      <td>0.004525</td>\n    </tr>\n    <tr>\n      <th>2151</th>\n      <td>take</td>\n      <td>1</td>\n      <td>0.000143</td>\n      <td>NaN</td>\n      <td>0.537657</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.462343</td>\n      <td>0.004525</td>\n    </tr>\n    <tr>\n      <th>2152</th>\n      <td>faster</td>\n      <td>1</td>\n      <td>0.000143</td>\n      <td>NaN</td>\n      <td>0.537657</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.462343</td>\n      <td>0.004525</td>\n    </tr>\n    <tr>\n      <th>2153</th>\n      <td>boringpointless</td>\n      <td>1</td>\n      <td>0.000143</td>\n      <td>NaN</td>\n      <td>0.537657</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.462343</td>\n      <td>0.004525</td>\n    </tr>\n    <tr>\n      <th>2154</th>\n      <td>remotely</td>\n      <td>1</td>\n      <td>0.000143</td>\n      <td>NaN</td>\n      <td>0.537657</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.462343</td>\n      <td>0.004525</td>\n    </tr>\n  </tbody>\n</table>\n<p>2155 rows × 9 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------Fold 2---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                           IMDB Review  Sentiment\n0          This scene is very strong and unpleasant.            0\n1    The plot was the same as pretty much every oth...          0\n2    I liked the way Dustin Hoffman's character was...          1\n3    From here on the Widmark character turns unint...          0\n6    This movie does an excellent job of revealing ...          1\n..                                                 ...        ...\n593            I never walked out of a movie faster.            0\n594                        He's a national treasure.            1\n595  One of the most boring,pointless movies I have...          0\n596  As for the killer, don't expect anything origi...          0\n597  Vivian Schilling did an excellent job with the...          1\n\n[478 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IMDB Review</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>This scene is very strong and unpleasant.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The plot was the same as pretty much every oth...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I liked the way Dustin Hoffman's character was...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>From here on the Widmark character turns unint...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>This movie does an excellent job of revealing ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>593</th>\n      <td>I never walked out of a movie faster.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>594</th>\n      <td>He's a national treasure.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>595</th>\n      <td>One of the most boring,pointless movies I have...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>596</th>\n      <td>As for the killer, don't expect anything origi...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>597</th>\n      <td>Vivian Schilling did an excellent job with the...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>478 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  62.5\n"
     ]
    },
    {
     "data": {
      "text/plain": "                 Word  Word Frequency   P(Word)  \\\n0                very              32  0.003922   \n1               scene              10  0.001226   \n2              strong               5  0.000613   \n3                  is             155  0.018997   \n4                 and             180  0.022062   \n...               ...             ...       ...   \n2550         national               1  0.000123   \n2551  boringpointless               1  0.000123   \n2552         remotely               1  0.000123   \n2553        schilling               1  0.000123   \n2554           vivian               1  0.000123   \n\n      Positive Sentiment Word Frequency  P(Sentiment = Positive)  \\\n0                                  17.0                 0.552301   \n1                                   4.0                 0.552301   \n2                                   3.0                 0.552301   \n3                                  77.0                 0.552301   \n4                                 115.0                 0.552301   \n...                                 ...                      ...   \n2550                                1.0                 0.552301   \n2551                                NaN                 0.552301   \n2552                                NaN                 0.552301   \n2553                                1.0                 0.552301   \n2554                                1.0                 0.552301   \n\n      P(Word | Sentiment = Positive)  Negative Sentiment Word Frequency  \\\n0                           0.064394                               15.0   \n1                           0.015152                                6.0   \n2                           0.011364                                2.0   \n3                           0.291667                               78.0   \n4                           0.435606                               65.0   \n...                              ...                                ...   \n2550                        0.003788                                NaN   \n2551                             NaN                                1.0   \n2552                             NaN                                1.0   \n2553                        0.003788                                NaN   \n2554                        0.003788                                NaN   \n\n      P(Sentiment = Negative)  P(Word | Sentiment = Negative)  \n0                    0.447699                        0.070093  \n1                    0.447699                        0.028037  \n2                    0.447699                        0.009346  \n3                    0.447699                        0.364486  \n4                    0.447699                        0.303738  \n...                       ...                             ...  \n2550                 0.447699                             NaN  \n2551                 0.447699                        0.004673  \n2552                 0.447699                        0.004673  \n2553                 0.447699                             NaN  \n2554                 0.447699                             NaN  \n\n[2555 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Word Frequency</th>\n      <th>P(Word)</th>\n      <th>Positive Sentiment Word Frequency</th>\n      <th>P(Sentiment = Positive)</th>\n      <th>P(Word | Sentiment = Positive)</th>\n      <th>Negative Sentiment Word Frequency</th>\n      <th>P(Sentiment = Negative)</th>\n      <th>P(Word | Sentiment = Negative)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>very</td>\n      <td>32</td>\n      <td>0.003922</td>\n      <td>17.0</td>\n      <td>0.552301</td>\n      <td>0.064394</td>\n      <td>15.0</td>\n      <td>0.447699</td>\n      <td>0.070093</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>scene</td>\n      <td>10</td>\n      <td>0.001226</td>\n      <td>4.0</td>\n      <td>0.552301</td>\n      <td>0.015152</td>\n      <td>6.0</td>\n      <td>0.447699</td>\n      <td>0.028037</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>strong</td>\n      <td>5</td>\n      <td>0.000613</td>\n      <td>3.0</td>\n      <td>0.552301</td>\n      <td>0.011364</td>\n      <td>2.0</td>\n      <td>0.447699</td>\n      <td>0.009346</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>is</td>\n      <td>155</td>\n      <td>0.018997</td>\n      <td>77.0</td>\n      <td>0.552301</td>\n      <td>0.291667</td>\n      <td>78.0</td>\n      <td>0.447699</td>\n      <td>0.364486</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>and</td>\n      <td>180</td>\n      <td>0.022062</td>\n      <td>115.0</td>\n      <td>0.552301</td>\n      <td>0.435606</td>\n      <td>65.0</td>\n      <td>0.447699</td>\n      <td>0.303738</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2550</th>\n      <td>national</td>\n      <td>1</td>\n      <td>0.000123</td>\n      <td>1.0</td>\n      <td>0.552301</td>\n      <td>0.003788</td>\n      <td>NaN</td>\n      <td>0.447699</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2551</th>\n      <td>boringpointless</td>\n      <td>1</td>\n      <td>0.000123</td>\n      <td>NaN</td>\n      <td>0.552301</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.447699</td>\n      <td>0.004673</td>\n    </tr>\n    <tr>\n      <th>2552</th>\n      <td>remotely</td>\n      <td>1</td>\n      <td>0.000123</td>\n      <td>NaN</td>\n      <td>0.552301</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.447699</td>\n      <td>0.004673</td>\n    </tr>\n    <tr>\n      <th>2553</th>\n      <td>schilling</td>\n      <td>1</td>\n      <td>0.000123</td>\n      <td>1.0</td>\n      <td>0.552301</td>\n      <td>0.003788</td>\n      <td>NaN</td>\n      <td>0.447699</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2554</th>\n      <td>vivian</td>\n      <td>1</td>\n      <td>0.000123</td>\n      <td>1.0</td>\n      <td>0.552301</td>\n      <td>0.003788</td>\n      <td>NaN</td>\n      <td>0.447699</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>2555 rows × 9 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------Fold 3---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                           IMDB Review  Sentiment\n1    The plot was the same as pretty much every oth...          0\n2    I liked the way Dustin Hoffman's character was...          1\n4    Also the music by Mark Snow is possibly the be...          1\n5    The memories are murky but I can only say that...          1\n7    The writers were \"smack on\" and I think the be...          1\n..                                                 ...        ...\n592  I just got bored watching Jessice Lange take h...          0\n594                        He's a national treasure.            1\n595  One of the most boring,pointless movies I have...          0\n596  As for the killer, don't expect anything origi...          0\n597  Vivian Schilling did an excellent job with the...          1\n\n[478 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IMDB Review</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>The plot was the same as pretty much every oth...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I liked the way Dustin Hoffman's character was...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Also the music by Mark Snow is possibly the be...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>The memories are murky but I can only say that...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>The writers were \"smack on\" and I think the be...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>592</th>\n      <td>I just got bored watching Jessice Lange take h...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>594</th>\n      <td>He's a national treasure.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>595</th>\n      <td>One of the most boring,pointless movies I have...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>596</th>\n      <td>As for the killer, don't expect anything origi...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>597</th>\n      <td>Vivian Schilling did an excellent job with the...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>478 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  57.5\n"
     ]
    },
    {
     "data": {
      "text/plain": "                 Word  Word Frequency   P(Word)  \\\n0                 the             244  0.030352   \n1                  as              43  0.005349   \n2              horror               6  0.000746   \n3              pretty               9  0.001120   \n4               every              10  0.001244   \n...               ...             ...       ...   \n2507         national               1  0.000124   \n2508  boringpointless               1  0.000124   \n2509         remotely               1  0.000124   \n2510        schilling               1  0.000124   \n2511           vivian               1  0.000124   \n\n      Positive Sentiment Word Frequency  P(Sentiment = Positive)  \\\n0                                 133.0                 0.529289   \n1                                  23.0                 0.529289   \n2                                   3.0                 0.529289   \n3                                   5.0                 0.529289   \n4                                   4.0                 0.529289   \n...                                 ...                      ...   \n2507                                1.0                 0.529289   \n2508                                NaN                 0.529289   \n2509                                NaN                 0.529289   \n2510                                1.0                 0.529289   \n2511                                1.0                 0.529289   \n\n      P(Word | Sentiment = Positive)  Negative Sentiment Word Frequency  \\\n0                           0.525692                              111.0   \n1                           0.090909                               20.0   \n2                           0.011858                                3.0   \n3                           0.019763                                4.0   \n4                           0.015810                                6.0   \n...                              ...                                ...   \n2507                        0.003953                                NaN   \n2508                             NaN                                1.0   \n2509                             NaN                                1.0   \n2510                        0.003953                                NaN   \n2511                        0.003953                                NaN   \n\n      P(Sentiment = Negative)  P(Word | Sentiment = Negative)  \n0                    0.470711                        0.493333  \n1                    0.470711                        0.088889  \n2                    0.470711                        0.013333  \n3                    0.470711                        0.017778  \n4                    0.470711                        0.026667  \n...                       ...                             ...  \n2507                 0.470711                             NaN  \n2508                 0.470711                        0.004444  \n2509                 0.470711                        0.004444  \n2510                 0.470711                             NaN  \n2511                 0.470711                             NaN  \n\n[2512 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Word Frequency</th>\n      <th>P(Word)</th>\n      <th>Positive Sentiment Word Frequency</th>\n      <th>P(Sentiment = Positive)</th>\n      <th>P(Word | Sentiment = Positive)</th>\n      <th>Negative Sentiment Word Frequency</th>\n      <th>P(Sentiment = Negative)</th>\n      <th>P(Word | Sentiment = Negative)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>the</td>\n      <td>244</td>\n      <td>0.030352</td>\n      <td>133.0</td>\n      <td>0.529289</td>\n      <td>0.525692</td>\n      <td>111.0</td>\n      <td>0.470711</td>\n      <td>0.493333</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>as</td>\n      <td>43</td>\n      <td>0.005349</td>\n      <td>23.0</td>\n      <td>0.529289</td>\n      <td>0.090909</td>\n      <td>20.0</td>\n      <td>0.470711</td>\n      <td>0.088889</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>horror</td>\n      <td>6</td>\n      <td>0.000746</td>\n      <td>3.0</td>\n      <td>0.529289</td>\n      <td>0.011858</td>\n      <td>3.0</td>\n      <td>0.470711</td>\n      <td>0.013333</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>pretty</td>\n      <td>9</td>\n      <td>0.001120</td>\n      <td>5.0</td>\n      <td>0.529289</td>\n      <td>0.019763</td>\n      <td>4.0</td>\n      <td>0.470711</td>\n      <td>0.017778</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>every</td>\n      <td>10</td>\n      <td>0.001244</td>\n      <td>4.0</td>\n      <td>0.529289</td>\n      <td>0.015810</td>\n      <td>6.0</td>\n      <td>0.470711</td>\n      <td>0.026667</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2507</th>\n      <td>national</td>\n      <td>1</td>\n      <td>0.000124</td>\n      <td>1.0</td>\n      <td>0.529289</td>\n      <td>0.003953</td>\n      <td>NaN</td>\n      <td>0.470711</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2508</th>\n      <td>boringpointless</td>\n      <td>1</td>\n      <td>0.000124</td>\n      <td>NaN</td>\n      <td>0.529289</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.470711</td>\n      <td>0.004444</td>\n    </tr>\n    <tr>\n      <th>2509</th>\n      <td>remotely</td>\n      <td>1</td>\n      <td>0.000124</td>\n      <td>NaN</td>\n      <td>0.529289</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.470711</td>\n      <td>0.004444</td>\n    </tr>\n    <tr>\n      <th>2510</th>\n      <td>schilling</td>\n      <td>1</td>\n      <td>0.000124</td>\n      <td>1.0</td>\n      <td>0.529289</td>\n      <td>0.003953</td>\n      <td>NaN</td>\n      <td>0.470711</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2511</th>\n      <td>vivian</td>\n      <td>1</td>\n      <td>0.000124</td>\n      <td>1.0</td>\n      <td>0.529289</td>\n      <td>0.003953</td>\n      <td>NaN</td>\n      <td>0.470711</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>2512 rows × 9 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------Fold 4---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                           IMDB Review  Sentiment\n0          This scene is very strong and unpleasant.            0\n1    The plot was the same as pretty much every oth...          0\n2    I liked the way Dustin Hoffman's character was...          1\n3    From here on the Widmark character turns unint...          0\n4    Also the music by Mark Snow is possibly the be...          1\n..                                                 ...        ...\n592  I just got bored watching Jessice Lange take h...          0\n593            I never walked out of a movie faster.            0\n594                        He's a national treasure.            1\n596  As for the killer, don't expect anything origi...          0\n597  Vivian Schilling did an excellent job with the...          1\n\n[479 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IMDB Review</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>This scene is very strong and unpleasant.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The plot was the same as pretty much every oth...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I liked the way Dustin Hoffman's character was...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>From here on the Widmark character turns unint...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Also the music by Mark Snow is possibly the be...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>592</th>\n      <td>I just got bored watching Jessice Lange take h...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>593</th>\n      <td>I never walked out of a movie faster.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>594</th>\n      <td>He's a national treasure.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>596</th>\n      <td>As for the killer, don't expect anything origi...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>597</th>\n      <td>Vivian Schilling did an excellent job with the...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>479 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  56.30252100840336\n"
     ]
    },
    {
     "data": {
      "text/plain": "           Word  Word Frequency   P(Word)  Positive Sentiment Word Frequency  \\\n0          very              32  0.004166                               13.0   \n1         scene               5  0.000651                                1.0   \n2        strong               5  0.000651                                3.0   \n3            is             145  0.018875                               70.0   \n4           and             180  0.023431                              117.0   \n...         ...             ...       ...                                ...   \n2347   national               1  0.000130                                1.0   \n2348   remotely               1  0.000130                                NaN   \n2349     killer               1  0.000130                                NaN   \n2350  schilling               1  0.000130                                1.0   \n2351     vivian               1  0.000130                                1.0   \n\n      P(Sentiment = Positive)  P(Word | Sentiment = Positive)  \\\n0                    0.530271                        0.051181   \n1                    0.530271                        0.003937   \n2                    0.530271                        0.011811   \n3                    0.530271                        0.275591   \n4                    0.530271                        0.460630   \n...                       ...                             ...   \n2347                 0.530271                        0.003937   \n2348                 0.530271                             NaN   \n2349                 0.530271                             NaN   \n2350                 0.530271                        0.003937   \n2351                 0.530271                        0.003937   \n\n      Negative Sentiment Word Frequency  P(Sentiment = Negative)  \\\n0                                  19.0                 0.469729   \n1                                   4.0                 0.469729   \n2                                   2.0                 0.469729   \n3                                  75.0                 0.469729   \n4                                  63.0                 0.469729   \n...                                 ...                      ...   \n2347                                NaN                 0.469729   \n2348                                1.0                 0.469729   \n2349                                1.0                 0.469729   \n2350                                NaN                 0.469729   \n2351                                NaN                 0.469729   \n\n      P(Word | Sentiment = Negative)  \n0                           0.084444  \n1                           0.017778  \n2                           0.008889  \n3                           0.333333  \n4                           0.280000  \n...                              ...  \n2347                             NaN  \n2348                        0.004444  \n2349                        0.004444  \n2350                             NaN  \n2351                             NaN  \n\n[2352 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Word Frequency</th>\n      <th>P(Word)</th>\n      <th>Positive Sentiment Word Frequency</th>\n      <th>P(Sentiment = Positive)</th>\n      <th>P(Word | Sentiment = Positive)</th>\n      <th>Negative Sentiment Word Frequency</th>\n      <th>P(Sentiment = Negative)</th>\n      <th>P(Word | Sentiment = Negative)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>very</td>\n      <td>32</td>\n      <td>0.004166</td>\n      <td>13.0</td>\n      <td>0.530271</td>\n      <td>0.051181</td>\n      <td>19.0</td>\n      <td>0.469729</td>\n      <td>0.084444</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>scene</td>\n      <td>5</td>\n      <td>0.000651</td>\n      <td>1.0</td>\n      <td>0.530271</td>\n      <td>0.003937</td>\n      <td>4.0</td>\n      <td>0.469729</td>\n      <td>0.017778</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>strong</td>\n      <td>5</td>\n      <td>0.000651</td>\n      <td>3.0</td>\n      <td>0.530271</td>\n      <td>0.011811</td>\n      <td>2.0</td>\n      <td>0.469729</td>\n      <td>0.008889</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>is</td>\n      <td>145</td>\n      <td>0.018875</td>\n      <td>70.0</td>\n      <td>0.530271</td>\n      <td>0.275591</td>\n      <td>75.0</td>\n      <td>0.469729</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>and</td>\n      <td>180</td>\n      <td>0.023431</td>\n      <td>117.0</td>\n      <td>0.530271</td>\n      <td>0.460630</td>\n      <td>63.0</td>\n      <td>0.469729</td>\n      <td>0.280000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2347</th>\n      <td>national</td>\n      <td>1</td>\n      <td>0.000130</td>\n      <td>1.0</td>\n      <td>0.530271</td>\n      <td>0.003937</td>\n      <td>NaN</td>\n      <td>0.469729</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2348</th>\n      <td>remotely</td>\n      <td>1</td>\n      <td>0.000130</td>\n      <td>NaN</td>\n      <td>0.530271</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.469729</td>\n      <td>0.004444</td>\n    </tr>\n    <tr>\n      <th>2349</th>\n      <td>killer</td>\n      <td>1</td>\n      <td>0.000130</td>\n      <td>NaN</td>\n      <td>0.530271</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.469729</td>\n      <td>0.004444</td>\n    </tr>\n    <tr>\n      <th>2350</th>\n      <td>schilling</td>\n      <td>1</td>\n      <td>0.000130</td>\n      <td>1.0</td>\n      <td>0.530271</td>\n      <td>0.003937</td>\n      <td>NaN</td>\n      <td>0.469729</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2351</th>\n      <td>vivian</td>\n      <td>1</td>\n      <td>0.000130</td>\n      <td>1.0</td>\n      <td>0.530271</td>\n      <td>0.003937</td>\n      <td>NaN</td>\n      <td>0.469729</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>2352 rows × 9 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------Fold 5---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                           IMDB Review  Sentiment\n0          This scene is very strong and unpleasant.            0\n1    The plot was the same as pretty much every oth...          0\n2    I liked the way Dustin Hoffman's character was...          1\n3    From here on the Widmark character turns unint...          0\n4    Also the music by Mark Snow is possibly the be...          1\n..                                                 ...        ...\n592  I just got bored watching Jessice Lange take h...          0\n593            I never walked out of a movie faster.            0\n594                        He's a national treasure.            1\n595  One of the most boring,pointless movies I have...          0\n597  Vivian Schilling did an excellent job with the...          1\n\n[479 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IMDB Review</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>This scene is very strong and unpleasant.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The plot was the same as pretty much every oth...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I liked the way Dustin Hoffman's character was...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>From here on the Widmark character turns unint...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Also the music by Mark Snow is possibly the be...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>592</th>\n      <td>I just got bored watching Jessice Lange take h...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>593</th>\n      <td>I never walked out of a movie faster.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>594</th>\n      <td>He's a national treasure.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>595</th>\n      <td>One of the most boring,pointless movies I have...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>597</th>\n      <td>Vivian Schilling did an excellent job with the...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>479 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  63.02521008403362\n"
     ]
    },
    {
     "data": {
      "text/plain": "                 Word  Word Frequency   P(Word)  \\\n0                very              34  0.004281   \n1               scene              10  0.001259   \n2              strong               4  0.000504   \n3                  is             145  0.018257   \n4                 and             168  0.021153   \n...               ...             ...       ...   \n2523         treasure               1  0.000126   \n2524         national               1  0.000126   \n2525  boringpointless               1  0.000126   \n2526        schilling               1  0.000126   \n2527           vivian               1  0.000126   \n\n      Positive Sentiment Word Frequency  P(Sentiment = Positive)  \\\n0                                  18.0                 0.534447   \n1                                   4.0                 0.534447   \n2                                   2.0                 0.534447   \n3                                  68.0                 0.534447   \n4                                 109.0                 0.534447   \n...                                 ...                      ...   \n2523                                1.0                 0.534447   \n2524                                1.0                 0.534447   \n2525                                NaN                 0.534447   \n2526                                1.0                 0.534447   \n2527                                1.0                 0.534447   \n\n      P(Word | Sentiment = Positive)  Negative Sentiment Word Frequency  \\\n0                           0.070312                               16.0   \n1                           0.015625                                6.0   \n2                           0.007812                                2.0   \n3                           0.265625                               77.0   \n4                           0.425781                               59.0   \n...                              ...                                ...   \n2523                        0.003906                                NaN   \n2524                        0.003906                                NaN   \n2525                             NaN                                1.0   \n2526                        0.003906                                NaN   \n2527                        0.003906                                NaN   \n\n      P(Sentiment = Negative)  P(Word | Sentiment = Negative)  \n0                    0.465553                        0.071749  \n1                    0.465553                        0.026906  \n2                    0.465553                        0.008969  \n3                    0.465553                        0.345291  \n4                    0.465553                        0.264574  \n...                       ...                             ...  \n2523                 0.465553                             NaN  \n2524                 0.465553                             NaN  \n2525                 0.465553                        0.004484  \n2526                 0.465553                             NaN  \n2527                 0.465553                             NaN  \n\n[2528 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Word Frequency</th>\n      <th>P(Word)</th>\n      <th>Positive Sentiment Word Frequency</th>\n      <th>P(Sentiment = Positive)</th>\n      <th>P(Word | Sentiment = Positive)</th>\n      <th>Negative Sentiment Word Frequency</th>\n      <th>P(Sentiment = Negative)</th>\n      <th>P(Word | Sentiment = Negative)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>very</td>\n      <td>34</td>\n      <td>0.004281</td>\n      <td>18.0</td>\n      <td>0.534447</td>\n      <td>0.070312</td>\n      <td>16.0</td>\n      <td>0.465553</td>\n      <td>0.071749</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>scene</td>\n      <td>10</td>\n      <td>0.001259</td>\n      <td>4.0</td>\n      <td>0.534447</td>\n      <td>0.015625</td>\n      <td>6.0</td>\n      <td>0.465553</td>\n      <td>0.026906</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>strong</td>\n      <td>4</td>\n      <td>0.000504</td>\n      <td>2.0</td>\n      <td>0.534447</td>\n      <td>0.007812</td>\n      <td>2.0</td>\n      <td>0.465553</td>\n      <td>0.008969</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>is</td>\n      <td>145</td>\n      <td>0.018257</td>\n      <td>68.0</td>\n      <td>0.534447</td>\n      <td>0.265625</td>\n      <td>77.0</td>\n      <td>0.465553</td>\n      <td>0.345291</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>and</td>\n      <td>168</td>\n      <td>0.021153</td>\n      <td>109.0</td>\n      <td>0.534447</td>\n      <td>0.425781</td>\n      <td>59.0</td>\n      <td>0.465553</td>\n      <td>0.264574</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2523</th>\n      <td>treasure</td>\n      <td>1</td>\n      <td>0.000126</td>\n      <td>1.0</td>\n      <td>0.534447</td>\n      <td>0.003906</td>\n      <td>NaN</td>\n      <td>0.465553</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2524</th>\n      <td>national</td>\n      <td>1</td>\n      <td>0.000126</td>\n      <td>1.0</td>\n      <td>0.534447</td>\n      <td>0.003906</td>\n      <td>NaN</td>\n      <td>0.465553</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2525</th>\n      <td>boringpointless</td>\n      <td>1</td>\n      <td>0.000126</td>\n      <td>NaN</td>\n      <td>0.534447</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.465553</td>\n      <td>0.004484</td>\n    </tr>\n    <tr>\n      <th>2526</th>\n      <td>schilling</td>\n      <td>1</td>\n      <td>0.000126</td>\n      <td>1.0</td>\n      <td>0.534447</td>\n      <td>0.003906</td>\n      <td>NaN</td>\n      <td>0.465553</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2527</th>\n      <td>vivian</td>\n      <td>1</td>\n      <td>0.000126</td>\n      <td>1.0</td>\n      <td>0.534447</td>\n      <td>0.003906</td>\n      <td>NaN</td>\n      <td>0.465553</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>2528 rows × 9 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                 Word  Word Frequency   P(Word)  \\\n0                very              32  0.004562   \n1               scene               6  0.000855   \n2              strong               2  0.000285   \n3                  is             135  0.019247   \n4                 and             173  0.024665   \n...               ...             ...       ...   \n2150          jessice               1  0.000143   \n2151             take               1  0.000143   \n2152           faster               1  0.000143   \n2153  boringpointless               1  0.000143   \n2154         remotely               1  0.000143   \n\n      Positive Sentiment Word Frequency  P(Sentiment = Positive)  \\\n0                                  15.0                 0.537657   \n1                                   3.0                 0.537657   \n2                                   1.0                 0.537657   \n3                                  67.0                 0.537657   \n4                                 113.0                 0.537657   \n...                                 ...                      ...   \n2150                                NaN                 0.537657   \n2151                                NaN                 0.537657   \n2152                                NaN                 0.537657   \n2153                                NaN                 0.537657   \n2154                                NaN                 0.537657   \n\n      P(Word | Sentiment = Positive)  Negative Sentiment Word Frequency  \\\n0                           0.058366                               17.0   \n1                           0.011673                                3.0   \n2                           0.003891                                1.0   \n3                           0.260700                               68.0   \n4                           0.439689                               60.0   \n...                              ...                                ...   \n2150                             NaN                                1.0   \n2151                             NaN                                1.0   \n2152                             NaN                                1.0   \n2153                             NaN                                1.0   \n2154                             NaN                                1.0   \n\n      P(Sentiment = Negative)  P(Word | Sentiment = Negative)  \n0                    0.462343                        0.076923  \n1                    0.462343                        0.013575  \n2                    0.462343                        0.004525  \n3                    0.462343                        0.307692  \n4                    0.462343                        0.271493  \n...                       ...                             ...  \n2150                 0.462343                        0.004525  \n2151                 0.462343                        0.004525  \n2152                 0.462343                        0.004525  \n2153                 0.462343                        0.004525  \n2154                 0.462343                        0.004525  \n\n[2155 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Word Frequency</th>\n      <th>P(Word)</th>\n      <th>Positive Sentiment Word Frequency</th>\n      <th>P(Sentiment = Positive)</th>\n      <th>P(Word | Sentiment = Positive)</th>\n      <th>Negative Sentiment Word Frequency</th>\n      <th>P(Sentiment = Negative)</th>\n      <th>P(Word | Sentiment = Negative)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>very</td>\n      <td>32</td>\n      <td>0.004562</td>\n      <td>15.0</td>\n      <td>0.537657</td>\n      <td>0.058366</td>\n      <td>17.0</td>\n      <td>0.462343</td>\n      <td>0.076923</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>scene</td>\n      <td>6</td>\n      <td>0.000855</td>\n      <td>3.0</td>\n      <td>0.537657</td>\n      <td>0.011673</td>\n      <td>3.0</td>\n      <td>0.462343</td>\n      <td>0.013575</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>strong</td>\n      <td>2</td>\n      <td>0.000285</td>\n      <td>1.0</td>\n      <td>0.537657</td>\n      <td>0.003891</td>\n      <td>1.0</td>\n      <td>0.462343</td>\n      <td>0.004525</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>is</td>\n      <td>135</td>\n      <td>0.019247</td>\n      <td>67.0</td>\n      <td>0.537657</td>\n      <td>0.260700</td>\n      <td>68.0</td>\n      <td>0.462343</td>\n      <td>0.307692</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>and</td>\n      <td>173</td>\n      <td>0.024665</td>\n      <td>113.0</td>\n      <td>0.537657</td>\n      <td>0.439689</td>\n      <td>60.0</td>\n      <td>0.462343</td>\n      <td>0.271493</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2150</th>\n      <td>jessice</td>\n      <td>1</td>\n      <td>0.000143</td>\n      <td>NaN</td>\n      <td>0.537657</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.462343</td>\n      <td>0.004525</td>\n    </tr>\n    <tr>\n      <th>2151</th>\n      <td>take</td>\n      <td>1</td>\n      <td>0.000143</td>\n      <td>NaN</td>\n      <td>0.537657</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.462343</td>\n      <td>0.004525</td>\n    </tr>\n    <tr>\n      <th>2152</th>\n      <td>faster</td>\n      <td>1</td>\n      <td>0.000143</td>\n      <td>NaN</td>\n      <td>0.537657</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.462343</td>\n      <td>0.004525</td>\n    </tr>\n    <tr>\n      <th>2153</th>\n      <td>boringpointless</td>\n      <td>1</td>\n      <td>0.000143</td>\n      <td>NaN</td>\n      <td>0.537657</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.462343</td>\n      <td>0.004525</td>\n    </tr>\n    <tr>\n      <th>2154</th>\n      <td>remotely</td>\n      <td>1</td>\n      <td>0.000143</td>\n      <td>NaN</td>\n      <td>0.537657</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.462343</td>\n      <td>0.004525</td>\n    </tr>\n  </tbody>\n</table>\n<p>2155 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def five_fold_cross_validation(data_frame: pd.DataFrame, smoothening: bool):\n",
    "    kf = KFold(n_splits=k, shuffle=True)\n",
    "    train_folds = kf.split(data_frame)\n",
    "    accuracies = []\n",
    "    max_accuracy_naive_bayes_parameters = pd.DataFrame()\n",
    "    for (train_training, train_testing), index in zip(train_folds, range(5)):\n",
    "        print(f\"---------------------------Fold {index + 1}---------------------------------\")\n",
    "        display(train.loc[train_training])\n",
    "        trained_parameters = generate_naive_bayes_parameters(train.loc[train_training], smoothening)\n",
    "        accuracy = predict_calculate_accuracy(train.loc[train_testing], trained_parameters)\n",
    "        accuracies.append(accuracy)\n",
    "        max_accuracy_naive_bayes_parameters = trained_parameters if max(\n",
    "            accuracies) == accuracy else max_accuracy_naive_bayes_parameters\n",
    "        display(trained_parameters)\n",
    "    return max_accuracy_naive_bayes_parameters\n",
    "\n",
    "\n",
    "vocabulary = five_fold_cross_validation(train, False)\n",
    "vocabulary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-205-198896de2224>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame[\"P(Sentiment = Positive | Sentence)\"] = data_frame[\"IMDB Review\"].apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  92.47491638795987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-205-198896de2224>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame[\"P(Sentiment = Negative | Sentence)\"] = data_frame[\"IMDB Review\"].apply(\n",
      "<ipython-input-205-198896de2224>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame[\"Predicted sentiment\"] = data_frame[\"P(Sentiment = Positive | Sentence)\"] > data_frame[\n"
     ]
    },
    {
     "data": {
      "text/plain": "92.47491638795987"
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_calculate_accuracy(train, vocabulary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  70.66666666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": "70.66666666666667"
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_calculate_accuracy(dev, vocabulary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  64.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "64.0"
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_calculate_accuracy(test, vocabulary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Most Useful words before Smoothing\n",
    "\n",
    "This is found by ordering the vocabulary in descending order of **P(Word | Sentiment)** for each negative and positive\n",
    "sentiments"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Useful Positive sentiment words:\n"
     ]
    },
    {
     "data": {
      "text/plain": "      Word  Word Frequency   P(Word)  Positive Sentiment Word Frequency  \\\n8      the             243  0.034645                              136.0   \n4      and             173  0.024665                              113.0   \n131      a             168  0.023952                               99.0   \n44      of             164  0.023382                               96.0   \n93      it             133  0.018962                               74.0   \n6     this             130  0.018534                               73.0   \n3       is             135  0.019247                               67.0   \n27       i             112  0.015968                               66.0   \n41      to             115  0.016396                               63.0   \n83    film              72  0.010265                               50.0   \n99      in              83  0.011833                               44.0   \n64     was              87  0.012404                               43.0   \n31    that              77  0.010978                               39.0   \n45   movie              76  0.010835                               38.0   \n162   with              39  0.005560                               29.0   \n39     but              53  0.007556                               27.0   \n206     as              44  0.006273                               26.0   \n80     for              49  0.006986                               22.0   \n73     one              37  0.005275                               22.0   \n461   good              31  0.004420                               22.0   \n\n     P(Sentiment = Positive)  P(Word | Sentiment = Positive)  \\\n8                   0.537657                        0.529183   \n4                   0.537657                        0.439689   \n131                 0.537657                        0.385214   \n44                  0.537657                        0.373541   \n93                  0.537657                        0.287938   \n6                   0.537657                        0.284047   \n3                   0.537657                        0.260700   \n27                  0.537657                        0.256809   \n41                  0.537657                        0.245136   \n83                  0.537657                        0.194553   \n99                  0.537657                        0.171206   \n64                  0.537657                        0.167315   \n31                  0.537657                        0.151751   \n45                  0.537657                        0.147860   \n162                 0.537657                        0.112840   \n39                  0.537657                        0.105058   \n206                 0.537657                        0.101167   \n80                  0.537657                        0.085603   \n73                  0.537657                        0.085603   \n461                 0.537657                        0.085603   \n\n     Negative Sentiment Word Frequency  P(Sentiment = Negative)  \\\n8                                107.0                 0.462343   \n4                                 60.0                 0.462343   \n131                               69.0                 0.462343   \n44                                68.0                 0.462343   \n93                                59.0                 0.462343   \n6                                 57.0                 0.462343   \n3                                 68.0                 0.462343   \n27                                46.0                 0.462343   \n41                                52.0                 0.462343   \n83                                22.0                 0.462343   \n99                                39.0                 0.462343   \n64                                44.0                 0.462343   \n31                                38.0                 0.462343   \n45                                38.0                 0.462343   \n162                               10.0                 0.462343   \n39                                26.0                 0.462343   \n206                               18.0                 0.462343   \n80                                27.0                 0.462343   \n73                                15.0                 0.462343   \n461                                9.0                 0.462343   \n\n     P(Word | Sentiment = Negative)  \n8                          0.484163  \n4                          0.271493  \n131                        0.312217  \n44                         0.307692  \n93                         0.266968  \n6                          0.257919  \n3                          0.307692  \n27                         0.208145  \n41                         0.235294  \n83                         0.099548  \n99                         0.176471  \n64                         0.199095  \n31                         0.171946  \n45                         0.171946  \n162                        0.045249  \n39                         0.117647  \n206                        0.081448  \n80                         0.122172  \n73                         0.067873  \n461                        0.040724  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Word Frequency</th>\n      <th>P(Word)</th>\n      <th>Positive Sentiment Word Frequency</th>\n      <th>P(Sentiment = Positive)</th>\n      <th>P(Word | Sentiment = Positive)</th>\n      <th>Negative Sentiment Word Frequency</th>\n      <th>P(Sentiment = Negative)</th>\n      <th>P(Word | Sentiment = Negative)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8</th>\n      <td>the</td>\n      <td>243</td>\n      <td>0.034645</td>\n      <td>136.0</td>\n      <td>0.537657</td>\n      <td>0.529183</td>\n      <td>107.0</td>\n      <td>0.462343</td>\n      <td>0.484163</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>and</td>\n      <td>173</td>\n      <td>0.024665</td>\n      <td>113.0</td>\n      <td>0.537657</td>\n      <td>0.439689</td>\n      <td>60.0</td>\n      <td>0.462343</td>\n      <td>0.271493</td>\n    </tr>\n    <tr>\n      <th>131</th>\n      <td>a</td>\n      <td>168</td>\n      <td>0.023952</td>\n      <td>99.0</td>\n      <td>0.537657</td>\n      <td>0.385214</td>\n      <td>69.0</td>\n      <td>0.462343</td>\n      <td>0.312217</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>of</td>\n      <td>164</td>\n      <td>0.023382</td>\n      <td>96.0</td>\n      <td>0.537657</td>\n      <td>0.373541</td>\n      <td>68.0</td>\n      <td>0.462343</td>\n      <td>0.307692</td>\n    </tr>\n    <tr>\n      <th>93</th>\n      <td>it</td>\n      <td>133</td>\n      <td>0.018962</td>\n      <td>74.0</td>\n      <td>0.537657</td>\n      <td>0.287938</td>\n      <td>59.0</td>\n      <td>0.462343</td>\n      <td>0.266968</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>this</td>\n      <td>130</td>\n      <td>0.018534</td>\n      <td>73.0</td>\n      <td>0.537657</td>\n      <td>0.284047</td>\n      <td>57.0</td>\n      <td>0.462343</td>\n      <td>0.257919</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>is</td>\n      <td>135</td>\n      <td>0.019247</td>\n      <td>67.0</td>\n      <td>0.537657</td>\n      <td>0.260700</td>\n      <td>68.0</td>\n      <td>0.462343</td>\n      <td>0.307692</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>i</td>\n      <td>112</td>\n      <td>0.015968</td>\n      <td>66.0</td>\n      <td>0.537657</td>\n      <td>0.256809</td>\n      <td>46.0</td>\n      <td>0.462343</td>\n      <td>0.208145</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>to</td>\n      <td>115</td>\n      <td>0.016396</td>\n      <td>63.0</td>\n      <td>0.537657</td>\n      <td>0.245136</td>\n      <td>52.0</td>\n      <td>0.462343</td>\n      <td>0.235294</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>film</td>\n      <td>72</td>\n      <td>0.010265</td>\n      <td>50.0</td>\n      <td>0.537657</td>\n      <td>0.194553</td>\n      <td>22.0</td>\n      <td>0.462343</td>\n      <td>0.099548</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>in</td>\n      <td>83</td>\n      <td>0.011833</td>\n      <td>44.0</td>\n      <td>0.537657</td>\n      <td>0.171206</td>\n      <td>39.0</td>\n      <td>0.462343</td>\n      <td>0.176471</td>\n    </tr>\n    <tr>\n      <th>64</th>\n      <td>was</td>\n      <td>87</td>\n      <td>0.012404</td>\n      <td>43.0</td>\n      <td>0.537657</td>\n      <td>0.167315</td>\n      <td>44.0</td>\n      <td>0.462343</td>\n      <td>0.199095</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>that</td>\n      <td>77</td>\n      <td>0.010978</td>\n      <td>39.0</td>\n      <td>0.537657</td>\n      <td>0.151751</td>\n      <td>38.0</td>\n      <td>0.462343</td>\n      <td>0.171946</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>movie</td>\n      <td>76</td>\n      <td>0.010835</td>\n      <td>38.0</td>\n      <td>0.537657</td>\n      <td>0.147860</td>\n      <td>38.0</td>\n      <td>0.462343</td>\n      <td>0.171946</td>\n    </tr>\n    <tr>\n      <th>162</th>\n      <td>with</td>\n      <td>39</td>\n      <td>0.005560</td>\n      <td>29.0</td>\n      <td>0.537657</td>\n      <td>0.112840</td>\n      <td>10.0</td>\n      <td>0.462343</td>\n      <td>0.045249</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>but</td>\n      <td>53</td>\n      <td>0.007556</td>\n      <td>27.0</td>\n      <td>0.537657</td>\n      <td>0.105058</td>\n      <td>26.0</td>\n      <td>0.462343</td>\n      <td>0.117647</td>\n    </tr>\n    <tr>\n      <th>206</th>\n      <td>as</td>\n      <td>44</td>\n      <td>0.006273</td>\n      <td>26.0</td>\n      <td>0.537657</td>\n      <td>0.101167</td>\n      <td>18.0</td>\n      <td>0.462343</td>\n      <td>0.081448</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>for</td>\n      <td>49</td>\n      <td>0.006986</td>\n      <td>22.0</td>\n      <td>0.537657</td>\n      <td>0.085603</td>\n      <td>27.0</td>\n      <td>0.462343</td>\n      <td>0.122172</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>one</td>\n      <td>37</td>\n      <td>0.005275</td>\n      <td>22.0</td>\n      <td>0.537657</td>\n      <td>0.085603</td>\n      <td>15.0</td>\n      <td>0.462343</td>\n      <td>0.067873</td>\n    </tr>\n    <tr>\n      <th>461</th>\n      <td>good</td>\n      <td>31</td>\n      <td>0.004420</td>\n      <td>22.0</td>\n      <td>0.537657</td>\n      <td>0.085603</td>\n      <td>9.0</td>\n      <td>0.462343</td>\n      <td>0.040724</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Most Useful Positive sentiment words:\")\n",
    "vocabulary.sort_values(\"P(Word | Sentiment = Positive)\", ascending=False)[:most_useful_limit]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Useful Negative sentiment words:\n"
     ]
    },
    {
     "data": {
      "text/plain": "      Word  Word Frequency   P(Word)  Positive Sentiment Word Frequency  \\\n8      the             243  0.034645                              136.0   \n131      a             168  0.023952                               99.0   \n3       is             135  0.019247                               67.0   \n44      of             164  0.023382                               96.0   \n4      and             173  0.024665                              113.0   \n93      it             133  0.018962                               74.0   \n6     this             130  0.018534                               73.0   \n41      to             115  0.016396                               63.0   \n27       i             112  0.015968                               66.0   \n64     was              87  0.012404                               43.0   \n99      in              83  0.011833                               44.0   \n31    that              77  0.010978                               39.0   \n45   movie              76  0.010835                               38.0   \n80     for              49  0.006986                               22.0   \n284    bad              31  0.004420                                4.0   \n127    not              38  0.005418                               11.0   \n39     but              53  0.007556                               27.0   \n83    film              72  0.010265                               50.0   \n67    just              32  0.004562                               10.0   \n11      on              35  0.004990                               14.0   \n\n     P(Sentiment = Positive)  P(Word | Sentiment = Positive)  \\\n8                   0.537657                        0.529183   \n131                 0.537657                        0.385214   \n3                   0.537657                        0.260700   \n44                  0.537657                        0.373541   \n4                   0.537657                        0.439689   \n93                  0.537657                        0.287938   \n6                   0.537657                        0.284047   \n41                  0.537657                        0.245136   \n27                  0.537657                        0.256809   \n64                  0.537657                        0.167315   \n99                  0.537657                        0.171206   \n31                  0.537657                        0.151751   \n45                  0.537657                        0.147860   \n80                  0.537657                        0.085603   \n284                 0.537657                        0.015564   \n127                 0.537657                        0.042802   \n39                  0.537657                        0.105058   \n83                  0.537657                        0.194553   \n67                  0.537657                        0.038911   \n11                  0.537657                        0.054475   \n\n     Negative Sentiment Word Frequency  P(Sentiment = Negative)  \\\n8                                107.0                 0.462343   \n131                               69.0                 0.462343   \n3                                 68.0                 0.462343   \n44                                68.0                 0.462343   \n4                                 60.0                 0.462343   \n93                                59.0                 0.462343   \n6                                 57.0                 0.462343   \n41                                52.0                 0.462343   \n27                                46.0                 0.462343   \n64                                44.0                 0.462343   \n99                                39.0                 0.462343   \n31                                38.0                 0.462343   \n45                                38.0                 0.462343   \n80                                27.0                 0.462343   \n284                               27.0                 0.462343   \n127                               27.0                 0.462343   \n39                                26.0                 0.462343   \n83                                22.0                 0.462343   \n67                                22.0                 0.462343   \n11                                21.0                 0.462343   \n\n     P(Word | Sentiment = Negative)  \n8                          0.484163  \n131                        0.312217  \n3                          0.307692  \n44                         0.307692  \n4                          0.271493  \n93                         0.266968  \n6                          0.257919  \n41                         0.235294  \n27                         0.208145  \n64                         0.199095  \n99                         0.176471  \n31                         0.171946  \n45                         0.171946  \n80                         0.122172  \n284                        0.122172  \n127                        0.122172  \n39                         0.117647  \n83                         0.099548  \n67                         0.099548  \n11                         0.095023  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Word Frequency</th>\n      <th>P(Word)</th>\n      <th>Positive Sentiment Word Frequency</th>\n      <th>P(Sentiment = Positive)</th>\n      <th>P(Word | Sentiment = Positive)</th>\n      <th>Negative Sentiment Word Frequency</th>\n      <th>P(Sentiment = Negative)</th>\n      <th>P(Word | Sentiment = Negative)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8</th>\n      <td>the</td>\n      <td>243</td>\n      <td>0.034645</td>\n      <td>136.0</td>\n      <td>0.537657</td>\n      <td>0.529183</td>\n      <td>107.0</td>\n      <td>0.462343</td>\n      <td>0.484163</td>\n    </tr>\n    <tr>\n      <th>131</th>\n      <td>a</td>\n      <td>168</td>\n      <td>0.023952</td>\n      <td>99.0</td>\n      <td>0.537657</td>\n      <td>0.385214</td>\n      <td>69.0</td>\n      <td>0.462343</td>\n      <td>0.312217</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>is</td>\n      <td>135</td>\n      <td>0.019247</td>\n      <td>67.0</td>\n      <td>0.537657</td>\n      <td>0.260700</td>\n      <td>68.0</td>\n      <td>0.462343</td>\n      <td>0.307692</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>of</td>\n      <td>164</td>\n      <td>0.023382</td>\n      <td>96.0</td>\n      <td>0.537657</td>\n      <td>0.373541</td>\n      <td>68.0</td>\n      <td>0.462343</td>\n      <td>0.307692</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>and</td>\n      <td>173</td>\n      <td>0.024665</td>\n      <td>113.0</td>\n      <td>0.537657</td>\n      <td>0.439689</td>\n      <td>60.0</td>\n      <td>0.462343</td>\n      <td>0.271493</td>\n    </tr>\n    <tr>\n      <th>93</th>\n      <td>it</td>\n      <td>133</td>\n      <td>0.018962</td>\n      <td>74.0</td>\n      <td>0.537657</td>\n      <td>0.287938</td>\n      <td>59.0</td>\n      <td>0.462343</td>\n      <td>0.266968</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>this</td>\n      <td>130</td>\n      <td>0.018534</td>\n      <td>73.0</td>\n      <td>0.537657</td>\n      <td>0.284047</td>\n      <td>57.0</td>\n      <td>0.462343</td>\n      <td>0.257919</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>to</td>\n      <td>115</td>\n      <td>0.016396</td>\n      <td>63.0</td>\n      <td>0.537657</td>\n      <td>0.245136</td>\n      <td>52.0</td>\n      <td>0.462343</td>\n      <td>0.235294</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>i</td>\n      <td>112</td>\n      <td>0.015968</td>\n      <td>66.0</td>\n      <td>0.537657</td>\n      <td>0.256809</td>\n      <td>46.0</td>\n      <td>0.462343</td>\n      <td>0.208145</td>\n    </tr>\n    <tr>\n      <th>64</th>\n      <td>was</td>\n      <td>87</td>\n      <td>0.012404</td>\n      <td>43.0</td>\n      <td>0.537657</td>\n      <td>0.167315</td>\n      <td>44.0</td>\n      <td>0.462343</td>\n      <td>0.199095</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>in</td>\n      <td>83</td>\n      <td>0.011833</td>\n      <td>44.0</td>\n      <td>0.537657</td>\n      <td>0.171206</td>\n      <td>39.0</td>\n      <td>0.462343</td>\n      <td>0.176471</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>that</td>\n      <td>77</td>\n      <td>0.010978</td>\n      <td>39.0</td>\n      <td>0.537657</td>\n      <td>0.151751</td>\n      <td>38.0</td>\n      <td>0.462343</td>\n      <td>0.171946</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>movie</td>\n      <td>76</td>\n      <td>0.010835</td>\n      <td>38.0</td>\n      <td>0.537657</td>\n      <td>0.147860</td>\n      <td>38.0</td>\n      <td>0.462343</td>\n      <td>0.171946</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>for</td>\n      <td>49</td>\n      <td>0.006986</td>\n      <td>22.0</td>\n      <td>0.537657</td>\n      <td>0.085603</td>\n      <td>27.0</td>\n      <td>0.462343</td>\n      <td>0.122172</td>\n    </tr>\n    <tr>\n      <th>284</th>\n      <td>bad</td>\n      <td>31</td>\n      <td>0.004420</td>\n      <td>4.0</td>\n      <td>0.537657</td>\n      <td>0.015564</td>\n      <td>27.0</td>\n      <td>0.462343</td>\n      <td>0.122172</td>\n    </tr>\n    <tr>\n      <th>127</th>\n      <td>not</td>\n      <td>38</td>\n      <td>0.005418</td>\n      <td>11.0</td>\n      <td>0.537657</td>\n      <td>0.042802</td>\n      <td>27.0</td>\n      <td>0.462343</td>\n      <td>0.122172</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>but</td>\n      <td>53</td>\n      <td>0.007556</td>\n      <td>27.0</td>\n      <td>0.537657</td>\n      <td>0.105058</td>\n      <td>26.0</td>\n      <td>0.462343</td>\n      <td>0.117647</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>film</td>\n      <td>72</td>\n      <td>0.010265</td>\n      <td>50.0</td>\n      <td>0.537657</td>\n      <td>0.194553</td>\n      <td>22.0</td>\n      <td>0.462343</td>\n      <td>0.099548</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>just</td>\n      <td>32</td>\n      <td>0.004562</td>\n      <td>10.0</td>\n      <td>0.537657</td>\n      <td>0.038911</td>\n      <td>22.0</td>\n      <td>0.462343</td>\n      <td>0.099548</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>on</td>\n      <td>35</td>\n      <td>0.004990</td>\n      <td>14.0</td>\n      <td>0.537657</td>\n      <td>0.054475</td>\n      <td>21.0</td>\n      <td>0.462343</td>\n      <td>0.095023</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Most Useful Negative sentiment words:\")\n",
    "vocabulary.sort_values(\"P(Word | Sentiment = Negative)\", ascending=False)[:most_useful_limit]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Smoothening\n",
    "\n",
    "Smoothening is done to compensate for unknown words. As all words can't be added to a dictionary and Naive Bayes is\n",
    "specialized to handle missing words.\n",
    "\n",
    "Smoothening is done by using the +1 method it is done in the get_naive_bayes_parameters function.\n",
    "\n",
    "All it does is adding +1 to the following:\n",
    "1. Word Frequency\n",
    "2. Positive Sentiment Word Frequency\n",
    "3. Negative Sentiment Word Frequency\n",
    "\n",
    "And +2 for Number of sentiments as these terms are in the denominator and needs to adhere and compensate for the +1 in\n",
    "the numerator so that the probability of most occurrence words will be less than 1\n",
    "1. Total words\n",
    "2. Total Positive sentiments\n",
    "3. Total Negative sentiments\n",
    "4. Total sentiments\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------Fold 1---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                           IMDB Review  Sentiment  \\\n0          This scene is very strong and unpleasant.            0   \n2    I liked the way Dustin Hoffman's character was...          1   \n6    This movie does an excellent job of revealing ...          1   \n7    The writers were \"smack on\" and I think the be...          1   \n8              Meredith M was better than all right.            1   \n..                                                 ...        ...   \n593            I never walked out of a movie faster.            0   \n594                        He's a national treasure.            1   \n595  One of the most boring,pointless movies I have...          0   \n596  As for the killer, don't expect anything origi...          0   \n597  Vivian Schilling did an excellent job with the...          1   \n\n     P(Sentiment = Positive | Sentence)  P(Sentiment = Negative | Sentence)  \\\n0                          0.000000e+00                        2.129726e-10   \n2                          6.030975e-26                        0.000000e+00   \n6                          9.614199e-29                        0.000000e+00   \n7                          4.520455e-23                        0.000000e+00   \n8                          5.900701e-13                        0.000000e+00   \n..                                  ...                                 ...   \n593                        0.000000e+00                        5.997471e-11   \n594                        1.315440e-03                        5.730402e-04   \n595                        0.000000e+00                        8.268346e-14   \n596                        0.000000e+00                        6.733542e-20   \n597                        0.000000e+00                        0.000000e+00   \n\n     Predicted sentiment  \n0                  False  \n2                   True  \n6                   True  \n7                   True  \n8                   True  \n..                   ...  \n593                False  \n594                 True  \n595                False  \n596                False  \n597                False  \n\n[478 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IMDB Review</th>\n      <th>Sentiment</th>\n      <th>P(Sentiment = Positive | Sentence)</th>\n      <th>P(Sentiment = Negative | Sentence)</th>\n      <th>Predicted sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>This scene is very strong and unpleasant.</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>2.129726e-10</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I liked the way Dustin Hoffman's character was...</td>\n      <td>1</td>\n      <td>6.030975e-26</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>This movie does an excellent job of revealing ...</td>\n      <td>1</td>\n      <td>9.614199e-29</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>The writers were \"smack on\" and I think the be...</td>\n      <td>1</td>\n      <td>4.520455e-23</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Meredith M was better than all right.</td>\n      <td>1</td>\n      <td>5.900701e-13</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>593</th>\n      <td>I never walked out of a movie faster.</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>5.997471e-11</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>594</th>\n      <td>He's a national treasure.</td>\n      <td>1</td>\n      <td>1.315440e-03</td>\n      <td>5.730402e-04</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>595</th>\n      <td>One of the most boring,pointless movies I have...</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>8.268346e-14</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>596</th>\n      <td>As for the killer, don't expect anything origi...</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>6.733542e-20</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>597</th>\n      <td>Vivian Schilling did an excellent job with the...</td>\n      <td>1</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>478 rows × 5 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  69.16666666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": "                 Word  Word Frequency   P(Word)  \\\n0                very              32  0.003462   \n1               scene               7  0.000757   \n2              strong               3  0.000325   \n3                  is             148  0.016014   \n4                 and             175  0.018935   \n...               ...             ...       ...   \n2168         national               2  0.000216   \n2169  boringpointless               2  0.000216   \n2170         remotely               2  0.000216   \n2171        schilling               2  0.000216   \n2172           vivian               2  0.000216   \n\n      Positive Sentiment Word Frequency  P(Sentiment = Positive)  \\\n0                                  17.0                   0.5375   \n1                                   4.0                   0.5375   \n2                                   2.0                   0.5375   \n3                                  73.0                   0.5375   \n4                                 114.0                   0.5375   \n...                                 ...                      ...   \n2168                                2.0                   0.5375   \n2169                                1.0                   0.5375   \n2170                                1.0                   0.5375   \n2171                                2.0                   0.5375   \n2172                                2.0                   0.5375   \n\n      P(Word | Sentiment = Positive)  Negative Sentiment Word Frequency  \\\n0                           0.065891                               16.0   \n1                           0.015504                                4.0   \n2                           0.007752                                2.0   \n3                           0.282946                               76.0   \n4                           0.441860                               62.0   \n...                              ...                                ...   \n2168                        0.007752                                1.0   \n2169                        0.003876                                2.0   \n2170                        0.003876                                2.0   \n2171                        0.007752                                1.0   \n2172                        0.007752                                1.0   \n\n      P(Sentiment = Negative)  P(Word | Sentiment = Negative)  \n0                    0.466667                        0.071429  \n1                    0.466667                        0.017857  \n2                    0.466667                        0.008929  \n3                    0.466667                        0.339286  \n4                    0.466667                        0.276786  \n...                       ...                             ...  \n2168                 0.466667                        0.004464  \n2169                 0.466667                        0.008929  \n2170                 0.466667                        0.008929  \n2171                 0.466667                        0.004464  \n2172                 0.466667                        0.004464  \n\n[2173 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Word Frequency</th>\n      <th>P(Word)</th>\n      <th>Positive Sentiment Word Frequency</th>\n      <th>P(Sentiment = Positive)</th>\n      <th>P(Word | Sentiment = Positive)</th>\n      <th>Negative Sentiment Word Frequency</th>\n      <th>P(Sentiment = Negative)</th>\n      <th>P(Word | Sentiment = Negative)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>very</td>\n      <td>32</td>\n      <td>0.003462</td>\n      <td>17.0</td>\n      <td>0.5375</td>\n      <td>0.065891</td>\n      <td>16.0</td>\n      <td>0.466667</td>\n      <td>0.071429</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>scene</td>\n      <td>7</td>\n      <td>0.000757</td>\n      <td>4.0</td>\n      <td>0.5375</td>\n      <td>0.015504</td>\n      <td>4.0</td>\n      <td>0.466667</td>\n      <td>0.017857</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>strong</td>\n      <td>3</td>\n      <td>0.000325</td>\n      <td>2.0</td>\n      <td>0.5375</td>\n      <td>0.007752</td>\n      <td>2.0</td>\n      <td>0.466667</td>\n      <td>0.008929</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>is</td>\n      <td>148</td>\n      <td>0.016014</td>\n      <td>73.0</td>\n      <td>0.5375</td>\n      <td>0.282946</td>\n      <td>76.0</td>\n      <td>0.466667</td>\n      <td>0.339286</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>and</td>\n      <td>175</td>\n      <td>0.018935</td>\n      <td>114.0</td>\n      <td>0.5375</td>\n      <td>0.441860</td>\n      <td>62.0</td>\n      <td>0.466667</td>\n      <td>0.276786</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2168</th>\n      <td>national</td>\n      <td>2</td>\n      <td>0.000216</td>\n      <td>2.0</td>\n      <td>0.5375</td>\n      <td>0.007752</td>\n      <td>1.0</td>\n      <td>0.466667</td>\n      <td>0.004464</td>\n    </tr>\n    <tr>\n      <th>2169</th>\n      <td>boringpointless</td>\n      <td>2</td>\n      <td>0.000216</td>\n      <td>1.0</td>\n      <td>0.5375</td>\n      <td>0.003876</td>\n      <td>2.0</td>\n      <td>0.466667</td>\n      <td>0.008929</td>\n    </tr>\n    <tr>\n      <th>2170</th>\n      <td>remotely</td>\n      <td>2</td>\n      <td>0.000216</td>\n      <td>1.0</td>\n      <td>0.5375</td>\n      <td>0.003876</td>\n      <td>2.0</td>\n      <td>0.466667</td>\n      <td>0.008929</td>\n    </tr>\n    <tr>\n      <th>2171</th>\n      <td>schilling</td>\n      <td>2</td>\n      <td>0.000216</td>\n      <td>2.0</td>\n      <td>0.5375</td>\n      <td>0.007752</td>\n      <td>1.0</td>\n      <td>0.466667</td>\n      <td>0.004464</td>\n    </tr>\n    <tr>\n      <th>2172</th>\n      <td>vivian</td>\n      <td>2</td>\n      <td>0.000216</td>\n      <td>2.0</td>\n      <td>0.5375</td>\n      <td>0.007752</td>\n      <td>1.0</td>\n      <td>0.466667</td>\n      <td>0.004464</td>\n    </tr>\n  </tbody>\n</table>\n<p>2173 rows × 9 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------Fold 2---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                           IMDB Review  Sentiment  \\\n0          This scene is very strong and unpleasant.            0   \n1    The plot was the same as pretty much every oth...          0   \n2    I liked the way Dustin Hoffman's character was...          1   \n3    From here on the Widmark character turns unint...          0   \n4    Also the music by Mark Snow is possibly the be...          1   \n..                                                 ...        ...   \n590  So I am here to warn you--DO NOT RENT THIS MOV...          0   \n591  Crash is a depressing little nothing, that pro...          0   \n594                        He's a national treasure.            1   \n596  As for the killer, don't expect anything origi...          0   \n597  Vivian Schilling did an excellent job with the...          1   \n\n     P(Sentiment = Positive | Sentence)  P(Sentiment = Negative | Sentence)  \\\n0                          0.000000e+00                        2.129726e-10   \n1                          0.000000e+00                        0.000000e+00   \n2                          6.030975e-26                        0.000000e+00   \n3                          0.000000e+00                        1.486995e-16   \n4                          1.299131e-22                        0.000000e+00   \n..                                  ...                                 ...   \n590                        0.000000e+00                        9.300731e-28   \n591                        0.000000e+00                        1.697297e-36   \n594                        1.315440e-03                        5.730402e-04   \n596                        0.000000e+00                        6.733542e-20   \n597                        0.000000e+00                        0.000000e+00   \n\n     Predicted sentiment  \n0                  False  \n1                  False  \n2                   True  \n3                  False  \n4                   True  \n..                   ...  \n590                False  \n591                False  \n594                 True  \n596                False  \n597                False  \n\n[478 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IMDB Review</th>\n      <th>Sentiment</th>\n      <th>P(Sentiment = Positive | Sentence)</th>\n      <th>P(Sentiment = Negative | Sentence)</th>\n      <th>Predicted sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>This scene is very strong and unpleasant.</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>2.129726e-10</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The plot was the same as pretty much every oth...</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I liked the way Dustin Hoffman's character was...</td>\n      <td>1</td>\n      <td>6.030975e-26</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>From here on the Widmark character turns unint...</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>1.486995e-16</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Also the music by Mark Snow is possibly the be...</td>\n      <td>1</td>\n      <td>1.299131e-22</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>590</th>\n      <td>So I am here to warn you--DO NOT RENT THIS MOV...</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>9.300731e-28</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>591</th>\n      <td>Crash is a depressing little nothing, that pro...</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>1.697297e-36</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>594</th>\n      <td>He's a national treasure.</td>\n      <td>1</td>\n      <td>1.315440e-03</td>\n      <td>5.730402e-04</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>596</th>\n      <td>As for the killer, don't expect anything origi...</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>6.733542e-20</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>597</th>\n      <td>Vivian Schilling did an excellent job with the...</td>\n      <td>1</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>478 rows × 5 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  67.5\n"
     ]
    },
    {
     "data": {
      "text/plain": "           Word  Word Frequency   P(Word)  Positive Sentiment Word Frequency  \\\n0          very              32  0.003053                               14.0   \n1         scene              10  0.000954                                4.0   \n2        strong               6  0.000573                                4.0   \n3            is             144  0.013740                               62.0   \n4           and             182  0.017366                              112.0   \n...         ...             ...       ...                                ...   \n2510   treasure               2  0.000191                                2.0   \n2511   national               2  0.000191                                2.0   \n2512   remotely               2  0.000191                                1.0   \n2513  schilling               2  0.000191                                2.0   \n2514     vivian               2  0.000191                                2.0   \n\n      P(Sentiment = Positive)  P(Word | Sentiment = Positive)  \\\n0                     0.53125                        0.054902   \n1                     0.53125                        0.015686   \n2                     0.53125                        0.015686   \n3                     0.53125                        0.243137   \n4                     0.53125                        0.439216   \n...                       ...                             ...   \n2510                  0.53125                        0.007843   \n2511                  0.53125                        0.007843   \n2512                  0.53125                        0.003922   \n2513                  0.53125                        0.007843   \n2514                  0.53125                        0.007843   \n\n      Negative Sentiment Word Frequency  P(Sentiment = Negative)  \\\n0                                  19.0                 0.472917   \n1                                   7.0                 0.472917   \n2                                   3.0                 0.472917   \n3                                  83.0                 0.472917   \n4                                  71.0                 0.472917   \n...                                 ...                      ...   \n2510                                1.0                 0.472917   \n2511                                1.0                 0.472917   \n2512                                2.0                 0.472917   \n2513                                1.0                 0.472917   \n2514                                1.0                 0.472917   \n\n      P(Word | Sentiment = Negative)  \n0                           0.083700  \n1                           0.030837  \n2                           0.013216  \n3                           0.365639  \n4                           0.312775  \n...                              ...  \n2510                        0.004405  \n2511                        0.004405  \n2512                        0.008811  \n2513                        0.004405  \n2514                        0.004405  \n\n[2515 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Word Frequency</th>\n      <th>P(Word)</th>\n      <th>Positive Sentiment Word Frequency</th>\n      <th>P(Sentiment = Positive)</th>\n      <th>P(Word | Sentiment = Positive)</th>\n      <th>Negative Sentiment Word Frequency</th>\n      <th>P(Sentiment = Negative)</th>\n      <th>P(Word | Sentiment = Negative)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>very</td>\n      <td>32</td>\n      <td>0.003053</td>\n      <td>14.0</td>\n      <td>0.53125</td>\n      <td>0.054902</td>\n      <td>19.0</td>\n      <td>0.472917</td>\n      <td>0.083700</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>scene</td>\n      <td>10</td>\n      <td>0.000954</td>\n      <td>4.0</td>\n      <td>0.53125</td>\n      <td>0.015686</td>\n      <td>7.0</td>\n      <td>0.472917</td>\n      <td>0.030837</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>strong</td>\n      <td>6</td>\n      <td>0.000573</td>\n      <td>4.0</td>\n      <td>0.53125</td>\n      <td>0.015686</td>\n      <td>3.0</td>\n      <td>0.472917</td>\n      <td>0.013216</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>is</td>\n      <td>144</td>\n      <td>0.013740</td>\n      <td>62.0</td>\n      <td>0.53125</td>\n      <td>0.243137</td>\n      <td>83.0</td>\n      <td>0.472917</td>\n      <td>0.365639</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>and</td>\n      <td>182</td>\n      <td>0.017366</td>\n      <td>112.0</td>\n      <td>0.53125</td>\n      <td>0.439216</td>\n      <td>71.0</td>\n      <td>0.472917</td>\n      <td>0.312775</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2510</th>\n      <td>treasure</td>\n      <td>2</td>\n      <td>0.000191</td>\n      <td>2.0</td>\n      <td>0.53125</td>\n      <td>0.007843</td>\n      <td>1.0</td>\n      <td>0.472917</td>\n      <td>0.004405</td>\n    </tr>\n    <tr>\n      <th>2511</th>\n      <td>national</td>\n      <td>2</td>\n      <td>0.000191</td>\n      <td>2.0</td>\n      <td>0.53125</td>\n      <td>0.007843</td>\n      <td>1.0</td>\n      <td>0.472917</td>\n      <td>0.004405</td>\n    </tr>\n    <tr>\n      <th>2512</th>\n      <td>remotely</td>\n      <td>2</td>\n      <td>0.000191</td>\n      <td>1.0</td>\n      <td>0.53125</td>\n      <td>0.003922</td>\n      <td>2.0</td>\n      <td>0.472917</td>\n      <td>0.008811</td>\n    </tr>\n    <tr>\n      <th>2513</th>\n      <td>schilling</td>\n      <td>2</td>\n      <td>0.000191</td>\n      <td>2.0</td>\n      <td>0.53125</td>\n      <td>0.007843</td>\n      <td>1.0</td>\n      <td>0.472917</td>\n      <td>0.004405</td>\n    </tr>\n    <tr>\n      <th>2514</th>\n      <td>vivian</td>\n      <td>2</td>\n      <td>0.000191</td>\n      <td>2.0</td>\n      <td>0.53125</td>\n      <td>0.007843</td>\n      <td>1.0</td>\n      <td>0.472917</td>\n      <td>0.004405</td>\n    </tr>\n  </tbody>\n</table>\n<p>2515 rows × 9 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------Fold 3---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                           IMDB Review  Sentiment  \\\n0          This scene is very strong and unpleasant.            0   \n1    The plot was the same as pretty much every oth...          0   \n2    I liked the way Dustin Hoffman's character was...          1   \n3    From here on the Widmark character turns unint...          0   \n4    Also the music by Mark Snow is possibly the be...          1   \n..                                                 ...        ...   \n590  So I am here to warn you--DO NOT RENT THIS MOV...          0   \n592  I just got bored watching Jessice Lange take h...          0   \n593            I never walked out of a movie faster.            0   \n594                        He's a national treasure.            1   \n595  One of the most boring,pointless movies I have...          0   \n\n     P(Sentiment = Positive | Sentence)  P(Sentiment = Negative | Sentence)  \\\n0                          0.000000e+00                        2.129726e-10   \n1                          0.000000e+00                        0.000000e+00   \n2                          6.030975e-26                        0.000000e+00   \n3                          0.000000e+00                        1.486995e-16   \n4                          1.299131e-22                        0.000000e+00   \n..                                  ...                                 ...   \n590                        0.000000e+00                        9.300731e-28   \n592                        0.000000e+00                        2.193928e-21   \n593                        0.000000e+00                        5.997471e-11   \n594                        1.315440e-03                        5.730402e-04   \n595                        0.000000e+00                        8.268346e-14   \n\n     Predicted sentiment  \n0                  False  \n1                  False  \n2                   True  \n3                  False  \n4                   True  \n..                   ...  \n590                False  \n592                False  \n593                False  \n594                 True  \n595                False  \n\n[478 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IMDB Review</th>\n      <th>Sentiment</th>\n      <th>P(Sentiment = Positive | Sentence)</th>\n      <th>P(Sentiment = Negative | Sentence)</th>\n      <th>Predicted sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>This scene is very strong and unpleasant.</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>2.129726e-10</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The plot was the same as pretty much every oth...</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I liked the way Dustin Hoffman's character was...</td>\n      <td>1</td>\n      <td>6.030975e-26</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>From here on the Widmark character turns unint...</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>1.486995e-16</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Also the music by Mark Snow is possibly the be...</td>\n      <td>1</td>\n      <td>1.299131e-22</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>590</th>\n      <td>So I am here to warn you--DO NOT RENT THIS MOV...</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>9.300731e-28</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>592</th>\n      <td>I just got bored watching Jessice Lange take h...</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>2.193928e-21</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>593</th>\n      <td>I never walked out of a movie faster.</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>5.997471e-11</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>594</th>\n      <td>He's a national treasure.</td>\n      <td>1</td>\n      <td>1.315440e-03</td>\n      <td>5.730402e-04</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>595</th>\n      <td>One of the most boring,pointless movies I have...</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>8.268346e-14</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>478 rows × 5 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  64.16666666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": "                 Word  Word Frequency   P(Word)  \\\n0                very              34  0.003266   \n1               scene              11  0.001057   \n2              strong               6  0.000576   \n3                  is             147  0.014120   \n4                 and             162  0.015560   \n...               ...             ...       ...   \n2475          jessice               2  0.000192   \n2476           faster               2  0.000192   \n2477         treasure               2  0.000192   \n2478         national               2  0.000192   \n2479  boringpointless               2  0.000192   \n\n      Positive Sentiment Word Frequency  P(Sentiment = Positive)  \\\n0                                  16.0                 0.527083   \n1                                   5.0                 0.527083   \n2                                   4.0                 0.527083   \n3                                  64.0                 0.527083   \n4                                 102.0                 0.527083   \n...                                 ...                      ...   \n2475                                1.0                 0.527083   \n2476                                1.0                 0.527083   \n2477                                2.0                 0.527083   \n2478                                2.0                 0.527083   \n2479                                1.0                 0.527083   \n\n      P(Word | Sentiment = Positive)  Negative Sentiment Word Frequency  \\\n0                           0.063241                               19.0   \n1                           0.019763                                7.0   \n2                           0.015810                                3.0   \n3                           0.252964                               84.0   \n4                           0.403162                               61.0   \n...                              ...                                ...   \n2475                        0.003953                                2.0   \n2476                        0.003953                                2.0   \n2477                        0.007905                                1.0   \n2478                        0.007905                                1.0   \n2479                        0.003953                                2.0   \n\n      P(Sentiment = Negative)  P(Word | Sentiment = Negative)  \n0                    0.477083                        0.082969  \n1                    0.477083                        0.030568  \n2                    0.477083                        0.013100  \n3                    0.477083                        0.366812  \n4                    0.477083                        0.266376  \n...                       ...                             ...  \n2475                 0.477083                        0.008734  \n2476                 0.477083                        0.008734  \n2477                 0.477083                        0.004367  \n2478                 0.477083                        0.004367  \n2479                 0.477083                        0.008734  \n\n[2480 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Word Frequency</th>\n      <th>P(Word)</th>\n      <th>Positive Sentiment Word Frequency</th>\n      <th>P(Sentiment = Positive)</th>\n      <th>P(Word | Sentiment = Positive)</th>\n      <th>Negative Sentiment Word Frequency</th>\n      <th>P(Sentiment = Negative)</th>\n      <th>P(Word | Sentiment = Negative)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>very</td>\n      <td>34</td>\n      <td>0.003266</td>\n      <td>16.0</td>\n      <td>0.527083</td>\n      <td>0.063241</td>\n      <td>19.0</td>\n      <td>0.477083</td>\n      <td>0.082969</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>scene</td>\n      <td>11</td>\n      <td>0.001057</td>\n      <td>5.0</td>\n      <td>0.527083</td>\n      <td>0.019763</td>\n      <td>7.0</td>\n      <td>0.477083</td>\n      <td>0.030568</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>strong</td>\n      <td>6</td>\n      <td>0.000576</td>\n      <td>4.0</td>\n      <td>0.527083</td>\n      <td>0.015810</td>\n      <td>3.0</td>\n      <td>0.477083</td>\n      <td>0.013100</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>is</td>\n      <td>147</td>\n      <td>0.014120</td>\n      <td>64.0</td>\n      <td>0.527083</td>\n      <td>0.252964</td>\n      <td>84.0</td>\n      <td>0.477083</td>\n      <td>0.366812</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>and</td>\n      <td>162</td>\n      <td>0.015560</td>\n      <td>102.0</td>\n      <td>0.527083</td>\n      <td>0.403162</td>\n      <td>61.0</td>\n      <td>0.477083</td>\n      <td>0.266376</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2475</th>\n      <td>jessice</td>\n      <td>2</td>\n      <td>0.000192</td>\n      <td>1.0</td>\n      <td>0.527083</td>\n      <td>0.003953</td>\n      <td>2.0</td>\n      <td>0.477083</td>\n      <td>0.008734</td>\n    </tr>\n    <tr>\n      <th>2476</th>\n      <td>faster</td>\n      <td>2</td>\n      <td>0.000192</td>\n      <td>1.0</td>\n      <td>0.527083</td>\n      <td>0.003953</td>\n      <td>2.0</td>\n      <td>0.477083</td>\n      <td>0.008734</td>\n    </tr>\n    <tr>\n      <th>2477</th>\n      <td>treasure</td>\n      <td>2</td>\n      <td>0.000192</td>\n      <td>2.0</td>\n      <td>0.527083</td>\n      <td>0.007905</td>\n      <td>1.0</td>\n      <td>0.477083</td>\n      <td>0.004367</td>\n    </tr>\n    <tr>\n      <th>2478</th>\n      <td>national</td>\n      <td>2</td>\n      <td>0.000192</td>\n      <td>2.0</td>\n      <td>0.527083</td>\n      <td>0.007905</td>\n      <td>1.0</td>\n      <td>0.477083</td>\n      <td>0.004367</td>\n    </tr>\n    <tr>\n      <th>2479</th>\n      <td>boringpointless</td>\n      <td>2</td>\n      <td>0.000192</td>\n      <td>1.0</td>\n      <td>0.527083</td>\n      <td>0.003953</td>\n      <td>2.0</td>\n      <td>0.477083</td>\n      <td>0.008734</td>\n    </tr>\n  </tbody>\n</table>\n<p>2480 rows × 9 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------Fold 4---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                           IMDB Review  Sentiment  \\\n0          This scene is very strong and unpleasant.            0   \n1    The plot was the same as pretty much every oth...          0   \n2    I liked the way Dustin Hoffman's character was...          1   \n3    From here on the Widmark character turns unint...          0   \n4    Also the music by Mark Snow is possibly the be...          1   \n..                                                 ...        ...   \n592  I just got bored watching Jessice Lange take h...          0   \n593            I never walked out of a movie faster.            0   \n595  One of the most boring,pointless movies I have...          0   \n596  As for the killer, don't expect anything origi...          0   \n597  Vivian Schilling did an excellent job with the...          1   \n\n     P(Sentiment = Positive | Sentence)  P(Sentiment = Negative | Sentence)  \\\n0                          0.000000e+00                        2.129726e-10   \n1                          0.000000e+00                        0.000000e+00   \n2                          6.030975e-26                        0.000000e+00   \n3                          0.000000e+00                        1.486995e-16   \n4                          1.299131e-22                        0.000000e+00   \n..                                  ...                                 ...   \n592                        0.000000e+00                        2.193928e-21   \n593                        0.000000e+00                        5.997471e-11   \n595                        0.000000e+00                        8.268346e-14   \n596                        0.000000e+00                        6.733542e-20   \n597                        0.000000e+00                        0.000000e+00   \n\n     Predicted sentiment  \n0                  False  \n1                  False  \n2                   True  \n3                  False  \n4                   True  \n..                   ...  \n592                False  \n593                False  \n595                False  \n596                False  \n597                False  \n\n[479 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IMDB Review</th>\n      <th>Sentiment</th>\n      <th>P(Sentiment = Positive | Sentence)</th>\n      <th>P(Sentiment = Negative | Sentence)</th>\n      <th>Predicted sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>This scene is very strong and unpleasant.</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>2.129726e-10</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The plot was the same as pretty much every oth...</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I liked the way Dustin Hoffman's character was...</td>\n      <td>1</td>\n      <td>6.030975e-26</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>From here on the Widmark character turns unint...</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>1.486995e-16</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Also the music by Mark Snow is possibly the be...</td>\n      <td>1</td>\n      <td>1.299131e-22</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>592</th>\n      <td>I just got bored watching Jessice Lange take h...</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>2.193928e-21</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>593</th>\n      <td>I never walked out of a movie faster.</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>5.997471e-11</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>595</th>\n      <td>One of the most boring,pointless movies I have...</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>8.268346e-14</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>596</th>\n      <td>As for the killer, don't expect anything origi...</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>6.733542e-20</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>597</th>\n      <td>Vivian Schilling did an excellent job with the...</td>\n      <td>1</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>479 rows × 5 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  68.90756302521008\n"
     ]
    },
    {
     "data": {
      "text/plain": "                 Word  Word Frequency   P(Word)  \\\n0                very              33  0.003088   \n1               scene               8  0.000749   \n2              strong               6  0.000561   \n3                  is             159  0.014878   \n4                 and             180  0.016843   \n...               ...             ...       ...   \n2518           walked               2  0.000187   \n2519  boringpointless               2  0.000187   \n2520         remotely               2  0.000187   \n2521        schilling               2  0.000187   \n2522           vivian               2  0.000187   \n\n      Positive Sentiment Word Frequency  P(Sentiment = Positive)  \\\n0                                  15.0                 0.544699   \n1                                   4.0                 0.544699   \n2                                   4.0                 0.544699   \n3                                  81.0                 0.544699   \n4                                 118.0                 0.544699   \n...                                 ...                      ...   \n2518                                1.0                 0.544699   \n2519                                1.0                 0.544699   \n2520                                1.0                 0.544699   \n2521                                2.0                 0.544699   \n2522                                2.0                 0.544699   \n\n      P(Word | Sentiment = Positive)  Negative Sentiment Word Frequency  \\\n0                           0.057252                               19.0   \n1                           0.015267                                5.0   \n2                           0.015267                                3.0   \n3                           0.309160                               79.0   \n4                           0.450382                               63.0   \n...                              ...                                ...   \n2518                        0.003817                                2.0   \n2519                        0.003817                                2.0   \n2520                        0.003817                                2.0   \n2521                        0.007634                                1.0   \n2522                        0.007634                                1.0   \n\n      P(Sentiment = Negative)  P(Word | Sentiment = Negative)  \n0                    0.459459                        0.085973  \n1                    0.459459                        0.022624  \n2                    0.459459                        0.013575  \n3                    0.459459                        0.357466  \n4                    0.459459                        0.285068  \n...                       ...                             ...  \n2518                 0.459459                        0.009050  \n2519                 0.459459                        0.009050  \n2520                 0.459459                        0.009050  \n2521                 0.459459                        0.004525  \n2522                 0.459459                        0.004525  \n\n[2523 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Word Frequency</th>\n      <th>P(Word)</th>\n      <th>Positive Sentiment Word Frequency</th>\n      <th>P(Sentiment = Positive)</th>\n      <th>P(Word | Sentiment = Positive)</th>\n      <th>Negative Sentiment Word Frequency</th>\n      <th>P(Sentiment = Negative)</th>\n      <th>P(Word | Sentiment = Negative)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>very</td>\n      <td>33</td>\n      <td>0.003088</td>\n      <td>15.0</td>\n      <td>0.544699</td>\n      <td>0.057252</td>\n      <td>19.0</td>\n      <td>0.459459</td>\n      <td>0.085973</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>scene</td>\n      <td>8</td>\n      <td>0.000749</td>\n      <td>4.0</td>\n      <td>0.544699</td>\n      <td>0.015267</td>\n      <td>5.0</td>\n      <td>0.459459</td>\n      <td>0.022624</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>strong</td>\n      <td>6</td>\n      <td>0.000561</td>\n      <td>4.0</td>\n      <td>0.544699</td>\n      <td>0.015267</td>\n      <td>3.0</td>\n      <td>0.459459</td>\n      <td>0.013575</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>is</td>\n      <td>159</td>\n      <td>0.014878</td>\n      <td>81.0</td>\n      <td>0.544699</td>\n      <td>0.309160</td>\n      <td>79.0</td>\n      <td>0.459459</td>\n      <td>0.357466</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>and</td>\n      <td>180</td>\n      <td>0.016843</td>\n      <td>118.0</td>\n      <td>0.544699</td>\n      <td>0.450382</td>\n      <td>63.0</td>\n      <td>0.459459</td>\n      <td>0.285068</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2518</th>\n      <td>walked</td>\n      <td>2</td>\n      <td>0.000187</td>\n      <td>1.0</td>\n      <td>0.544699</td>\n      <td>0.003817</td>\n      <td>2.0</td>\n      <td>0.459459</td>\n      <td>0.009050</td>\n    </tr>\n    <tr>\n      <th>2519</th>\n      <td>boringpointless</td>\n      <td>2</td>\n      <td>0.000187</td>\n      <td>1.0</td>\n      <td>0.544699</td>\n      <td>0.003817</td>\n      <td>2.0</td>\n      <td>0.459459</td>\n      <td>0.009050</td>\n    </tr>\n    <tr>\n      <th>2520</th>\n      <td>remotely</td>\n      <td>2</td>\n      <td>0.000187</td>\n      <td>1.0</td>\n      <td>0.544699</td>\n      <td>0.003817</td>\n      <td>2.0</td>\n      <td>0.459459</td>\n      <td>0.009050</td>\n    </tr>\n    <tr>\n      <th>2521</th>\n      <td>schilling</td>\n      <td>2</td>\n      <td>0.000187</td>\n      <td>2.0</td>\n      <td>0.544699</td>\n      <td>0.007634</td>\n      <td>1.0</td>\n      <td>0.459459</td>\n      <td>0.004525</td>\n    </tr>\n    <tr>\n      <th>2522</th>\n      <td>vivian</td>\n      <td>2</td>\n      <td>0.000187</td>\n      <td>2.0</td>\n      <td>0.544699</td>\n      <td>0.007634</td>\n      <td>1.0</td>\n      <td>0.459459</td>\n      <td>0.004525</td>\n    </tr>\n  </tbody>\n</table>\n<p>2523 rows × 9 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------Fold 5---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                           IMDB Review  Sentiment  \\\n1    The plot was the same as pretty much every oth...          0   \n3    From here on the Widmark character turns unint...          0   \n4    Also the music by Mark Snow is possibly the be...          1   \n5    The memories are murky but I can only say that...          1   \n6    This movie does an excellent job of revealing ...          1   \n..                                                 ...        ...   \n593            I never walked out of a movie faster.            0   \n594                        He's a national treasure.            1   \n595  One of the most boring,pointless movies I have...          0   \n596  As for the killer, don't expect anything origi...          0   \n597  Vivian Schilling did an excellent job with the...          1   \n\n     P(Sentiment = Positive | Sentence)  P(Sentiment = Negative | Sentence)  \\\n1                          0.000000e+00                        0.000000e+00   \n3                          0.000000e+00                        1.486995e-16   \n4                          1.299131e-22                        0.000000e+00   \n5                          2.708460e-31                        0.000000e+00   \n6                          9.614199e-29                        0.000000e+00   \n..                                  ...                                 ...   \n593                        0.000000e+00                        5.997471e-11   \n594                        1.315440e-03                        5.730402e-04   \n595                        0.000000e+00                        8.268346e-14   \n596                        0.000000e+00                        6.733542e-20   \n597                        0.000000e+00                        0.000000e+00   \n\n     Predicted sentiment  \n1                  False  \n3                  False  \n4                   True  \n5                   True  \n6                   True  \n..                   ...  \n593                False  \n594                 True  \n595                False  \n596                False  \n597                False  \n\n[479 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IMDB Review</th>\n      <th>Sentiment</th>\n      <th>P(Sentiment = Positive | Sentence)</th>\n      <th>P(Sentiment = Negative | Sentence)</th>\n      <th>Predicted sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>The plot was the same as pretty much every oth...</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>From here on the Widmark character turns unint...</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>1.486995e-16</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Also the music by Mark Snow is possibly the be...</td>\n      <td>1</td>\n      <td>1.299131e-22</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>The memories are murky but I can only say that...</td>\n      <td>1</td>\n      <td>2.708460e-31</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>This movie does an excellent job of revealing ...</td>\n      <td>1</td>\n      <td>9.614199e-29</td>\n      <td>0.000000e+00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>593</th>\n      <td>I never walked out of a movie faster.</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>5.997471e-11</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>594</th>\n      <td>He's a national treasure.</td>\n      <td>1</td>\n      <td>1.315440e-03</td>\n      <td>5.730402e-04</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>595</th>\n      <td>One of the most boring,pointless movies I have...</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>8.268346e-14</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>596</th>\n      <td>As for the killer, don't expect anything origi...</td>\n      <td>0</td>\n      <td>0.000000e+00</td>\n      <td>6.733542e-20</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>597</th>\n      <td>Vivian Schilling did an excellent job with the...</td>\n      <td>1</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>479 rows × 5 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  63.865546218487395\n"
     ]
    },
    {
     "data": {
      "text/plain": "                 Word  Word Frequency   P(Word)  \\\n0                 the             241  0.023777   \n1                  as              49  0.004834   \n2              horror               6  0.000592   \n3              pretty              10  0.000987   \n4               every              13  0.001283   \n...               ...             ...       ...   \n2414         national               2  0.000197   \n2415  boringpointless               2  0.000197   \n2416         remotely               2  0.000197   \n2417        schilling               2  0.000197   \n2418           vivian               2  0.000197   \n\n      Positive Sentiment Word Frequency  P(Sentiment = Positive)  \\\n0                                 139.0                 0.553015   \n1                                  27.0                 0.553015   \n2                                   4.0                 0.553015   \n3                                   6.0                 0.553015   \n4                                   8.0                 0.553015   \n...                                 ...                      ...   \n2414                                2.0                 0.553015   \n2415                                1.0                 0.553015   \n2416                                1.0                 0.553015   \n2417                                2.0                 0.553015   \n2418                                2.0                 0.553015   \n\n      P(Word | Sentiment = Positive)  Negative Sentiment Word Frequency  \\\n0                           0.522556                              103.0   \n1                           0.101504                               23.0   \n2                           0.015038                                3.0   \n3                           0.022556                                5.0   \n4                           0.030075                                6.0   \n...                              ...                                ...   \n2414                        0.007519                                1.0   \n2415                        0.003759                                2.0   \n2416                        0.003759                                2.0   \n2417                        0.007519                                1.0   \n2418                        0.007519                                1.0   \n\n      P(Sentiment = Negative)  P(Word | Sentiment = Negative)  \n0                    0.451143                        0.474654  \n1                    0.451143                        0.105991  \n2                    0.451143                        0.013825  \n3                    0.451143                        0.023041  \n4                    0.451143                        0.027650  \n...                       ...                             ...  \n2414                 0.451143                        0.004608  \n2415                 0.451143                        0.009217  \n2416                 0.451143                        0.009217  \n2417                 0.451143                        0.004608  \n2418                 0.451143                        0.004608  \n\n[2419 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Word Frequency</th>\n      <th>P(Word)</th>\n      <th>Positive Sentiment Word Frequency</th>\n      <th>P(Sentiment = Positive)</th>\n      <th>P(Word | Sentiment = Positive)</th>\n      <th>Negative Sentiment Word Frequency</th>\n      <th>P(Sentiment = Negative)</th>\n      <th>P(Word | Sentiment = Negative)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>the</td>\n      <td>241</td>\n      <td>0.023777</td>\n      <td>139.0</td>\n      <td>0.553015</td>\n      <td>0.522556</td>\n      <td>103.0</td>\n      <td>0.451143</td>\n      <td>0.474654</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>as</td>\n      <td>49</td>\n      <td>0.004834</td>\n      <td>27.0</td>\n      <td>0.553015</td>\n      <td>0.101504</td>\n      <td>23.0</td>\n      <td>0.451143</td>\n      <td>0.105991</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>horror</td>\n      <td>6</td>\n      <td>0.000592</td>\n      <td>4.0</td>\n      <td>0.553015</td>\n      <td>0.015038</td>\n      <td>3.0</td>\n      <td>0.451143</td>\n      <td>0.013825</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>pretty</td>\n      <td>10</td>\n      <td>0.000987</td>\n      <td>6.0</td>\n      <td>0.553015</td>\n      <td>0.022556</td>\n      <td>5.0</td>\n      <td>0.451143</td>\n      <td>0.023041</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>every</td>\n      <td>13</td>\n      <td>0.001283</td>\n      <td>8.0</td>\n      <td>0.553015</td>\n      <td>0.030075</td>\n      <td>6.0</td>\n      <td>0.451143</td>\n      <td>0.027650</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2414</th>\n      <td>national</td>\n      <td>2</td>\n      <td>0.000197</td>\n      <td>2.0</td>\n      <td>0.553015</td>\n      <td>0.007519</td>\n      <td>1.0</td>\n      <td>0.451143</td>\n      <td>0.004608</td>\n    </tr>\n    <tr>\n      <th>2415</th>\n      <td>boringpointless</td>\n      <td>2</td>\n      <td>0.000197</td>\n      <td>1.0</td>\n      <td>0.553015</td>\n      <td>0.003759</td>\n      <td>2.0</td>\n      <td>0.451143</td>\n      <td>0.009217</td>\n    </tr>\n    <tr>\n      <th>2416</th>\n      <td>remotely</td>\n      <td>2</td>\n      <td>0.000197</td>\n      <td>1.0</td>\n      <td>0.553015</td>\n      <td>0.003759</td>\n      <td>2.0</td>\n      <td>0.451143</td>\n      <td>0.009217</td>\n    </tr>\n    <tr>\n      <th>2417</th>\n      <td>schilling</td>\n      <td>2</td>\n      <td>0.000197</td>\n      <td>2.0</td>\n      <td>0.553015</td>\n      <td>0.007519</td>\n      <td>1.0</td>\n      <td>0.451143</td>\n      <td>0.004608</td>\n    </tr>\n    <tr>\n      <th>2418</th>\n      <td>vivian</td>\n      <td>2</td>\n      <td>0.000197</td>\n      <td>2.0</td>\n      <td>0.553015</td>\n      <td>0.007519</td>\n      <td>1.0</td>\n      <td>0.451143</td>\n      <td>0.004608</td>\n    </tr>\n  </tbody>\n</table>\n<p>2419 rows × 9 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                 Word  Word Frequency   P(Word)  \\\n0                very              32  0.003462   \n1               scene               7  0.000757   \n2              strong               3  0.000325   \n3                  is             148  0.016014   \n4                 and             175  0.018935   \n...               ...             ...       ...   \n2168         national               2  0.000216   \n2169  boringpointless               2  0.000216   \n2170         remotely               2  0.000216   \n2171        schilling               2  0.000216   \n2172           vivian               2  0.000216   \n\n      Positive Sentiment Word Frequency  P(Sentiment = Positive)  \\\n0                                  17.0                   0.5375   \n1                                   4.0                   0.5375   \n2                                   2.0                   0.5375   \n3                                  73.0                   0.5375   \n4                                 114.0                   0.5375   \n...                                 ...                      ...   \n2168                                2.0                   0.5375   \n2169                                1.0                   0.5375   \n2170                                1.0                   0.5375   \n2171                                2.0                   0.5375   \n2172                                2.0                   0.5375   \n\n      P(Word | Sentiment = Positive)  Negative Sentiment Word Frequency  \\\n0                           0.065891                               16.0   \n1                           0.015504                                4.0   \n2                           0.007752                                2.0   \n3                           0.282946                               76.0   \n4                           0.441860                               62.0   \n...                              ...                                ...   \n2168                        0.007752                                1.0   \n2169                        0.003876                                2.0   \n2170                        0.003876                                2.0   \n2171                        0.007752                                1.0   \n2172                        0.007752                                1.0   \n\n      P(Sentiment = Negative)  P(Word | Sentiment = Negative)  \n0                    0.466667                        0.071429  \n1                    0.466667                        0.017857  \n2                    0.466667                        0.008929  \n3                    0.466667                        0.339286  \n4                    0.466667                        0.276786  \n...                       ...                             ...  \n2168                 0.466667                        0.004464  \n2169                 0.466667                        0.008929  \n2170                 0.466667                        0.008929  \n2171                 0.466667                        0.004464  \n2172                 0.466667                        0.004464  \n\n[2173 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Word Frequency</th>\n      <th>P(Word)</th>\n      <th>Positive Sentiment Word Frequency</th>\n      <th>P(Sentiment = Positive)</th>\n      <th>P(Word | Sentiment = Positive)</th>\n      <th>Negative Sentiment Word Frequency</th>\n      <th>P(Sentiment = Negative)</th>\n      <th>P(Word | Sentiment = Negative)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>very</td>\n      <td>32</td>\n      <td>0.003462</td>\n      <td>17.0</td>\n      <td>0.5375</td>\n      <td>0.065891</td>\n      <td>16.0</td>\n      <td>0.466667</td>\n      <td>0.071429</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>scene</td>\n      <td>7</td>\n      <td>0.000757</td>\n      <td>4.0</td>\n      <td>0.5375</td>\n      <td>0.015504</td>\n      <td>4.0</td>\n      <td>0.466667</td>\n      <td>0.017857</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>strong</td>\n      <td>3</td>\n      <td>0.000325</td>\n      <td>2.0</td>\n      <td>0.5375</td>\n      <td>0.007752</td>\n      <td>2.0</td>\n      <td>0.466667</td>\n      <td>0.008929</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>is</td>\n      <td>148</td>\n      <td>0.016014</td>\n      <td>73.0</td>\n      <td>0.5375</td>\n      <td>0.282946</td>\n      <td>76.0</td>\n      <td>0.466667</td>\n      <td>0.339286</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>and</td>\n      <td>175</td>\n      <td>0.018935</td>\n      <td>114.0</td>\n      <td>0.5375</td>\n      <td>0.441860</td>\n      <td>62.0</td>\n      <td>0.466667</td>\n      <td>0.276786</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2168</th>\n      <td>national</td>\n      <td>2</td>\n      <td>0.000216</td>\n      <td>2.0</td>\n      <td>0.5375</td>\n      <td>0.007752</td>\n      <td>1.0</td>\n      <td>0.466667</td>\n      <td>0.004464</td>\n    </tr>\n    <tr>\n      <th>2169</th>\n      <td>boringpointless</td>\n      <td>2</td>\n      <td>0.000216</td>\n      <td>1.0</td>\n      <td>0.5375</td>\n      <td>0.003876</td>\n      <td>2.0</td>\n      <td>0.466667</td>\n      <td>0.008929</td>\n    </tr>\n    <tr>\n      <th>2170</th>\n      <td>remotely</td>\n      <td>2</td>\n      <td>0.000216</td>\n      <td>1.0</td>\n      <td>0.5375</td>\n      <td>0.003876</td>\n      <td>2.0</td>\n      <td>0.466667</td>\n      <td>0.008929</td>\n    </tr>\n    <tr>\n      <th>2171</th>\n      <td>schilling</td>\n      <td>2</td>\n      <td>0.000216</td>\n      <td>2.0</td>\n      <td>0.5375</td>\n      <td>0.007752</td>\n      <td>1.0</td>\n      <td>0.466667</td>\n      <td>0.004464</td>\n    </tr>\n    <tr>\n      <th>2172</th>\n      <td>vivian</td>\n      <td>2</td>\n      <td>0.000216</td>\n      <td>2.0</td>\n      <td>0.5375</td>\n      <td>0.007752</td>\n      <td>1.0</td>\n      <td>0.466667</td>\n      <td>0.004464</td>\n    </tr>\n  </tbody>\n</table>\n<p>2173 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = five_fold_cross_validation(train, True)\n",
    "vocabulary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-205-198896de2224>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame[\"P(Sentiment = Positive | Sentence)\"] = data_frame[\"IMDB Review\"].apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  91.80602006688963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-205-198896de2224>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame[\"P(Sentiment = Negative | Sentence)\"] = data_frame[\"IMDB Review\"].apply(\n",
      "<ipython-input-205-198896de2224>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame[\"Predicted sentiment\"] = data_frame[\"P(Sentiment = Positive | Sentence)\"] > data_frame[\n"
     ]
    },
    {
     "data": {
      "text/plain": "91.80602006688963"
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_calculate_accuracy(train, vocabulary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  69.33333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": "69.33333333333333"
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_calculate_accuracy(dev, vocabulary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  72.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "72.0"
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_calculate_accuracy(test, vocabulary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Most Useful words after Smoothing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Useful Positive sentiment words:\n"
     ]
    },
    {
     "data": {
      "text/plain": "      Word  Word Frequency   P(Word)  Positive Sentiment Word Frequency  \\\n23     the             242  0.026185                              136.0   \n4      and             175  0.018935                              114.0   \n43       a             176  0.019043                              105.0   \n25      of             156  0.016879                               90.0   \n91      it             135  0.014607                               74.0   \n3       is             148  0.016014                               73.0   \n6     this             127  0.013742                               68.0   \n20       i             109  0.011794                               64.0   \n7       to             117  0.012660                               62.0   \n78    film              73  0.007899                               58.0   \n170     in              91  0.009846                               49.0   \n9      was              85  0.009197                               43.0   \n86    that              78  0.008440                               41.0   \n26   movie              80  0.008656                               41.0   \n17    with              44  0.004761                               30.0   \n74     but              51  0.005518                               28.0   \n251     as              41  0.004436                               27.0   \n171    are              36  0.003895                               24.0   \n173    you              44  0.004761                               23.0   \n75     for              48  0.005194                               22.0   \n\n     P(Sentiment = Positive)  P(Word | Sentiment = Positive)  \\\n23                    0.5375                        0.527132   \n4                     0.5375                        0.441860   \n43                    0.5375                        0.406977   \n25                    0.5375                        0.348837   \n91                    0.5375                        0.286822   \n3                     0.5375                        0.282946   \n6                     0.5375                        0.263566   \n20                    0.5375                        0.248062   \n7                     0.5375                        0.240310   \n78                    0.5375                        0.224806   \n170                   0.5375                        0.189922   \n9                     0.5375                        0.166667   \n86                    0.5375                        0.158915   \n26                    0.5375                        0.158915   \n17                    0.5375                        0.116279   \n74                    0.5375                        0.108527   \n251                   0.5375                        0.104651   \n171                   0.5375                        0.093023   \n173                   0.5375                        0.089147   \n75                    0.5375                        0.085271   \n\n     Negative Sentiment Word Frequency  P(Sentiment = Negative)  \\\n23                               107.0                 0.466667   \n4                                 62.0                 0.466667   \n43                                72.0                 0.466667   \n25                                67.0                 0.466667   \n91                                62.0                 0.466667   \n3                                 76.0                 0.466667   \n6                                 60.0                 0.466667   \n20                                46.0                 0.466667   \n7                                 56.0                 0.466667   \n78                                16.0                 0.466667   \n170                               43.0                 0.466667   \n9                                 43.0                 0.466667   \n86                                38.0                 0.466667   \n26                                40.0                 0.466667   \n17                                15.0                 0.466667   \n74                                24.0                 0.466667   \n251                               15.0                 0.466667   \n171                               13.0                 0.466667   \n173                               22.0                 0.466667   \n75                                27.0                 0.466667   \n\n     P(Word | Sentiment = Negative)  \n23                         0.477679  \n4                          0.276786  \n43                         0.321429  \n25                         0.299107  \n91                         0.276786  \n3                          0.339286  \n6                          0.267857  \n20                         0.205357  \n7                          0.250000  \n78                         0.071429  \n170                        0.191964  \n9                          0.191964  \n86                         0.169643  \n26                         0.178571  \n17                         0.066964  \n74                         0.107143  \n251                        0.066964  \n171                        0.058036  \n173                        0.098214  \n75                         0.120536  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Word Frequency</th>\n      <th>P(Word)</th>\n      <th>Positive Sentiment Word Frequency</th>\n      <th>P(Sentiment = Positive)</th>\n      <th>P(Word | Sentiment = Positive)</th>\n      <th>Negative Sentiment Word Frequency</th>\n      <th>P(Sentiment = Negative)</th>\n      <th>P(Word | Sentiment = Negative)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>23</th>\n      <td>the</td>\n      <td>242</td>\n      <td>0.026185</td>\n      <td>136.0</td>\n      <td>0.5375</td>\n      <td>0.527132</td>\n      <td>107.0</td>\n      <td>0.466667</td>\n      <td>0.477679</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>and</td>\n      <td>175</td>\n      <td>0.018935</td>\n      <td>114.0</td>\n      <td>0.5375</td>\n      <td>0.441860</td>\n      <td>62.0</td>\n      <td>0.466667</td>\n      <td>0.276786</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>a</td>\n      <td>176</td>\n      <td>0.019043</td>\n      <td>105.0</td>\n      <td>0.5375</td>\n      <td>0.406977</td>\n      <td>72.0</td>\n      <td>0.466667</td>\n      <td>0.321429</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>of</td>\n      <td>156</td>\n      <td>0.016879</td>\n      <td>90.0</td>\n      <td>0.5375</td>\n      <td>0.348837</td>\n      <td>67.0</td>\n      <td>0.466667</td>\n      <td>0.299107</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>it</td>\n      <td>135</td>\n      <td>0.014607</td>\n      <td>74.0</td>\n      <td>0.5375</td>\n      <td>0.286822</td>\n      <td>62.0</td>\n      <td>0.466667</td>\n      <td>0.276786</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>is</td>\n      <td>148</td>\n      <td>0.016014</td>\n      <td>73.0</td>\n      <td>0.5375</td>\n      <td>0.282946</td>\n      <td>76.0</td>\n      <td>0.466667</td>\n      <td>0.339286</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>this</td>\n      <td>127</td>\n      <td>0.013742</td>\n      <td>68.0</td>\n      <td>0.5375</td>\n      <td>0.263566</td>\n      <td>60.0</td>\n      <td>0.466667</td>\n      <td>0.267857</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>i</td>\n      <td>109</td>\n      <td>0.011794</td>\n      <td>64.0</td>\n      <td>0.5375</td>\n      <td>0.248062</td>\n      <td>46.0</td>\n      <td>0.466667</td>\n      <td>0.205357</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>to</td>\n      <td>117</td>\n      <td>0.012660</td>\n      <td>62.0</td>\n      <td>0.5375</td>\n      <td>0.240310</td>\n      <td>56.0</td>\n      <td>0.466667</td>\n      <td>0.250000</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>film</td>\n      <td>73</td>\n      <td>0.007899</td>\n      <td>58.0</td>\n      <td>0.5375</td>\n      <td>0.224806</td>\n      <td>16.0</td>\n      <td>0.466667</td>\n      <td>0.071429</td>\n    </tr>\n    <tr>\n      <th>170</th>\n      <td>in</td>\n      <td>91</td>\n      <td>0.009846</td>\n      <td>49.0</td>\n      <td>0.5375</td>\n      <td>0.189922</td>\n      <td>43.0</td>\n      <td>0.466667</td>\n      <td>0.191964</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>was</td>\n      <td>85</td>\n      <td>0.009197</td>\n      <td>43.0</td>\n      <td>0.5375</td>\n      <td>0.166667</td>\n      <td>43.0</td>\n      <td>0.466667</td>\n      <td>0.191964</td>\n    </tr>\n    <tr>\n      <th>86</th>\n      <td>that</td>\n      <td>78</td>\n      <td>0.008440</td>\n      <td>41.0</td>\n      <td>0.5375</td>\n      <td>0.158915</td>\n      <td>38.0</td>\n      <td>0.466667</td>\n      <td>0.169643</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>movie</td>\n      <td>80</td>\n      <td>0.008656</td>\n      <td>41.0</td>\n      <td>0.5375</td>\n      <td>0.158915</td>\n      <td>40.0</td>\n      <td>0.466667</td>\n      <td>0.178571</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>with</td>\n      <td>44</td>\n      <td>0.004761</td>\n      <td>30.0</td>\n      <td>0.5375</td>\n      <td>0.116279</td>\n      <td>15.0</td>\n      <td>0.466667</td>\n      <td>0.066964</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>but</td>\n      <td>51</td>\n      <td>0.005518</td>\n      <td>28.0</td>\n      <td>0.5375</td>\n      <td>0.108527</td>\n      <td>24.0</td>\n      <td>0.466667</td>\n      <td>0.107143</td>\n    </tr>\n    <tr>\n      <th>251</th>\n      <td>as</td>\n      <td>41</td>\n      <td>0.004436</td>\n      <td>27.0</td>\n      <td>0.5375</td>\n      <td>0.104651</td>\n      <td>15.0</td>\n      <td>0.466667</td>\n      <td>0.066964</td>\n    </tr>\n    <tr>\n      <th>171</th>\n      <td>are</td>\n      <td>36</td>\n      <td>0.003895</td>\n      <td>24.0</td>\n      <td>0.5375</td>\n      <td>0.093023</td>\n      <td>13.0</td>\n      <td>0.466667</td>\n      <td>0.058036</td>\n    </tr>\n    <tr>\n      <th>173</th>\n      <td>you</td>\n      <td>44</td>\n      <td>0.004761</td>\n      <td>23.0</td>\n      <td>0.5375</td>\n      <td>0.089147</td>\n      <td>22.0</td>\n      <td>0.466667</td>\n      <td>0.098214</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>for</td>\n      <td>48</td>\n      <td>0.005194</td>\n      <td>22.0</td>\n      <td>0.5375</td>\n      <td>0.085271</td>\n      <td>27.0</td>\n      <td>0.466667</td>\n      <td>0.120536</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Most Useful Positive sentiment words:\")\n",
    "vocabulary.sort_values(\"P(Word | Sentiment = Positive)\", ascending=False)[:most_useful_limit]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Useful Negative sentiment words:\n"
     ]
    },
    {
     "data": {
      "text/plain": "      Word  Word Frequency   P(Word)  Positive Sentiment Word Frequency  \\\n23     the             242  0.026185                              136.0   \n3       is             148  0.016014                               73.0   \n43       a             176  0.019043                              105.0   \n25      of             156  0.016879                               90.0   \n4      and             175  0.018935                              114.0   \n91      it             135  0.014607                               74.0   \n6     this             127  0.013742                               68.0   \n7       to             117  0.012660                               62.0   \n20       i             109  0.011794                               64.0   \n170     in              91  0.009846                               49.0   \n9      was              85  0.009197                               43.0   \n26   movie              80  0.008656                               41.0   \n86    that              78  0.008440                               41.0   \n236    bad              36  0.003895                                6.0   \n75     for              48  0.005194                               22.0   \n74     but              51  0.005518                               28.0   \n97     not              31  0.003354                                9.0   \n173    you              44  0.004761                               23.0   \n178  there              30  0.003246                               10.0   \n12    just              31  0.003354                               12.0   \n\n     P(Sentiment = Positive)  P(Word | Sentiment = Positive)  \\\n23                    0.5375                        0.527132   \n3                     0.5375                        0.282946   \n43                    0.5375                        0.406977   \n25                    0.5375                        0.348837   \n4                     0.5375                        0.441860   \n91                    0.5375                        0.286822   \n6                     0.5375                        0.263566   \n7                     0.5375                        0.240310   \n20                    0.5375                        0.248062   \n170                   0.5375                        0.189922   \n9                     0.5375                        0.166667   \n26                    0.5375                        0.158915   \n86                    0.5375                        0.158915   \n236                   0.5375                        0.023256   \n75                    0.5375                        0.085271   \n74                    0.5375                        0.108527   \n97                    0.5375                        0.034884   \n173                   0.5375                        0.089147   \n178                   0.5375                        0.038760   \n12                    0.5375                        0.046512   \n\n     Negative Sentiment Word Frequency  P(Sentiment = Negative)  \\\n23                               107.0                 0.466667   \n3                                 76.0                 0.466667   \n43                                72.0                 0.466667   \n25                                67.0                 0.466667   \n4                                 62.0                 0.466667   \n91                                62.0                 0.466667   \n6                                 60.0                 0.466667   \n7                                 56.0                 0.466667   \n20                                46.0                 0.466667   \n170                               43.0                 0.466667   \n9                                 43.0                 0.466667   \n26                                40.0                 0.466667   \n86                                38.0                 0.466667   \n236                               31.0                 0.466667   \n75                                27.0                 0.466667   \n74                                24.0                 0.466667   \n97                                23.0                 0.466667   \n173                               22.0                 0.466667   \n178                               21.0                 0.466667   \n12                                20.0                 0.466667   \n\n     P(Word | Sentiment = Negative)  \n23                         0.477679  \n3                          0.339286  \n43                         0.321429  \n25                         0.299107  \n4                          0.276786  \n91                         0.276786  \n6                          0.267857  \n7                          0.250000  \n20                         0.205357  \n170                        0.191964  \n9                          0.191964  \n26                         0.178571  \n86                         0.169643  \n236                        0.138393  \n75                         0.120536  \n74                         0.107143  \n97                         0.102679  \n173                        0.098214  \n178                        0.093750  \n12                         0.089286  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Word Frequency</th>\n      <th>P(Word)</th>\n      <th>Positive Sentiment Word Frequency</th>\n      <th>P(Sentiment = Positive)</th>\n      <th>P(Word | Sentiment = Positive)</th>\n      <th>Negative Sentiment Word Frequency</th>\n      <th>P(Sentiment = Negative)</th>\n      <th>P(Word | Sentiment = Negative)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>23</th>\n      <td>the</td>\n      <td>242</td>\n      <td>0.026185</td>\n      <td>136.0</td>\n      <td>0.5375</td>\n      <td>0.527132</td>\n      <td>107.0</td>\n      <td>0.466667</td>\n      <td>0.477679</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>is</td>\n      <td>148</td>\n      <td>0.016014</td>\n      <td>73.0</td>\n      <td>0.5375</td>\n      <td>0.282946</td>\n      <td>76.0</td>\n      <td>0.466667</td>\n      <td>0.339286</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>a</td>\n      <td>176</td>\n      <td>0.019043</td>\n      <td>105.0</td>\n      <td>0.5375</td>\n      <td>0.406977</td>\n      <td>72.0</td>\n      <td>0.466667</td>\n      <td>0.321429</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>of</td>\n      <td>156</td>\n      <td>0.016879</td>\n      <td>90.0</td>\n      <td>0.5375</td>\n      <td>0.348837</td>\n      <td>67.0</td>\n      <td>0.466667</td>\n      <td>0.299107</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>and</td>\n      <td>175</td>\n      <td>0.018935</td>\n      <td>114.0</td>\n      <td>0.5375</td>\n      <td>0.441860</td>\n      <td>62.0</td>\n      <td>0.466667</td>\n      <td>0.276786</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>it</td>\n      <td>135</td>\n      <td>0.014607</td>\n      <td>74.0</td>\n      <td>0.5375</td>\n      <td>0.286822</td>\n      <td>62.0</td>\n      <td>0.466667</td>\n      <td>0.276786</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>this</td>\n      <td>127</td>\n      <td>0.013742</td>\n      <td>68.0</td>\n      <td>0.5375</td>\n      <td>0.263566</td>\n      <td>60.0</td>\n      <td>0.466667</td>\n      <td>0.267857</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>to</td>\n      <td>117</td>\n      <td>0.012660</td>\n      <td>62.0</td>\n      <td>0.5375</td>\n      <td>0.240310</td>\n      <td>56.0</td>\n      <td>0.466667</td>\n      <td>0.250000</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>i</td>\n      <td>109</td>\n      <td>0.011794</td>\n      <td>64.0</td>\n      <td>0.5375</td>\n      <td>0.248062</td>\n      <td>46.0</td>\n      <td>0.466667</td>\n      <td>0.205357</td>\n    </tr>\n    <tr>\n      <th>170</th>\n      <td>in</td>\n      <td>91</td>\n      <td>0.009846</td>\n      <td>49.0</td>\n      <td>0.5375</td>\n      <td>0.189922</td>\n      <td>43.0</td>\n      <td>0.466667</td>\n      <td>0.191964</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>was</td>\n      <td>85</td>\n      <td>0.009197</td>\n      <td>43.0</td>\n      <td>0.5375</td>\n      <td>0.166667</td>\n      <td>43.0</td>\n      <td>0.466667</td>\n      <td>0.191964</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>movie</td>\n      <td>80</td>\n      <td>0.008656</td>\n      <td>41.0</td>\n      <td>0.5375</td>\n      <td>0.158915</td>\n      <td>40.0</td>\n      <td>0.466667</td>\n      <td>0.178571</td>\n    </tr>\n    <tr>\n      <th>86</th>\n      <td>that</td>\n      <td>78</td>\n      <td>0.008440</td>\n      <td>41.0</td>\n      <td>0.5375</td>\n      <td>0.158915</td>\n      <td>38.0</td>\n      <td>0.466667</td>\n      <td>0.169643</td>\n    </tr>\n    <tr>\n      <th>236</th>\n      <td>bad</td>\n      <td>36</td>\n      <td>0.003895</td>\n      <td>6.0</td>\n      <td>0.5375</td>\n      <td>0.023256</td>\n      <td>31.0</td>\n      <td>0.466667</td>\n      <td>0.138393</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>for</td>\n      <td>48</td>\n      <td>0.005194</td>\n      <td>22.0</td>\n      <td>0.5375</td>\n      <td>0.085271</td>\n      <td>27.0</td>\n      <td>0.466667</td>\n      <td>0.120536</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>but</td>\n      <td>51</td>\n      <td>0.005518</td>\n      <td>28.0</td>\n      <td>0.5375</td>\n      <td>0.108527</td>\n      <td>24.0</td>\n      <td>0.466667</td>\n      <td>0.107143</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>not</td>\n      <td>31</td>\n      <td>0.003354</td>\n      <td>9.0</td>\n      <td>0.5375</td>\n      <td>0.034884</td>\n      <td>23.0</td>\n      <td>0.466667</td>\n      <td>0.102679</td>\n    </tr>\n    <tr>\n      <th>173</th>\n      <td>you</td>\n      <td>44</td>\n      <td>0.004761</td>\n      <td>23.0</td>\n      <td>0.5375</td>\n      <td>0.089147</td>\n      <td>22.0</td>\n      <td>0.466667</td>\n      <td>0.098214</td>\n    </tr>\n    <tr>\n      <th>178</th>\n      <td>there</td>\n      <td>30</td>\n      <td>0.003246</td>\n      <td>10.0</td>\n      <td>0.5375</td>\n      <td>0.038760</td>\n      <td>21.0</td>\n      <td>0.466667</td>\n      <td>0.093750</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>just</td>\n      <td>31</td>\n      <td>0.003354</td>\n      <td>12.0</td>\n      <td>0.5375</td>\n      <td>0.046512</td>\n      <td>20.0</td>\n      <td>0.466667</td>\n      <td>0.089286</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Most Useful Negative sentiment words:\")\n",
    "vocabulary.sort_values(\"P(Word | Sentiment = Negative)\", ascending=False)[:most_useful_limit]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMlp6bFS4Cf9rSnQgklke3R",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "sentiment_prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}